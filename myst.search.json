{"version":"1","records":[{"hierarchy":{"lvl1":"MRMS Cookbook"},"type":"lvl1","url":"/","position":0},{"hierarchy":{"lvl1":"MRMS Cookbook"},"content":"\n\n\n\n\n [![DOI](https://zenodo.org/badge/475509405.svg)](https://zenodo.org/badge/latestdoi/475509405) \n\nThis Project Pythia Cookbook covers how to access, analyze, and visualize Multi-radar, Multi-sensor (MRMS) Data.","type":"content","url":"/","position":1},{"hierarchy":{"lvl1":"MRMS Cookbook","lvl2":"Motivation"},"type":"lvl2","url":"/#motivation","position":2},{"hierarchy":{"lvl1":"MRMS Cookbook","lvl2":"Motivation"},"content":"The Multi-Radar, Multi-Sensor (MRMS) System combines radar, surface, and upper-air observation to produce a high-resolution (1 km) dataset used by researchers and forecasters alike. Despite its use, there are few published Python workflows that illustrate how to access MRMS data from Amazon Web Services (AWS) and produce beautiful, useful visualizations. We hope this cookbook serves the MRMS-user community well!","type":"content","url":"/#motivation","position":3},{"hierarchy":{"lvl1":"MRMS Cookbook","lvl2":"Authors"},"type":"lvl2","url":"/#authors","position":4},{"hierarchy":{"lvl1":"MRMS Cookbook","lvl2":"Authors"},"content":"","type":"content","url":"/#authors","position":5},{"hierarchy":{"lvl1":"MRMS Cookbook","lvl3":"Contributors","lvl2":"Authors"},"type":"lvl3","url":"/#contributors","position":6},{"hierarchy":{"lvl1":"MRMS Cookbook","lvl3":"Contributors","lvl2":"Authors"},"content":"","type":"content","url":"/#contributors","position":7},{"hierarchy":{"lvl1":"MRMS Cookbook","lvl2":"Structure"},"type":"lvl2","url":"/#structure","position":8},{"hierarchy":{"lvl1":"MRMS Cookbook","lvl2":"Structure"},"content":"Chapter 1 offers a brief overview of MRMS data and provides context for how the data is organized on AWS.\n\nChapter 2 contains a case study of the \n\nMarch 24–27 2023 Tornado Outbreak, showcasing fields relevant to severe weather prediction.\n\nChapter 3 examines another recent severe weather event, the \n\nJuly 2025 Central Texas Floods, instead focusing on precipitation fields and \n\nFLASH output, including comparisons to station observations.\n\nChapter 4 compares MRMS-derived precipitation estimates at Bankhead National Forest (BNF) Field Sites.\n\nChapter 5 offers a real-time look at MRMS data with the opportunity to select certain data fields.","type":"content","url":"/#structure","position":9},{"hierarchy":{"lvl1":"MRMS Cookbook","lvl2":"Running the Notebooks"},"type":"lvl2","url":"/#running-the-notebooks","position":10},{"hierarchy":{"lvl1":"MRMS Cookbook","lvl2":"Running the Notebooks"},"content":"You can either run the notebook using \n\nBinder or on your local machine.","type":"content","url":"/#running-the-notebooks","position":11},{"hierarchy":{"lvl1":"MRMS Cookbook","lvl3":"Running on Binder","lvl2":"Running the Notebooks"},"type":"lvl3","url":"/#running-on-binder","position":12},{"hierarchy":{"lvl1":"MRMS Cookbook","lvl3":"Running on Binder","lvl2":"Running the Notebooks"},"content":"The simplest way to interact with a Jupyter Notebook is through\n\n\nBinder, which enables the execution of a\n\n\nJupyter Book in the cloud. The details of how this works are not\nimportant for now. All you need to know is how to launch a Pythia\nCookbooks chapter via Binder. Simply navigate your mouse to\nthe top right corner of the book chapter you are viewing and click\non the rocket ship icon, (see figure below), and be sure to select\n“launch Binder”. After a moment you should be presented with a\nnotebook that you can interact with. I.e. you’ll be able to execute\nand even change the example programs. You’ll see that the code cells\nhave no output at first, until you execute them by pressing\nShift+Enter. Complete details on how to interact with\na live Jupyter notebook are described in \n\nGetting Started with\nJupyter.\n\nNote: not all Cookbook chapters are executable. If you do not see\nthe rocket ship icon, such as on this page, you are not viewing an\nexecutable book chapter.","type":"content","url":"/#running-on-binder","position":13},{"hierarchy":{"lvl1":"MRMS Cookbook","lvl3":"Running on Your Own Machine","lvl2":"Running the Notebooks"},"type":"lvl3","url":"/#running-on-your-own-machine","position":14},{"hierarchy":{"lvl1":"MRMS Cookbook","lvl3":"Running on Your Own Machine","lvl2":"Running the Notebooks"},"content":"If you are interested in running this material locally on your computer, you will need to follow this workflow:\n\nClone the https://github.com/ProjectPythia/mrms-cookbook repository: git clone https://github.com/ProjectPythia/mrms-cookbook.git\n\nMove into the mrms-cookbook directorycd mrms-cookbook\n\nCreate and activate your conda environment from the environment.yml fileconda env create -f environment.yml\nconda activate mrms-cookbook-dev\n\nMove into the notebooks directory and start up Jupyterlabcd notebooks/\njupyter lab","type":"content","url":"/#running-on-your-own-machine","position":15},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)"},"type":"lvl1","url":"/notebooks/bnf-mrms-qpe-hourly","position":0},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)"},"content":"\n\n","type":"content","url":"/notebooks/bnf-mrms-qpe-hourly","position":1},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)"},"type":"lvl1","url":"/notebooks/bnf-mrms-qpe-hourly#noaa-multi-radar-multi-sensor-system-mrms-at-the-bnf-field-site-s","position":2},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)"},"content":"\n\n","type":"content","url":"/notebooks/bnf-mrms-qpe-hourly#noaa-multi-radar-multi-sensor-system-mrms-at-the-bnf-field-site-s","position":3},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl2":"Overview"},"type":"lvl2","url":"/notebooks/bnf-mrms-qpe-hourly#overview","position":4},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl2":"Overview"},"content":"We’ll go through the steps of:\n\nDefine our region of verification sites\n\nQuery and Load Data from MRMS Buckets on AWS\n\nCreate a Multi-Panel Display of QPE for the different sites\n\n","type":"content","url":"/notebooks/bnf-mrms-qpe-hourly#overview","position":5},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl2":"Prerequisites"},"type":"lvl2","url":"/notebooks/bnf-mrms-qpe-hourly#prerequisites","position":6},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl2":"Prerequisites"},"content":"Concepts\n\nImportance\n\nNotes\n\nIntro to Cartopy\n\nNecessary\n\nMapping and Tiles\n\nIntro to Xarray\n\nNecessary\n\nFamiliarity with metadata structure\n\nTime to learn: 30 minutes\n\nSystem requirements:\n\nAny Operating System\n\nAt least 8 GB of RAM\n\n","type":"content","url":"/notebooks/bnf-mrms-qpe-hourly#prerequisites","position":7},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl2":"Imports"},"type":"lvl2","url":"/notebooks/bnf-mrms-qpe-hourly#imports","position":8},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl2":"Imports"},"content":"\n\nimport cfgrib\nimport xarray as xr\nimport fsspec\nimport glob\nimport tempfile\nimport gzip\nimport geopandas as gpd\nimport pandas as pd\nimport numpy as np\nimport warnings\n\nfrom cartopy import feature as cfeature\nimport cartopy.crs as ccrs\nfrom cartopy.io.img_tiles import OSM\nfrom matplotlib.transforms import offset_copy\nfrom matplotlib import pyplot as plt\n\nfrom metpy.plots import USCOUNTIES\n\nimport cmweather\n\n# To ignore all RuntimeWarnings globally\nwarnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n\n","type":"content","url":"/notebooks/bnf-mrms-qpe-hourly#imports","position":9},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl2":"Hourly QPE BNF Mosaic"},"type":"lvl2","url":"/notebooks/bnf-mrms-qpe-hourly#hourly-qpe-bnf-mosaic","position":10},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl2":"Hourly QPE BNF Mosaic"},"content":"The \n\nNOAA Multi-Radar / Multi-Sensor System (MRMS) was created to produce products of preciptiation impacts on transportation and aviation.\n\nUsing the \n\nNOAA MRMS AWS Bucket, this notebook details creation of quicklooks to investigate a Quantitative Preciptiation Estimates (QPE) for the U.S. Department of Energy Atmospheric Radiation Measurement (ARM) AMF-3 Deployment to Bankhead National Forest.\n\nWe start first with a dictionary containing our sites of interest, these are located Southwest of Decatur, Alabama.\n\nMore about the BNF Site can be found on the \n\nARM Website.\n\nglobal_sites = {\"M1\" : [34.34525, -87.33842],\n                \"S4\" : [34.46451, -87.23598],\n                \"S3\" : [34.63080, -87.13311],\n                \"S20\" : [34.65401, -87.29264],\n                \"S30\" : [34.38501, -86.92757],\n                \"S40\" : [34.17932, -87.45349]}\n\n\n# Define a domain to set the extent of the figures\nbnf_domain = [272.0, 274.0, 34.1, 35.1]\n\n","type":"content","url":"/notebooks/bnf-mrms-qpe-hourly#hourly-qpe-bnf-mosaic","position":11},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl3":"Visualize the Site Locations Using Cartopy","lvl2":"Hourly QPE BNF Mosaic"},"type":"lvl3","url":"/notebooks/bnf-mrms-qpe-hourly#visualize-the-site-locations-using-cartopy","position":12},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl3":"Visualize the Site Locations Using Cartopy","lvl2":"Hourly QPE BNF Mosaic"},"content":"\n\nfig = plt.figure(figsize=(12,8))\nax = plt.subplot(projection=ccrs.PlateCarree())\n\ntiler = OSM()\nax.add_image(tiler, 12, zorder=0, alpha=0.7)\nfor site in global_sites:\n    ax.scatter(global_sites[site][1], global_sites[site][0], label=site)\n\nax.set_extent(bnf_domain)\n\nplt.legend(loc=\"upper right\")\nplt.title(\"ARM Bankhead National Forest Sites\", fontsize=16);\n\n","type":"content","url":"/notebooks/bnf-mrms-qpe-hourly#visualize-the-site-locations-using-cartopy","position":13},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl2":"Query and Load Data from MRMS Buckets on AWS"},"type":"lvl2","url":"/notebooks/bnf-mrms-qpe-hourly#query-and-load-data-from-mrms-buckets-on-aws","position":14},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl2":"Query and Load Data from MRMS Buckets on AWS"},"content":"Note the Multi-Sensor (i.e. gauge adjusted) QPE product is split into two categories (Pass 1 and Pass 2), which defines the gauge latency used to adjust radar dervied QPE.\n\n# Define a Date for Analysis [YYYYMMDD format]\nDATE = \"20250524\"\nHOUR = \"000000\"\n\n## Setup the AWS S3 filesystem\nfs = fsspec.filesystem(\"s3\", anon=True)\n\ns3_multi_bucket = [f\"s3://noaa-mrms-pds/CONUS/MultiSensor_QPE_01H_Pass1_00.00/{DATE}/*.gz\"]\ns3_pass2_bucket = [f\"s3://noaa-mrms-pds/CONUS/MultiSensor_QPE_01H_Pass2_00.00/{DATE}/*.gz\"]\ns3_radar_bucket = [f\"s3://noaa-mrms-pds/CONUS/RadarOnly_QPE_01H_00.00/{DATE}/*[0-9]0000.grib2.gz\"]\n\n","type":"content","url":"/notebooks/bnf-mrms-qpe-hourly#query-and-load-data-from-mrms-buckets-on-aws","position":15},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl3":"Loop through and Create Lists of Datasets","lvl2":"Query and Load Data from MRMS Buckets on AWS"},"type":"lvl3","url":"/notebooks/bnf-mrms-qpe-hourly#loop-through-and-create-lists-of-datasets","position":16},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl3":"Loop through and Create Lists of Datasets","lvl2":"Query and Load Data from MRMS Buckets on AWS"},"content":"Our next step is to search, access, and load our data into merged datasets, adding some additional metadata such as units. We apply this for each our our multipass, pass2, and radar datasets.\n\nds_multi_list = []\nfor scan in s3_multi_bucket:\n    file_path = sorted(fs.glob(scan))\n    for mrms in file_path:\n        with fs.open(mrms, 'rb') as gzip_file:\n            with tempfile.NamedTemporaryFile(suffix=\".grib2\") as f:\n                # Uncompress and read the file\n                f.write(gzip.decompress(gzip_file.read()))\n                ds = xr.load_dataset(f.name, decode_timedelta=False)\n                # Parameters are stored as 'unknown'; meta data in filename\n                ds = ds.rename({\"unknown\" : \"multisensor_qpe_1hr\"})\n                ds[\"multisensor_qpe_1hr\"].attrs[\"units\"] = \"mm\"\n                ds[\"multisensor_qpe_1hr\"].attrs[\"long_name\"] = \"Precipitation Accumulation (1-Hr latency)\"\n                # Subset for the desired bounding box and take out all missing values\n                ds = ds.sel(latitude=slice(bnf_domain[3], bnf_domain[2]), longitude=slice(bnf_domain[0], bnf_domain[1])).where(ds.multisensor_qpe_1hr > 0)\n                ds_multi_list.append(ds)\n\nds_radar_list = []\nfor scan in s3_radar_bucket:\n    file_path = sorted(fs.glob(scan))\n    for mrms in file_path:\n        with fs.open(mrms, 'rb') as gzip_file:\n            with tempfile.NamedTemporaryFile(suffix=\".grib2\") as f:\n                # Uncompress and read the file\n                f.write(gzip.decompress(gzip_file.read()))\n                ds = xr.load_dataset(f.name, decode_timedelta=False)\n                ds = ds.rename({\"unknown\" : \"radar_qpe_1hr\"})\n                ds[\"radar_qpe_1hr\"].attrs[\"units\"] = \"mm\"\n                ds[\"radar_qpe_1hr\"].attrs[\"long_name\"] = \"Precipitation Accumulation\"\n                 # Subset for the desired bounding box and take out all missing values\n                ds = ds.sel(latitude=slice(bnf_domain[3], bnf_domain[2]), longitude=slice(bnf_domain[0], bnf_domain[1])).where(ds.radar_qpe_1hr > 0)\n                ds_radar_list.append(ds)\n\nds_pass2_list = []\nfor scan in s3_pass2_bucket:\n    file_path = sorted(fs.glob(scan))\n    for mrms in file_path:\n        with fs.open(mrms, 'rb') as gzip_file:\n            with tempfile.NamedTemporaryFile(suffix=\".grib2\") as f:\n                # Uncompress and read the file\n                f.write(gzip.decompress(gzip_file.read()))\n                ds = xr.load_dataset(f.name, decode_timedelta=False)\n                ds = ds.rename({\"unknown\" : \"multisensor_qpe_pass2\"})\n                ds[\"multisensor_qpe_pass2\"].attrs[\"units\"] = \"mm\"\n                ds[\"multisensor_qpe_pass2\"].attrs[\"long_name\"] = \"Precipitation Accumulation (2-Hr latency)\"\n                # Subset for the desired bounding box and take out all missing values\n                ds = ds.sel(latitude=slice(bnf_domain[3], bnf_domain[2]), longitude=slice(bnf_domain[0], bnf_domain[1])).where(ds.multisensor_qpe_pass2 > 0)\n                ds_pass2_list.append(ds)\n\n","type":"content","url":"/notebooks/bnf-mrms-qpe-hourly#loop-through-and-create-lists-of-datasets","position":17},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl3":"Merge our Files Together","lvl2":"Query and Load Data from MRMS Buckets on AWS"},"type":"lvl3","url":"/notebooks/bnf-mrms-qpe-hourly#merge-our-files-together","position":18},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl3":"Merge our Files Together","lvl2":"Query and Load Data from MRMS Buckets on AWS"},"content":"Once we have lists of files, we can merge based on the time dimension.\n\n# Concatenate all hourly files into xarray datasets\nds_radar_merged = xr.concat(ds_radar_list, dim=\"time\")\nds_multi_merged = xr.concat(ds_multi_list, dim=\"time\")\nds_pass2_merged = xr.concat(ds_pass2_list, dim=\"time\")\n\nAnd finally merge our various passes and QPE data into one single dataset.\n\n# Merge Radar, Multi-Sensor Pass 1 and Multi-Sensor Pass 2 QPE into single dataset\nds_merged = xr.merge([ds_radar_merged, ds_multi_merged, ds_pass2_merged])\n\n","type":"content","url":"/notebooks/bnf-mrms-qpe-hourly#merge-our-files-together","position":19},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl3":"Calculate Precipitation Accumulation","lvl2":"Query and Load Data from MRMS Buckets on AWS"},"type":"lvl3","url":"/notebooks/bnf-mrms-qpe-hourly#calculate-precipitation-accumulation","position":20},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl3":"Calculate Precipitation Accumulation","lvl2":"Query and Load Data from MRMS Buckets on AWS"},"content":"Our last step is to calculate our preciptiation accumulation as observed from radar data. We do this by using the xarray cumulative sum \n\ncumsum function.\n\n# Calculate the Cumulative Distribution\nradar_cumulative = ds_merged['radar_qpe_1hr'].cumsum(dim='time')\nmultisensor = ds_merged['multisensor_qpe_1hr'].cumsum(dim=\"time\")\nmultisensor_pass2 = ds_merged['multisensor_qpe_pass2'].cumsum(dim=\"time\")\n\nds_merged['cumulative_radar_qpe'] = radar_cumulative\nds_merged[\"cumulative_radar_qpe\"].attrs[\"units\"] = \"mm\"\nds_merged[\"cumulative_radar_qpe\"].attrs[\"long_name\"] = \"Precipitation Accumulation\"\n\nds_merged['cumulative_multisensor'] = multisensor\nds_merged[\"cumulative_multisensor\"].attrs[\"units\"] = \"mm\"\nds_merged[\"cumulative_multisensor\"].attrs[\"long_name\"] = \"Precipitation Accumulation (1-Hr latency)\"\n\nds_merged['cumulative_ms_pass2'] = multisensor_pass2\nds_merged[\"cumulative_ms_pass2\"].attrs[\"units\"] = \"mm\"\nds_merged[\"cumulative_ms_pass2\"].attrs[\"long_name\"] = \"Precipitation Accumulation (2-Hr latency)\"\nds_merged\n\n","type":"content","url":"/notebooks/bnf-mrms-qpe-hourly#calculate-precipitation-accumulation","position":21},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl2":"Create a Multi-Panel QPE Display"},"type":"lvl2","url":"/notebooks/bnf-mrms-qpe-hourly#create-a-multi-panel-qpe-display","position":22},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl2":"Create a Multi-Panel QPE Display"},"content":"Now that we have our merged, cleaned data, we can create a single graphic summarizing the cumulative precipitation at our different sites. We use nearest neighbor here to subset from the broader region.\n\n#---------------------------------------------------\n# Define the Figure for Detailed Subplot Placement\n#---------------------------------------------------\nfig = plt.figure(figsize=(24, 10))\ntiler = OSM()\nmercator = tiler.crs\nax = fig.add_subplot(1, 3, 1, projection=ccrs.PlateCarree())\n\n# adjust the subplot widths\nplt.subplots_adjust(wspace=0.3)\n\n# Find the maximum value at each position\nda_max = ds_merged.isel(time=-1).radar_qpe_1hr.max()\n\n# Find the minimum value at each position\nda_min = 0\n\n# ---------------------------------------------\n# Display the Radar Precipitation Accumulation\n# ---------------------------------------------\n\n## subset the data\nds_merged.isel(time=15).radar_qpe_1hr.plot(transform=ccrs.PlateCarree(),\n                                           ax=ax,\n                                           cmap=\"ChaseSpectral\",\n                                           vmin=da_min,\n                                           vmax=da_max,\n                                           cbar_kwargs={\"location\" : \"bottom\"})\n\n# Add some various map elements to the plot to make it recognizable.\nax.add_feature(cfeature.LAND)\nax.add_feature(cfeature.OCEAN)\nax.add_feature(cfeature.BORDERS)\nax.add_image(tiler, 12, zorder=1, alpha=0.55)\nax.gridlines(draw_labels=True)\n\n# Set plot bounds\nax.set_extent(bnf_domain)\n\n# add in crosshairs to indicate the lat/lon slices\nax.axhline(y=global_sites[\"M1\"][0], color=\"black\", linestyle=\"--\")\nax.axvline(x=global_sites[\"M1\"][1], color=\"red\", linestyle=\"--\")\n\n# Display the location of the BNF supplementarly sites\nfor key in global_sites:\n    # Add a marker for the BNF sites.\n    ax.plot(global_sites[key][1], \n            global_sites[key][0], \n            marker='o', \n            color='black', \n            markersize=10, \n            alpha=0.7, \n            transform=ccrs.PlateCarree())\n\n    # Use the cartopy interface to create a matplotlib transform object\n    # for the Geodetic coordinate system. We will use this along with\n    # matplotlib's offset_copy function to define a coordinate system which\n    # translates the text by 25 pixels to the left.\n    geodetic_transform = ccrs.PlateCarree()._as_mpl_transform(ax)\n    text_transform = offset_copy(geodetic_transform, units='dots', x=+50, y=+15)\n\n    # Add text to the right of the symbol.\n    ax.text(global_sites[key][1]-0.1, \n            global_sites[key][0], \n            key, \n            verticalalignment='center', \n            horizontalalignment='right', \n            transform=text_transform,\n            bbox=dict(facecolor='sandybrown', \n            alpha=0.5, \n            boxstyle='round'))\n    \n# update the title of the display\nax.set_title(np.datetime_as_string(ds_merged['valid_time'].isel(time=15).data, unit='s').replace(\"T\", \" - \") + \n             \"Z\\n\" + \"Radar Derived 1-Hr QPE - MRMS\")\n\n# ----------------------------\n# Display the Multisensor QPE\n# ----------------------------\n## subset the data\nax1 = fig.add_subplot(1, 3, 2, projection=ccrs.PlateCarree())\nds_merged.isel(time=15).multisensor_qpe_1hr.plot(transform=ccrs.PlateCarree(),\n                                                 ax=ax1,\n                                                 cmap=\"ChaseSpectral\",\n                                                 vmin=da_min,\n                                                 vmax=da_max,\n                                                 cbar_kwargs={\"location\" : \"bottom\"})\n\n# Add some various map elements to the plot to make it recognizable.\nax1.add_feature(cfeature.LAND)\nax1.add_feature(cfeature.OCEAN)\nax1.add_feature(cfeature.BORDERS)\nax1.add_image(tiler, 12, zorder=1, alpha=0.55)\nax1.gridlines(draw_labels=True)\n\n# Set plot bounds\nax1.set_extent(bnf_domain)\n\n# add in crosshairs to indicate the lat/lon slices\nax1.axhline(y=global_sites[\"M1\"][0], color=\"black\", linestyle=\"--\")\nax1.axvline(x=global_sites[\"M1\"][1], color=\"red\", linestyle=\"--\")\n\n# Display the location of the BNF Supplementary Site\nfor key in global_sites:\n    # Add a marker for the BNF sites.\n    ax1.plot(global_sites[key][1], \n            global_sites[key][0], \n            marker='o', \n            color='black', \n            markersize=10, \n            alpha=0.7, \n            transform=ccrs.PlateCarree())\n\n    # Use the cartopy interface to create a matplotlib transform object\n    # for the Geodetic coordinate system. We will use this along with\n    # matplotlib's offset_copy function to define a coordinate system which\n    # translates the text by 25 pixels to the left.\n    geodetic_transform = ccrs.PlateCarree()._as_mpl_transform(ax1)\n    text_transform = offset_copy(geodetic_transform, units='dots', x=+50, y=+15)\n\n\n    # Add text to the right of the site marker.\n    ax1.text(global_sites[key][1]-0.1, \n             global_sites[key][0], \n             key, \n             verticalalignment='center', \n             horizontalalignment='right', \n             transform=text_transform,\n             bbox=dict(facecolor='sandybrown', \n             alpha=0.5, \n             boxstyle='round')\n    )\n    \n# update the title of the display\nax1.set_title(np.datetime_as_string(ds_merged['valid_time'].isel(time=15).data, unit='s').replace(\"T\", \" - \") + \n             \"Z\\n\" + \"Multisensor 1-Hr QPE - Pass 1\")\n\n# ----------------------------\n# Display the QPE Difference\n# ----------------------------\n## subset the data\nax3 = fig.add_subplot(1, 3, 3, projection=ccrs.PlateCarree())\nds_merged.isel(time=15).multisensor_qpe_pass2.plot(transform=ccrs.PlateCarree(),\n                                                   ax=ax3,\n                                                   cmap=\"ChaseSpectral\",\n                                                   vmin=da_min,\n                                                   vmax=da_max,\n                                                   cbar_kwargs={\"location\" : \"bottom\"})\n\n# Add some various map elements to the plot to make it recognizable.\nax3.add_feature(cfeature.LAND)\nax3.add_feature(cfeature.OCEAN)\nax3.add_feature(cfeature.BORDERS)\nax3.add_image(tiler, 12, zorder=1, alpha=0.55)\nax3.gridlines(draw_labels=True)\n\n# Set plot bounds\nax3.set_extent(bnf_domain)\n\n# add in crosshairs to indicate the lat/lon slices\nax3.axhline(y=global_sites[\"M1\"][0], color=\"black\", linestyle=\"--\")\nax3.axvline(x=global_sites[\"M1\"][1], color=\"red\", linestyle=\"--\")\n\n# Display the location of the BNF Supplementary Sites\nfor key in global_sites:\n    # Add a marker for the BNF sites.\n    ax3.plot(global_sites[key][1], \n            global_sites[key][0], \n            marker='o', \n            color='black', \n            markersize=10, \n            alpha=0.7, \n            transform=ccrs.PlateCarree())\n\n    # Use the cartopy interface to create a matplotlib transform object\n    # for the Geodetic coordinate system. We will use this along with\n    # matplotlib's offset_copy function to define a coordinate system which\n    # translates the text by 25 pixels to the left.\n    geodetic_transform = ccrs.PlateCarree()._as_mpl_transform(ax3)\n    text_transform = offset_copy(geodetic_transform, units='dots', x=+50, y=+15)\n\n    # Add text to the right of the site marker.\n    ax3.text(global_sites[key][1]-0.1, \n             global_sites[key][0], \n             key, \n             verticalalignment='center', \n             horizontalalignment='right', \n             transform=text_transform,\n             bbox=dict(facecolor='sandybrown', \n             alpha=0.5, \n             boxstyle='round'))\n    \n# update the title of the display\nax3.set_title(np.datetime_as_string(ds_merged['valid_time'].isel(time=15).data, unit='s').replace(\"T\", \" - \") + \n             \"Z\\n\" + \"MultiSensor 24-Hr QPE - Pass 2\");\n\n","type":"content","url":"/notebooks/bnf-mrms-qpe-hourly#create-a-multi-panel-qpe-display","position":23},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl2":"Summary"},"type":"lvl2","url":"/notebooks/bnf-mrms-qpe-hourly#summary","position":24},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl2":"Summary"},"content":"Within this notebook, we explored plotting a set of a field sites, accessing MRMS data, and visualizing a case over the ARM DOE Bankhead National Forest field site. We hope this serves as a framework for verification and understanding precipitation values in specific regions of interest.","type":"content","url":"/notebooks/bnf-mrms-qpe-hourly#summary","position":25},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl3":"What’s Next","lvl2":"Summary"},"type":"lvl3","url":"/notebooks/bnf-mrms-qpe-hourly#whats-next","position":26},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl3":"What’s Next","lvl2":"Summary"},"content":"We can extend this workflow by investigating timeseries for the various sites and looking into more robust verification techniques.","type":"content","url":"/notebooks/bnf-mrms-qpe-hourly#whats-next","position":27},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl2":"References"},"type":"lvl2","url":"/notebooks/bnf-mrms-qpe-hourly#references","position":28},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl2":"References"},"content":"Notebook originally modified from Joseph O’Brien\n\nNOAA Multi-Radar/Multi-Sensor System (MRMS) was accessed on from https://registry.opendata.aws/noaa-mrms-pds","type":"content","url":"/notebooks/bnf-mrms-qpe-hourly#references","position":29},{"hierarchy":{"lvl1":"Chapter 2: Case Study"},"type":"lvl1","url":"/notebooks/ch2-mar-2023-tornado-jdh","position":0},{"hierarchy":{"lvl1":"Chapter 2: Case Study"},"content":"","type":"content","url":"/notebooks/ch2-mar-2023-tornado-jdh","position":1},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl2":"March 24-27, 2023 Tornado Outbreak"},"type":"lvl2","url":"/notebooks/ch2-mar-2023-tornado-jdh#march-24-27-2023-tornado-outbreak","position":2},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl2":"March 24-27, 2023 Tornado Outbreak"},"content":"\n\n\n\nNext, title your notebook appropriately with a top-level Markdown header, # (see the very first cell above). Do not use this level header anywhere else in the notebook. Our book build process will use this title in the navbar, table of contents, etc. Keep it short, keep it descriptive.\n\nFollow this with a --- cell to visually distinguish the transition to the prerequisites section.\n\n\n\n","type":"content","url":"/notebooks/ch2-mar-2023-tornado-jdh#march-24-27-2023-tornado-outbreak","position":3},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl2":"Overview"},"type":"lvl2","url":"/notebooks/ch2-mar-2023-tornado-jdh#overview","position":4},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl2":"Overview"},"content":"The tornado outbreak of March 24–27, 2023 was a devastating multi-day severe weather event that swept across the Southern United States, particularly impacting Mississippi, Alabama, Tennessee, and Georgia. Triggered by a slow-moving upper-level trough interacting with moist, unstable air from the Gulf of Mexico, the outbreak produced 35 confirmed tornadoes, including a violent EF4 that tore through Rolling Fork, Midnight, and Silver City, Mississippi with peak winds of 195 mph. That tornado alone caused catastrophic damage and multiple fatalities, prompting tornado emergencies and widespread destruction.\nOver the four-day span, the system also unleashed damaging straight-line winds, large hail, and flooding. In total, the outbreak resulted in 23 fatalities (plus two from non-tornadic causes), over 230 injuries, and an estimated $1.9 billion in damage. The event was notable not only for its intensity but also for its geographic breadth and the prolonged nature of the severe weather threat.\n\nThis chapter explores MRMS data from this tornado outbreak, using:\n\nReflectivity\n\nRotation\n\nHail Swaths\n\nLocal Storm Reports\n\n\n\n","type":"content","url":"/notebooks/ch2-mar-2023-tornado-jdh#overview","position":5},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl2":"Imports"},"type":"lvl2","url":"/notebooks/ch2-mar-2023-tornado-jdh#imports","position":6},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl2":"Imports"},"content":"\n\nimport sys\nimport s3fs\nimport urllib\nimport tempfile\nimport gzip\nimport xarray as xr\nimport xarray\nimport io\nimport numpy as np\nimport cartopy\nimport datetime\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport cartopy.crs as ccrs\nimport cartopy.feature as cfeature\n\naws = s3fs.S3FileSystem(anon=True)\n\n\n\n","type":"content","url":"/notebooks/ch2-mar-2023-tornado-jdh#imports","position":7},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl2":"Build Map"},"type":"lvl2","url":"/notebooks/ch2-mar-2023-tornado-jdh#build-map","position":8},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl2":"Build Map"},"content":"","type":"content","url":"/notebooks/ch2-mar-2023-tornado-jdh#build-map","position":9},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl4":"This section uses Cartopy to build a map.","lvl2":"Build Map"},"type":"lvl4","url":"/notebooks/ch2-mar-2023-tornado-jdh#this-section-uses-cartopy-to-build-a-map","position":10},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl4":"This section uses Cartopy to build a map.","lvl2":"Build Map"},"content":"\n\n# Set up the map projection\nprojection = ccrs.LambertConformal(central_longitude=-96, central_latitude=39)\n\n# Create the figure and axes\nfig, ax = plt.subplots(figsize=(12, 8), subplot_kw={'projection': projection})\n\n# Set extent for CONUS (approximate)\nax.set_extent([-125, -66.5, 24, 50], crs=ccrs.PlateCarree())\n\n# Add geographic features\nax.add_feature(cfeature.STATES.with_scale('50m'), edgecolor='gray')\nax.add_feature(cfeature.BORDERS.with_scale('50m'), linestyle='--', edgecolor='black')\nax.add_feature(cfeature.COASTLINE.with_scale('50m'))\n\n# Optional: remove ticks\nax.set_xticks([])\nax.set_yticks([])\n\n# Add title\nplt.title(\"Blank Map\", fontsize=18)\n\nplt.show()\n\n","type":"content","url":"/notebooks/ch2-mar-2023-tornado-jdh#this-section-uses-cartopy-to-build-a-map","position":11},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl4":"We will be looking specifically at the tornado outbreak that occurred in Dixie Alley, so let’s set our extents specifically to Dixie Alley.","lvl2":"Build Map"},"type":"lvl4","url":"/notebooks/ch2-mar-2023-tornado-jdh#we-will-be-looking-specifically-at-the-tornado-outbreak-that-occurred-in-dixie-alley-so-lets-set-our-extents-specifically-to-dixie-alley","position":12},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl4":"We will be looking specifically at the tornado outbreak that occurred in Dixie Alley, so let’s set our extents specifically to Dixie Alley.","lvl2":"Build Map"},"content":"\n\nlon_min, lon_max = -96, -80\nlat_min, lat_max = 29, 38\n\n# Set up the map projection\nprojection = ccrs.LambertConformal(central_longitude=-88, central_latitude=34)\n\n# Create the figure and axes\nfig, ax = plt.subplots(figsize=(12, 8), subplot_kw={'projection': projection})\n\n# Set extent for CONUS (approximate)\nax.set_extent([lon_min, lon_max, lat_min, lat_max], crs=ccrs.PlateCarree())\n\n# Add geographic features\nax.add_feature(cfeature.STATES.with_scale('50m'), edgecolor='gray')\nax.add_feature(cfeature.BORDERS.with_scale('50m'), linestyle='--', edgecolor='black')\nax.add_feature(cfeature.COASTLINE.with_scale('50m'))\n\n# Optional: remove ticks\nax.set_xticks([])\nax.set_yticks([])\n\n# Add title\nplt.title(\"Blank Dixie Alley Map\", fontsize=18)\n\nplt.show()\n\n","type":"content","url":"/notebooks/ch2-mar-2023-tornado-jdh#we-will-be-looking-specifically-at-the-tornado-outbreak-that-occurred-in-dixie-alley-so-lets-set-our-extents-specifically-to-dixie-alley","position":13},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl4":"Great, now we can highlight our case study!","lvl2":"Build Map"},"type":"lvl4","url":"/notebooks/ch2-mar-2023-tornado-jdh#great-now-we-can-highlight-our-case-study","position":14},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl4":"Great, now we can highlight our case study!","lvl2":"Build Map"},"content":"\n\n\n\n","type":"content","url":"/notebooks/ch2-mar-2023-tornado-jdh#great-now-we-can-highlight-our-case-study","position":15},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl2":"Fetch Data"},"type":"lvl2","url":"/notebooks/ch2-mar-2023-tornado-jdh#fetch-data","position":16},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl2":"Fetch Data"},"content":"","type":"content","url":"/notebooks/ch2-mar-2023-tornado-jdh#fetch-data","position":17},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl4":"This section uses s3 to pull in the data from the AWS s3 server. Following data acquisition, the module uses xarray to filter the resulting DataArray for the size of the desired map.","lvl2":"Fetch Data"},"type":"lvl4","url":"/notebooks/ch2-mar-2023-tornado-jdh#this-section-uses-s3-to-pull-in-the-data-from-the-aws-s3-server-following-data-acquisition-the-module-uses-xarray-to-filter-the-resulting-dataarray-for-the-size-of-the-desired-map","position":18},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl4":"This section uses s3 to pull in the data from the AWS s3 server. Following data acquisition, the module uses xarray to filter the resulting DataArray for the size of the desired map.","lvl2":"Fetch Data"},"content":"","type":"content","url":"/notebooks/ch2-mar-2023-tornado-jdh#this-section-uses-s3-to-pull-in-the-data-from-the-aws-s3-server-following-data-acquisition-the-module-uses-xarray-to-filter-the-resulting-dataarray-for-the-size-of-the-desired-map","position":19},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl5":"For variable names, see link here.","lvl4":"This section uses s3 to pull in the data from the AWS s3 server. Following data acquisition, the module uses xarray to filter the resulting DataArray for the size of the desired map.","lvl2":"Fetch Data"},"type":"lvl5","url":"/notebooks/ch2-mar-2023-tornado-jdh#for-variable-names-see-link-here","position":20},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl5":"For variable names, see link here.","lvl4":"This section uses s3 to pull in the data from the AWS s3 server. Following data acquisition, the module uses xarray to filter the resulting DataArray for the size of the desired map.","lvl2":"Fetch Data"},"content":"\n\n# def fetch_mrms_data(variable: str, yyyymmdd: str, hh: str) -> xr.DataArray:\n#     \"\"\"\n#     Downloads and loads MRMS data from NOAA PDS.\n\n#     Parameters:\n#         variable (str): MRMS product name (e.g., 'MergedReflectivityQC').\n#         yyyymmdd (str): Date in YYYYMMDD format.\n#         hh (str): Hour in HH format (00–23 UTC).\n\n#     Returns:\n#         xarray.DataArray: Decoded MRMS data array.\n#     \"\"\"\n#     url = (\n#         f\"https://noaa-mrms-pds.s3.amazonaws.com/CONUS/{variable}/\"\n#         f\"{yyyymmdd}/MRMS_{variable}_{yyyymmdd}-{hh}0000.grib2.gz\"\n#     )\n\n#     response = urllib.request.urlopen(url)\n#     compressed_file = response.read()\n\n#     with tempfile.NamedTemporaryFile(suffix=\".grib2\") as f:\n#         f.write(gzip.decompress(compressed_file))\n#         data_in = xr.load_dataarray(f.name, engine='cfgrib', decode_timedelta=True)\n\n#     return data_in\n\n# def fetch_mrms_data(\n#     variable: str,\n#     yyyymmdd: str,\n#     hh: str,\n#     lon_min: float = None,\n#     lat_min: float = None,\n#     lon_max: float = None,\n#     lat_max: float = None\n# ) -> xr.DataArray:\n#     \"\"\"\n#     Downloads and loads MRMS data from NOAA PDS, with optional spatial filtering.\n\n#     Parameters:\n#         variable (str): MRMS product name (e.g., 'MergedReflectivityQC').\n#         yyyymmdd (str): Date in YYYYMMDD format.\n#         hh (str): Hour in HH format (00–23 UTC).\n#         lon_min, lat_min, lon_max, lat_max (float, optional): Bounding box for spatial subset. \n\n#     Returns:\n#         xarray.DataArray: Decoded MRMS data array, optionally subset by lat/lon.\n\n#     Example use: \n#         data = fetch_mrms_data('MergedReflectivityQC', '20230325', '02', lon_min=-96, lat_min=29, lon_max=-80, lat_max=38)\n#     \"\"\"\n#     url = (\n#         f\"https://noaa-mrms-pds.s3.amazonaws.com/CONUS/{variable}/\"\n#         f\"{yyyymmdd}/MRMS_{variable}_{yyyymmdd}-{hh}0000.grib2.gz\"\n#     )\n\n#     response = urllib.request.urlopen(url)\n#     compressed_file = response.read()\n\n#     with tempfile.NamedTemporaryFile(suffix=\".grib2\") as f:\n#         f.write(gzip.decompress(compressed_file))\n#         data_in = xr.load_dataarray(f.name, engine='cfgrib', decode_timedelta=True)\n\n#     # Optional spatial filtering\n#     if all(v is not None for v in [lon_min, lat_min, lon_max, lat_max]):\n#         data_in = data_in.sel(\n#             latitude=slice(lat_max, lat_min),  # descending order\n#             longitude=slice(360 - abs(lon_min), 360 - abs(lon_max))        \n#         )\n\n#     return data_in\n\ndef find_available_files(\n    variable: str,\n    yyyymmdd: str,\n    hh: str\n):\n    \n    files_list = []\n\n    available_files = aws.ls(f'noaa-mrms-pds/CONUS/{variable}/{yyyymmdd}/', refresh=True)\n    for file in available_files:\n        file_hour = file[-15:-13]\n        if file_hour == hh:\n            files_list.append(file)\n\n    if len(files_list) == 0:\n        raise ValueError(f\"No files found for {variable} on {yyyymmdd} at hour {hh}.\")\n    else:    \n        return files_list\n\ndef fetch_mrms_data(    \n    file: str,\n    lon_min: float = None,\n    lat_min: float = None,\n    lon_max: float = None,\n    lat_max: float = None\n):\n    url = (f\"https://noaa-mrms-pds.s3.amazonaws.com/{file[14:]}\")\n    response = urllib.request.urlopen(url)\n    compressed_file = response.read()        \n    with tempfile.NamedTemporaryFile(suffix=\".grib2\") as f:\n        f.write(gzip.decompress(compressed_file))\n        data_in = xr.load_dataarray(f.name, engine='cfgrib', decode_timedelta=True)\n\n    # Optional spatial filtering\n    if all(v is not None for v in [lon_min, lat_min, lon_max, lat_max]):\n        data_in = data_in.sel(\n            latitude=slice(lat_max, lat_min),  # descending order\n            longitude=slice(360 - abs(lon_min), 360 - abs(lon_max))        \n        )\n\n    return data_in\n\n# response = urllib.request.urlopen(\"https://noaa-mrms-pds.s3.amazonaws.com/CONUS/CREF_1HR_MAX_00.50/20230325/MRMS_CREF_1HR_MAX_00.50_20230325-010000.grib2.gz\")\n\n# compressed_file = response.read()\n\n# with tempfile.NamedTemporaryFile(suffix=\".grib2\") as f:\n#             f.write(gzip.decompress(compressed_file))\n#             data_in = xr.load_dataarray(f.name, engine='cfgrib', decode_timedelta=True)\n\n\n\n","type":"content","url":"/notebooks/ch2-mar-2023-tornado-jdh#for-variable-names-see-link-here","position":21},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl2":"Case Study - March 24, 2023"},"type":"lvl2","url":"/notebooks/ch2-mar-2023-tornado-jdh#case-study-march-24-2023","position":22},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl2":"Case Study - March 24, 2023"},"content":"","type":"content","url":"/notebooks/ch2-mar-2023-tornado-jdh#case-study-march-24-2023","position":23},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl3":"Rolling Fork - Silver City, MS Tornado","lvl2":"Case Study - March 24, 2023"},"type":"lvl3","url":"/notebooks/ch2-mar-2023-tornado-jdh#rolling-fork-silver-city-ms-tornado","position":24},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl3":"Rolling Fork - Silver City, MS Tornado","lvl2":"Case Study - March 24, 2023"},"content":"","type":"content","url":"/notebooks/ch2-mar-2023-tornado-jdh#rolling-fork-silver-city-ms-tornado","position":25},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl3":"3/25/23 1z to 2z","lvl2":"Case Study - March 24, 2023"},"type":"lvl3","url":"/notebooks/ch2-mar-2023-tornado-jdh#id-3-25-23-1z-to-2z","position":26},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl3":"3/25/23 1z to 2z","lvl2":"Case Study - March 24, 2023"},"content":"\n\n# Lon mins and maxes for our projections:\nlon_min, lon_max = -96, -80\nlat_min, lat_max = 29, 38\n\n","type":"content","url":"/notebooks/ch2-mar-2023-tornado-jdh#id-3-25-23-1z-to-2z","position":27},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl3":"Maximum 1-Hour Composite Reflectivity","lvl2":"Case Study - March 24, 2023"},"type":"lvl3","url":"/notebooks/ch2-mar-2023-tornado-jdh#maximum-1-hour-composite-reflectivity","position":28},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl3":"Maximum 1-Hour Composite Reflectivity","lvl2":"Case Study - March 24, 2023"},"content":"","type":"content","url":"/notebooks/ch2-mar-2023-tornado-jdh#maximum-1-hour-composite-reflectivity","position":29},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl5":"The MRMS Max 1-Hour Composite Reflectivity product represents the highest reflectivity value observed within the past hour across all radar scans, providing a time-integrated view of storm intensity. It helps forecasters identify areas of persistent or intense convection, especially useful for tracking severe weather like hail or heavy rainfall. This product is derived from a seamless mosaic of multiple radars, quality-controlled to remove non-meteorological artifacts.","lvl3":"Maximum 1-Hour Composite Reflectivity","lvl2":"Case Study - March 24, 2023"},"type":"lvl5","url":"/notebooks/ch2-mar-2023-tornado-jdh#the-mrms-max-1-hour-composite-reflectivity-product-represents-the-highest-reflectivity-value-observed-within-the-past-hour-across-all-radar-scans-providing-a-time-integrated-view-of-storm-intensity-it-helps-forecasters-identify-areas-of-persistent-or-intense-convection-especially-useful-for-tracking-severe-weather-like-hail-or-heavy-rainfall-this-product-is-derived-from-a-seamless-mosaic-of-multiple-radars-quality-controlled-to-remove-non-meteorological-artifacts","position":30},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl5":"The MRMS Max 1-Hour Composite Reflectivity product represents the highest reflectivity value observed within the past hour across all radar scans, providing a time-integrated view of storm intensity. It helps forecasters identify areas of persistent or intense convection, especially useful for tracking severe weather like hail or heavy rainfall. This product is derived from a seamless mosaic of multiple radars, quality-controlled to remove non-meteorological artifacts.","lvl3":"Maximum 1-Hour Composite Reflectivity","lvl2":"Case Study - March 24, 2023"},"content":"\n\n#### March 24, 2023 - Rolling Fork - Silver City, MS Tornado -- EF4, 71 minutes long, est winds 195 mph\n## 3/25/23 1z to 2z, so we'll grab two hours of data shortly\n\n#Grab 2 hours of data for plotting\ncref1files = find_available_files('CREF_1HR_MAX_00.50', '20230325', '01')\ncref1z = fetch_mrms_data(cref1files[0])    \n\ncref2files = find_available_files('CREF_1HR_MAX_00.50', '20230325', '02')\ncref2z = fetch_mrms_data(cref2files[0])\n\n# Mask fill values for both datasets\nmasked1 = np.ma.masked_where(cref1z == -99.0, cref1z)\nmasked2 = np.ma.masked_where(cref2z == -99.0, cref2z)\n\n# Define bounds for Dixie Alley\nprojection = ccrs.LambertConformal(central_longitude=-88, central_latitude=34)\n\n# Create side-by-side subplots\nfig, axes = plt.subplots(\n    1, 2, figsize=(16, 8),\n    subplot_kw={'projection': projection},\n    gridspec_kw={'bottom': 0.2}  # leave room for shared colorbar\n)\n\nmeshes = []\nfor ax, masked, title in zip(axes, [masked1, masked2], [\"(a) 3/25/2023 @ 01z\", \"(b) 3/25/2023 @ 02z\"]):\n    ax.set_extent([lon_min, lon_max, lat_min, lat_max], crs=ccrs.PlateCarree())\n    ax.add_feature(cfeature.STATES.with_scale('50m'), edgecolor='gray')\n    ax.add_feature(cfeature.BORDERS.with_scale('50m'), linestyle='--', edgecolor='black')\n    ax.add_feature(cfeature.COASTLINE.with_scale('50m'))\n    \n    mesh = ax.pcolormesh(\n        cref2z.longitude, cref2z.latitude, masked,\n        cmap='turbo', transform=ccrs.PlateCarree(), shading='auto'\n    )\n    ax.set_title(title, fontsize=15)\n    meshes.append(mesh)\n\n# Add shared colorbar beneath both plots\ncbar_ax = fig.add_axes([0.25, 0.25, 0.5, 0.02])  # [left, bottom, width, height]\ncbar = fig.colorbar(meshes[0], cax=cbar_ax, orientation='horizontal')\ncbar.set_label('Reflectivity (dBZ)')\nplt.suptitle('Max 1HR Composite Reflectivity:', fontsize='20', x=0.5, y=0.85, horizontalalignment='center', verticalalignment='top')\n\nplt.show()\n\n","type":"content","url":"/notebooks/ch2-mar-2023-tornado-jdh#the-mrms-max-1-hour-composite-reflectivity-product-represents-the-highest-reflectivity-value-observed-within-the-past-hour-across-all-radar-scans-providing-a-time-integrated-view-of-storm-intensity-it-helps-forecasters-identify-areas-of-persistent-or-intense-convection-especially-useful-for-tracking-severe-weather-like-hail-or-heavy-rainfall-this-product-is-derived-from-a-seamless-mosaic-of-multiple-radars-quality-controlled-to-remove-non-meteorological-artifacts","position":31},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl3":"Surface Precip Rate","lvl2":"Case Study - March 24, 2023"},"type":"lvl3","url":"/notebooks/ch2-mar-2023-tornado-jdh#surface-precip-rate","position":32},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl3":"Surface Precip Rate","lvl2":"Case Study - March 24, 2023"},"content":"To describe Surface Precip Rate, there are three variables that can be used:","type":"content","url":"/notebooks/ch2-mar-2023-tornado-jdh#surface-precip-rate","position":33},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl4":"Surface Precipitation Rate Products","lvl3":"Surface Precip Rate","lvl2":"Case Study - March 24, 2023"},"type":"lvl4","url":"/notebooks/ch2-mar-2023-tornado-jdh#surface-precipitation-rate-products","position":34},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl4":"Surface Precipitation Rate Products","lvl3":"Surface Precip Rate","lvl2":"Case Study - March 24, 2023"},"content":"Variable Name\n\nDescription\n\nTemporal Resolution\n\nFilename Pattern\n\nInstantaneous PrecipRate\n\n- Estimates current rainfall intensity- Derived from dual-pol radar\n\n- Every 2 minutes\n\nPrecipRate_00.00\n\nMultiSensor QPE (Pass 1)\n\n- Combines radar and precip gauge data- Available in 1-pass and 2-pass versions- Used for hourly accumulation\n\nHourly (Pass 1 and Pass 2)\n\nMRMS_QPE_01H_Pass1_00.00\n\nRadarOnly QPE\n\n- Estimates surface rainfall rate using dual-polarization radar reflectivity.- Captures rapid changes in precipitation intensity at high temporal resolution.\n\n- Every 2 minutes - Available in 15 minute as well as (1, 3, 6, 12, 24, 48) hour intervals- QPE since 12z also available\n\nRadarOnly_QPE_01H_00.00\n\n","type":"content","url":"/notebooks/ch2-mar-2023-tornado-jdh#surface-precipitation-rate-products","position":35},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl3":"Instantaneous Precip Rate","lvl2":"Case Study - March 24, 2023"},"type":"lvl3","url":"/notebooks/ch2-mar-2023-tornado-jdh#instantaneous-precip-rate","position":36},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl3":"Instantaneous Precip Rate","lvl2":"Case Study - March 24, 2023"},"content":"\n\nprecip1files= find_available_files('PrecipRate_00.00', '20230325', '01') # Precip Rate\nprecip_1z = fetch_mrms_data(precip1files[0]) \nprecip2files = find_available_files('PrecipRate_00.00', '20230325', '02')\nprecip_2z = fetch_mrms_data(precip2files[0])\nmasked1 = np.ma.masked_where(precip_1z <= 0, precip_1z)\nmasked2 = np.ma.masked_where(precip_2z <= 0, precip_2z)\n\n# Define bounds for Dixie Alley\nprojection = ccrs.LambertConformal(central_longitude=-88, central_latitude=34)\n\n# Create side-by-side subplots\nfig, axes = plt.subplots(\n    1, 2, figsize=(16, 8),\n    subplot_kw={'projection': projection},\n    gridspec_kw={'bottom': 0.2}  # leave room for shared colorbar\n)\n\nmeshes = []\nfor ax, masked, title in zip(axes, [masked1, masked2], [\"(a) 3/25/2023 @ 01z\", \"(b) 3/25/2023 @ 02z\"]):\n    ax.set_extent([lon_min, lon_max, lat_min, lat_max], crs=ccrs.PlateCarree())\n    ax.add_feature(cfeature.STATES.with_scale('50m'), edgecolor='gray')\n    ax.add_feature(cfeature.BORDERS.with_scale('50m'), linestyle='--', edgecolor='black')\n    ax.add_feature(cfeature.COASTLINE.with_scale('50m'))\n    \n    mesh = ax.pcolormesh(\n        precip_1z.longitude, precip_2z.latitude, masked,\n        cmap='turbo', transform=ccrs.PlateCarree(), shading='auto'\n    )\n    ax.set_title(title, fontsize=15)\n    meshes.append(mesh)\n\n# Add shared colorbar beneath both plots\ncbar_ax = fig.add_axes([0.25, 0.25, 0.5, 0.02])  # [left, bottom, width, height]\ncbar = fig.colorbar(meshes[0], cax=cbar_ax, orientation='horizontal')\ncbar.set_label('Precipitation (mm)')\nplt.suptitle('Instantaneous Precipitation', fontsize='20', x=0.5, y=0.85, horizontalalignment='center', verticalalignment='top')\n\nplt.show()\n\n\n\n","type":"content","url":"/notebooks/ch2-mar-2023-tornado-jdh#instantaneous-precip-rate","position":37},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl3":"MultiSensorQPE - 1 Hour - Pass 1","lvl2":"Case Study - March 24, 2023"},"type":"lvl3","url":"/notebooks/ch2-mar-2023-tornado-jdh#multisensorqpe-1-hour-pass-1","position":38},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl3":"MultiSensorQPE - 1 Hour - Pass 1","lvl2":"Case Study - March 24, 2023"},"content":"\n\n# MultiSensor_QPE_01H_Pass1_00.00\nQPE1files = find_available_files('MultiSensor_QPE_01H_Pass1_00.00', '20230325', '01') # QPE: Quantified Precip Estimation - Offered hourly.\nQPE_1z = fetch_mrms_data(QPE1files[0]) \nQPE2files = find_available_files('MultiSensor_QPE_01H_Pass1_00.00', '20230325', '02')\nQPE_2z = fetch_mrms_data(QPE2files[0])\nmasked1 = np.ma.masked_where(QPE_1z <= 0, QPE_1z)\nmasked2 = np.ma.masked_where(QPE_2z <= 0, QPE_2z)\n\n# Define bounds for Dixie Alley\nprojection = ccrs.LambertConformal(central_longitude=-88, central_latitude=34)\n\n# Create side-by-side subplots\nfig, axes = plt.subplots(\n    1, 2, figsize=(16, 8),\n    subplot_kw={'projection': projection},\n    gridspec_kw={'bottom': 0.2}  # leave room for shared colorbar\n)\n\nmeshes = []\nfor ax, masked, title in zip(axes, [masked1, masked2], [\"(a) 3/25/2023 @ 01z\", \"(b) 3/25/2023 @ 02z\"]):\n    ax.set_extent([lon_min, lon_max, lat_min, lat_max], crs=ccrs.PlateCarree())\n    ax.add_feature(cfeature.STATES.with_scale('50m'), edgecolor='gray')\n    ax.add_feature(cfeature.BORDERS.with_scale('50m'), linestyle='--', edgecolor='black')\n    ax.add_feature(cfeature.COASTLINE.with_scale('50m'))\n    \n    mesh = ax.pcolormesh(\n        QPE_1z.longitude, QPE_2z.latitude, masked,\n        cmap='turbo', transform=ccrs.PlateCarree(), shading='auto'\n    )\n    ax.set_title(title, fontsize=15)\n    meshes.append(mesh)\n\n# Add shared colorbar beneath both plots\ncbar_ax = fig.add_axes([0.25, 0.25, 0.5, 0.02])  # [left, bottom, width, height]\ncbar = fig.colorbar(meshes[0], cax=cbar_ax, orientation='horizontal')\ncbar.set_label('Precipitation (mm)')\nplt.suptitle('Multi-Sensor Quantified Precipitation Estimate (Pass 1):', fontsize='20', x=0.5, y=0.85, horizontalalignment='center', verticalalignment='top')\n\nplt.show()\n\n","type":"content","url":"/notebooks/ch2-mar-2023-tornado-jdh#multisensorqpe-1-hour-pass-1","position":39},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl3":"MultiSensorQPE - 1 Hour - Pass 2","lvl2":"Case Study - March 24, 2023"},"type":"lvl3","url":"/notebooks/ch2-mar-2023-tornado-jdh#multisensorqpe-1-hour-pass-2","position":40},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl3":"MultiSensorQPE - 1 Hour - Pass 2","lvl2":"Case Study - March 24, 2023"},"content":"\n\n# MultiSensor_QPE_01H_Pass2_00.00\nQPE1zp2files = find_available_files('MultiSensor_QPE_01H_Pass2_00.00', '20230325', '01') # QPE: Quantified Precip Estimation - last hour, 2nd pass\nQPE_1z_p2 = fetch_mrms_data(QPE1zp2files[0]) \nQPE2files = find_available_files('MultiSensor_QPE_01H_Pass2_00.00', '20230325', '02')\nQPE_2z_p2 = fetch_mrms_data(QPE2files[0])\nmasked1 = np.ma.masked_where(QPE_1z_p2 <= 0, QPE_1z_p2)\nmasked2 = np.ma.masked_where(QPE_2z_p2 <= 0, QPE_2z_p2)\n\n# Define bounds for Dixie Alley\nprojection = ccrs.LambertConformal(central_longitude=-88, central_latitude=34)\n\n# Create side-by-side subplots\nfig, axes = plt.subplots(\n    1, 2, figsize=(16, 8),\n    subplot_kw={'projection': projection},\n    gridspec_kw={'bottom': 0.2}  # leave room for shared colorbar\n)\n\nmeshes = []\nfor ax, masked, title in zip(axes, [masked1, masked2], [\"(a) 3/25/2023 @ 01z\", \"(b) 3/25/2023 @ 02z\"]):\n    ax.set_extent([lon_min, lon_max, lat_min, lat_max], crs=ccrs.PlateCarree())\n    ax.add_feature(cfeature.STATES.with_scale('50m'), edgecolor='gray')\n    ax.add_feature(cfeature.BORDERS.with_scale('50m'), linestyle='--', edgecolor='black')\n    ax.add_feature(cfeature.COASTLINE.with_scale('50m'))\n    \n    mesh = ax.pcolormesh(\n        QPE_1z_p2.longitude, QPE_2z_p2.latitude, masked,\n        cmap='turbo', transform=ccrs.PlateCarree(), shading='auto'\n    )\n    ax.set_title(title, fontsize=15)\n    meshes.append(mesh)\n\n# Add shared colorbar beneath both plots\ncbar_ax = fig.add_axes([0.25, 0.25, 0.5, 0.02])  # [left, bottom, width, height]\ncbar = fig.colorbar(meshes[0], cax=cbar_ax, orientation='horizontal')\ncbar.set_label('Precipitation (mm)')\nplt.suptitle('Multi-Sensor Quantified Precipitation Estimate (Pass 2):', fontsize='20', x=0.5, y=0.85, horizontalalignment='center', verticalalignment='top')\n\nplt.show()\n\n","type":"content","url":"/notebooks/ch2-mar-2023-tornado-jdh#multisensorqpe-1-hour-pass-2","position":41},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl3":"Radar Only QPE - Last Hour","lvl2":"Case Study - March 24, 2023"},"type":"lvl3","url":"/notebooks/ch2-mar-2023-tornado-jdh#radar-only-qpe-last-hour","position":42},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl3":"Radar Only QPE - Last Hour","lvl2":"Case Study - March 24, 2023"},"content":"\n\nRQPE1files = find_available_files('RadarOnly_QPE_01H_00.00', '20230325', '01') # RadarOnly_QPE: Radar Only Quantified Precip Estimation - last hour\nRQPE_1z = fetch_mrms_data(RQPE1files[0])\nRQPE2files = find_available_files('RadarOnly_QPE_01H_00.00', '20230325', '02')\nRQPE_2z = fetch_mrms_data(RQPE2files[0])\nmasked1 = np.ma.masked_where(RQPE_1z <= 0, RQPE_1z)\nmasked2 = np.ma.masked_where(RQPE_2z <= 0, RQPE_2z)\n\n# Define bounds for Dixie Alley\nprojection = ccrs.LambertConformal(central_longitude=-88, central_latitude=34)\n\n# Create side-by-side subplots\nfig, axes = plt.subplots(\n    1, 2, figsize=(16, 8),\n    subplot_kw={'projection': projection},\n    gridspec_kw={'bottom': 0.2}  # leave room for shared colorbar\n)\n\nmeshes = []\nfor ax, masked, title in zip(axes, [masked1, masked2], [\"(a) 3/25/2023 @ 01z\", \"(b) 3/25/2023 @ 02z\"]):\n    ax.set_extent([lon_min, lon_max, lat_min, lat_max], crs=ccrs.PlateCarree())\n    ax.add_feature(cfeature.STATES.with_scale('50m'), edgecolor='gray')\n    ax.add_feature(cfeature.BORDERS.with_scale('50m'), linestyle='--', edgecolor='black')\n    ax.add_feature(cfeature.COASTLINE.with_scale('50m'))\n    \n    mesh = ax.pcolormesh(\n        RQPE_1z.longitude, RQPE_2z.latitude, masked,\n        cmap='turbo', transform=ccrs.PlateCarree(), shading='auto'\n    )\n    ax.set_title(title, fontsize=15)\n    meshes.append(mesh)\n\n# Add shared colorbar beneath both plots\ncbar_ax = fig.add_axes([0.25, 0.25, 0.5, 0.02])  # [left, bottom, width, height]\ncbar = fig.colorbar(meshes[0], cax=cbar_ax, orientation='horizontal')\ncbar.set_label('Precipitation (mm)')\nplt.suptitle('Radar Only Quantified Precipitation Estimate:', fontsize='20', x=0.5, y=0.85, horizontalalignment='center', verticalalignment='top')\n\nplt.show()\n\n\n\n","type":"content","url":"/notebooks/ch2-mar-2023-tornado-jdh#radar-only-qpe-last-hour","position":43},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl2":"Rotation"},"type":"lvl2","url":"/notebooks/ch2-mar-2023-tornado-jdh#rotation","position":44},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl2":"Rotation"},"content":"","type":"content","url":"/notebooks/ch2-mar-2023-tornado-jdh#rotation","position":45},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl3":"These rotation products can be combined to assess both the intensity and persistence of storm-scale rotation across multiple atmospheric layers and time scales. By layering instantaneous azimuthal shear with rotation tracks—especially ML-enhanced versions—forecasters and researchers can better identify evolving mesocyclones, discriminate between transient and sustained rotation, and refine environmental risk assessments for severe weather and turbulence.","lvl2":"Rotation"},"type":"lvl3","url":"/notebooks/ch2-mar-2023-tornado-jdh#these-rotation-products-can-be-combined-to-assess-both-the-intensity-and-persistence-of-storm-scale-rotation-across-multiple-atmospheric-layers-and-time-scales-by-layering-instantaneous-azimuthal-shear-with-rotation-tracks-especially-ml-enhanced-versions-forecasters-and-researchers-can-better-identify-evolving-mesocyclones-discriminate-between-transient-and-sustained-rotation-and-refine-environmental-risk-assessments-for-severe-weather-and-turbulence","position":46},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl3":"These rotation products can be combined to assess both the intensity and persistence of storm-scale rotation across multiple atmospheric layers and time scales. By layering instantaneous azimuthal shear with rotation tracks—especially ML-enhanced versions—forecasters and researchers can better identify evolving mesocyclones, discriminate between transient and sustained rotation, and refine environmental risk assessments for severe weather and turbulence.","lvl2":"Rotation"},"content":"Variable\n\nDescription\n\nTemporal Resolution\n\nFilename Pattern\n\nMerged AzShear 0-2km AGL\n\nLow-level azimuthal shear (0–2 km AGL); highlights near-surface rotation.\n\nInstantaneous\n\nMergedAzShear_0-2kmAGL_00.50\n\nMerged Az Shear 3-6km AGL\n\nMid-level azimuthal shear (3–6 km AGL); captures elevated storm rotation.\n\nInstantaneous\n\nMergedAzShear_3-6kmAGL_00.50\n\nRotation Track 30min\n\n30-min accumulation of low-level rotation; useful for short-term tracking.\n\n30 minutes\n\nRotationTrack30min_00.50\n\nRotation Track 60min\n\n60-min accumulation of low-level rotation; highlights sustained activity.\n\n60 minutes\n\nRotationTrack60min_00.50\n\nRotation Track ML 30min\n\nML-enhanced 30-min rotation track; filters noise, boosts confidence.\n\n30 minutes\n\nRotationTrackML30min_00.50\n\nRotation Track ML 60min\n\nML-enhanced 60-min rotation track; detects short-lived intense rotation.\n\n60 minutes\n\nRotationTrackML60min_00.50\n\n# Naming convention is completely different! Would have to completely rewrite my method to get this - get plots similar to those above\n\n# MergedAzShear_0-2kmAGL_00.50\n\n\n\n\n# MergedAzShear_3-6kmAGL_00.50 -  for the sake of time, hold on this\n\n# RotationTrack30min_00.50 -  for the sake of time, hold on this\n# RotationTrack60min_00.50 -  for the sake of time, hold on this\n# RotationTrackML60min_00.50 -  for the sake of time, hold on this\n# RotationTrackML30min_00.50 -  for the sake of time, hold on this\n\n\n\n","type":"content","url":"/notebooks/ch2-mar-2023-tornado-jdh#these-rotation-products-can-be-combined-to-assess-both-the-intensity-and-persistence-of-storm-scale-rotation-across-multiple-atmospheric-layers-and-time-scales-by-layering-instantaneous-azimuthal-shear-with-rotation-tracks-especially-ml-enhanced-versions-forecasters-and-researchers-can-better-identify-evolving-mesocyclones-discriminate-between-transient-and-sustained-rotation-and-refine-environmental-risk-assessments-for-severe-weather-and-turbulence","position":47},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl2":"Hail Swaths"},"type":"lvl2","url":"/notebooks/ch2-mar-2023-tornado-jdh#hail-swaths","position":48},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl2":"Hail Swaths"},"content":"\n\n# MESH - Maximum Expected Size of Hail - for the sake of time, hold on this\n# SHI_00.50 - Severe Hail Index\n# VII_00.50 - Vergically Integrated Ice\n# POSH_00.50\n\n\n\n","type":"content","url":"/notebooks/ch2-mar-2023-tornado-jdh#hail-swaths","position":49},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl2":"Storm Intensity - Vertically Integrated Liquid"},"type":"lvl2","url":"/notebooks/ch2-mar-2023-tornado-jdh#storm-intensity-vertically-integrated-liquid","position":50},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl2":"Storm Intensity - Vertically Integrated Liquid"},"content":"\n\n# VIL_00.50\t\t\n# VIL_Density_00.50\t\t\t\n# VIL_Max_120min_00.50\n\n\n\n","type":"content","url":"/notebooks/ch2-mar-2023-tornado-jdh#storm-intensity-vertically-integrated-liquid","position":51},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl2":"Summary"},"type":"lvl2","url":"/notebooks/ch2-mar-2023-tornado-jdh#summary","position":52},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl2":"Summary"},"content":"Add one final --- marking the end of your body of content, and then conclude with a brief single paragraph summarizing at a high level the key pieces that were learned and how they tied to your objectives. Look to reiterate what the most important takeaways were.","type":"content","url":"/notebooks/ch2-mar-2023-tornado-jdh#summary","position":53},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl3":"What’s next?","lvl2":"Summary"},"type":"lvl3","url":"/notebooks/ch2-mar-2023-tornado-jdh#whats-next","position":54},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl3":"What’s next?","lvl2":"Summary"},"content":"Let Jupyter book tie this to the next (sequential) piece of content that people could move on to down below and in the sidebar. However, if this page uniquely enables your reader to tackle other nonsequential concepts throughout this book, or even external content, link to it here!\n\n","type":"content","url":"/notebooks/ch2-mar-2023-tornado-jdh#whats-next","position":55},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl2":"Resources and references"},"type":"lvl2","url":"/notebooks/ch2-mar-2023-tornado-jdh#resources-and-references","position":56},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl2":"Resources and references"},"content":"Finally, be rigorous in your citations and references as necessary. Give credit where credit is due. Also, feel free to link to relevant external material, further reading, documentation, etc. Then you’re done! Give yourself a quick review, a high five, and send us a pull request. A few final notes:\n\nKernel > Restart Kernel and Run All Cells... to confirm that your notebook will cleanly run from start to finish\n\nKernel > Restart Kernel and Clear All Outputs... before committing your notebook, our machines will do the heavy lifting\n\nTake credit! Provide author contact information if you’d like; if so, consider adding information here at the bottom of your notebook\n\nGive credit! Attribute appropriate authorship for referenced code, information, images, etc.\n\nOnly include what you’re legally allowed: no copyright infringement or plagiarism\n\nThank you for your contribution!","type":"content","url":"/notebooks/ch2-mar-2023-tornado-jdh#resources-and-references","position":57},{"hierarchy":{"lvl1":"MRMS Reflectivity Animation: July 4, 2025"},"type":"lvl1","url":"/notebooks/ch3-txfloods","position":0},{"hierarchy":{"lvl1":"MRMS Reflectivity Animation: July 4, 2025"},"content":"","type":"content","url":"/notebooks/ch3-txfloods","position":1},{"hierarchy":{"lvl1":"MRMS Reflectivity Animation: July 4, 2025","lvl2":"Overview"},"type":"lvl2","url":"/notebooks/ch3-txfloods#overview","position":2},{"hierarchy":{"lvl1":"MRMS Reflectivity Animation: July 4, 2025","lvl2":"Overview"},"content":"","type":"content","url":"/notebooks/ch3-txfloods#overview","position":3},{"hierarchy":{"lvl1":"MRMS Reflectivity Animation: July 4, 2025","lvl4":"This notebook walks through how to access, visualize, and animate low-level composite reflectivity data from the Multi-Radar/Multi-Sensor (MRMS) system.","lvl2":"Overview"},"type":"lvl4","url":"/notebooks/ch3-txfloods#this-notebook-walks-through-how-to-access-visualize-and-animate-low-level-composite-reflectivity-data-from-the-multi-radar-multi-sensor-mrms-system","position":4},{"hierarchy":{"lvl1":"MRMS Reflectivity Animation: July 4, 2025","lvl4":"This notebook walks through how to access, visualize, and animate low-level composite reflectivity data from the Multi-Radar/Multi-Sensor (MRMS) system.","lvl2":"Overview"},"content":"The case study focuses on the Central Texas flood event in July 2025, using reflectivity data hosted on AWS. The main steps include:\n\nSelecting and downloading MRMS data for specific timestamps\n\nCreating a static reflectivity map\n\nBuilding an animation to show reflectivity changes over time\n\nThis notebook is intended for students, forecasters, or researchers looking to explore radar visualization techniques or build familiarity with remote sensing workflows using Python.\n\n","type":"content","url":"/notebooks/ch3-txfloods#this-notebook-walks-through-how-to-access-visualize-and-animate-low-level-composite-reflectivity-data-from-the-multi-radar-multi-sensor-mrms-system","position":5},{"hierarchy":{"lvl1":"MRMS Reflectivity Animation: July 4, 2025","lvl3":"What is MRMS?","lvl2":"Overview"},"type":"lvl3","url":"/notebooks/ch3-txfloods#what-is-mrms","position":6},{"hierarchy":{"lvl1":"MRMS Reflectivity Animation: July 4, 2025","lvl3":"What is MRMS?","lvl2":"Overview"},"content":"The Multi-Radar/Multi-Sensor (MRMS) system is a set of real-time analysis products developed by NOAA’s National Severe Storms Laboratory (NSSL). It brings together data from:\n\nDozens of NEXRAD radars\n\nSurface observations\n\nSatellites\n\nLightning detection networks\n\nto create high-resolution snapshots of precipitation, severe weather, and related hazards.\n\nMRMS updates every 2.5 minutes and is commonly used in operational forecasting, hydrology, aviation, and research.","type":"content","url":"/notebooks/ch3-txfloods#what-is-mrms","position":7},{"hierarchy":{"lvl1":"MRMS Reflectivity Animation: July 4, 2025","lvl3":"Goal of This Notebook","lvl2":"Overview"},"type":"lvl3","url":"/notebooks/ch3-txfloods#goal-of-this-notebook","position":8},{"hierarchy":{"lvl1":"MRMS Reflectivity Animation: July 4, 2025","lvl3":"Goal of This Notebook","lvl2":"Overview"},"content":"The goal of this notebook is to walk through a simple, practical workflow for visualizing radar reflectivity data using Python. Specifically, we’ll:\n\nAccess MRMS Layer Composite Reflectivity Low data from AWS Open Data\n\nPlot a single reflectivity frame as a static map\n\nAnimate a 6-frame sequence from July 4, 2025, during the Central Texas flood event\n\nDemonstrate how to work with gridded radar data using open-source tools like MetPy, Cartopy, and xarray\n\n","type":"content","url":"/notebooks/ch3-txfloods#goal-of-this-notebook","position":9},{"hierarchy":{"lvl1":"MRMS Reflectivity Animation: July 4, 2025","lvl2":"Imports"},"type":"lvl2","url":"/notebooks/ch3-txfloods#imports","position":10},{"hierarchy":{"lvl1":"MRMS Reflectivity Animation: July 4, 2025","lvl2":"Imports"},"content":"below are the python packages that are used for this code\n\n# Core packages\nimport numpy as np\nimport numpy.ma as ma\nimport xarray as xr\n\n# Plotting\nimport matplotlib.pyplot as plt\nimport cartopy.crs as ccrs\nimport cartopy.feature as cfeature\nfrom metpy.plots import ctables  # For NWS reflectivity colormap\n\n# File handling (if you're downloading MRMS .grib2.gz files manually)\nimport urllib.request\nimport gzip\nimport tempfile\n\n# Animation\nfrom matplotlib.animation import ArtistAnimation\nfrom IPython.display import HTML  # To display the animation\n\n","type":"content","url":"/notebooks/ch3-txfloods#imports","position":11},{"hierarchy":{"lvl1":"MRMS Reflectivity Animation: July 4, 2025","lvl2":"Define Timestamps and Colormap"},"type":"lvl2","url":"/notebooks/ch3-txfloods#define-timestamps-and-colormap","position":12},{"hierarchy":{"lvl1":"MRMS Reflectivity Animation: July 4, 2025","lvl2":"Define Timestamps and Colormap"},"content":"To build the animation, we’ll use 6 hourly frames of MRMS data from the morning of July 4, 2025. Each timestamp matches a GRIB2 file available from the AWS MRMS archive.\n\nWe also define the standard NWS reflectivity colormap using MetPy, which gives us consistent color breaks every 5 dBZ which is a common setup for radar reflectivity plots.\n\n","type":"content","url":"/notebooks/ch3-txfloods#define-timestamps-and-colormap","position":13},{"hierarchy":{"lvl1":"MRMS Reflectivity Animation: July 4, 2025","lvl3":"Access and Load MRMS Data","lvl2":"Define Timestamps and Colormap"},"type":"lvl3","url":"/notebooks/ch3-txfloods#access-and-load-mrms-data","position":14},{"hierarchy":{"lvl1":"MRMS Reflectivity Animation: July 4, 2025","lvl3":"Access and Load MRMS Data","lvl2":"Define Timestamps and Colormap"},"content":"MRMS data is stored as .grib2.gz files on the AWS S3 public data bucket. Each file represents a single timestamp and product type.\n\nIn this step:\n\nWe use urllib.request.urlopen() to download the compressed file directly from AWS\n\nWe decompress it using Python’s built-in gzip module\n\nThen we load the GRIB2 file into an xarray.DataArray using the cfgrib engine\n\nThis approach lets us work with the data directly in Python without having to manually download or unzip anything ahead of time.\n\n# Define the URL to the compressed MRMS GRIB2 file for a specific timestamp\nurl = \"https://noaa-mrms-pds.s3.amazonaws.com/CONUS/LayerCompositeReflectivity_Low_00.50/20250704/MRMS_LayerCompositeReflectivity_Low_00.50_20250704-001040.grib2.gz\"\n\n# Download the file as bytes\nresponse = urllib.request.urlopen(url)\ncompressed_file = response.read()\n\n# Decompress and load into xarray using a temporary file\nwith tempfile.NamedTemporaryFile(suffix=\".grib2\") as f:\n    # Decompress the .gz content and write to temp file\n    f.write(gzip.decompress(compressed_file))\n\n    # Load GRIB2 data as an xarray DataArray\n    data_in = xr.load_dataarray(f.name, engine='cfgrib', decode_timedelta=True)\n\n\n\n","type":"content","url":"/notebooks/ch3-txfloods#access-and-load-mrms-data","position":15},{"hierarchy":{"lvl1":"MRMS Reflectivity Animation: July 4, 2025","lvl2":"Set Up Reflectivity Colormap and Extract Data"},"type":"lvl2","url":"/notebooks/ch3-txfloods#set-up-reflectivity-colormap-and-extract-data","position":16},{"hierarchy":{"lvl1":"MRMS Reflectivity Animation: July 4, 2025","lvl2":"Set Up Reflectivity Colormap and Extract Data"},"content":"This section gets the MRMS reflectivity data ready for plotting and builds a map to visualize it.\n\nColormap and Normalization:We use MetPy’s built-in NWSReflectivity colormap, which is designed for radar data in dBZ. The get_with_steps() function sets up color breaks every 5 dBZ — a common setup in operational radar displays.\n\nExtract Coordinates and Data:We pull out the longitude, latitude, and reflectivity values from the data array. If the coordinates are in 1D (which happens in some MRMS products), we convert them to 2D using np.meshgrid() so they work with the plotting function.\n\nMask Low Reflectivity Values:Reflectivity values below 5 dBZ are masked out with ma.masked_where() to remove light noise and clutter from the map.\n\nSet Up the Map:We create a static figure using matplotlib and Cartopy, with a PlateCarree projection centered over Texas. The domain is narrowed with set_extent() to focus on the region of interest.\n\nAdd Map Features:Coastlines, country borders, and U.S. state lines are added to give the plot geographic context.\n\nPlot the Reflectivity:The reflectivity field is plotted using pcolormesh() with our defined colormap and normalization. A horizontal colorbar is added to show the dBZ scale.\n\nFinal Touches:We include a plot title and display the final figure with \n\nplt.show().\n\nrefl_norm, refl_cmap = ctables.registry.get_with_steps('NWSReflectivity', 5, 5)\n\n# 2. Extract coords & data\nlons = data_in.longitude.values\nlats = data_in.latitude.values\nrefl = data_in.values\n\n# If coords are 1D, make them 2D\nif lons.ndim == 1 and lats.ndim == 1:\n    lons, lats = np.meshgrid(lons, lats)\n\n# 3. Plot\nfig = plt.figure(figsize=(10, 8))\nax = plt.axes(projection=ccrs.PlateCarree())\nax.set_extent([-106, -93, 25, 36], crs=ccrs.PlateCarree())\n\nax.add_feature(cfeature.COASTLINE, linewidth=1)\nax.add_feature(cfeature.BORDERS, linewidth=1)\nax.add_feature(cfeature.STATES, linewidth=0.5)\n\nmesh = ax.pcolormesh(\n    lons, lats, ma.masked_where(refl<5,refl),\n    cmap=refl_cmap,\n    norm=refl_norm,\n    transform=ccrs.PlateCarree()\n)\n\ncb = plt.colorbar(mesh, ax=ax, orientation='horizontal', pad=0.05, aspect=50)\ncb.set_label('Reflectivity (dBZ)')\n\nplt.title('MRMS Layer Composite Reflectivity – Texas', fontsize=14)\nplt.show()\n\n\nma.masked_where(refl<5,refl)\n\n","type":"content","url":"/notebooks/ch3-txfloods#set-up-reflectivity-colormap-and-extract-data","position":17},{"hierarchy":{"lvl1":"MRMS Reflectivity Animation: July 4, 2025","lvl3":"Select Timestamps and Animate Reflectivity","lvl2":"Set Up Reflectivity Colormap and Extract Data"},"type":"lvl3","url":"/notebooks/ch3-txfloods#select-timestamps-and-animate-reflectivity","position":18},{"hierarchy":{"lvl1":"MRMS Reflectivity Animation: July 4, 2025","lvl3":"Select Timestamps and Animate Reflectivity","lvl2":"Set Up Reflectivity Colormap and Extract Data"},"content":"This part of the notebook automates the process of pulling in multiple MRMS reflectivity files and creating an animation to show how low-level reflectivity changed over time.\n\nCheck for Available Timestamps:We define a time range from July 4 to July 7, 2025, and loop through it in 30-minute steps. For each time, we generate a file path from the AWS-hosted MRMS archive and try downloading it. If the file exists, we save that timestamp. For this demo, we stop after grabbing six valid files.\n\nSet Up the Map and Colormap:After collecting the timestamps, we build a static map using Cartopy (Plate Carree projection), focused on Texas and surrounding areas. We also apply the MetPy NWSReflectivity colormap and mask out any reflectivity values below 5 dBZ to clean up the visualization.\n\nDownload and Plot Each Frame:For each timestamp:\n\nThe corresponding .grib2.gz file is downloaded and decompressed.\n\nWe extract the reflectivity data and coordinates using xarray.\n\nIf the coordinate arrays are 1D, we convert them to 2D for plotting.\n\nThe reflectivity data is plotted with pcolormesh(), and we add a dynamic title showing the UTC time.\n\nEach frame (plot + title) is saved for the animation.\n\nBuild the Animation:We use ArtistAnimation from Matplotlib to stitch the frames together into an animation. plt.close(fig) is used beforehand to prevent Jupyter from displaying a static image under the animation.\n\nExport as a GIF:The finished animation is saved as a .gif using Pillow so it can be easily shared or embedded in a presentation.\n\nThe result is a short radar loop showing how reflectivity evolved during the early hours of July 4, 2025, which is a period tied to widespread heavy rain and flash flooding across Central Texas.\n\nfrom datetime import datetime, timedelta\n\n\nstart = datetime(2025, 7, 4, 0, 10, 40)\nend = datetime(2025, 7, 7, 0, 0, 0)\nstep = timedelta(minutes=30)\n\nvalid_timestamps = []\nt = start\n\nprint(\"Checking for available MRMS files...\\n\")\n\nwhile t <= end and len(valid_timestamps) < 6:\n    ts = t.strftime(\"%Y%m%d-%H%M%S\")\n    date_str = ts[:8]\n    url = (\n        f\"https://noaa-mrms-pds.s3.amazonaws.com/CONUS/LayerCompositeReflectivity_Low_00.50/\"\n        f\"{date_str}/MRMS_LayerCompositeReflectivity_Low_00.50_{ts}.grib2.gz\"\n    )\n    try:\n        resp = urllib.request.urlopen(url, timeout=5)\n        print(f\" Found: {ts}\")\n        valid_timestamps.append(ts)\n    except:\n        print(f\" Missing: {ts}\")\n    t += step\n\nprint(\"\\n Selected 6 timestamps:\")\nfor ts in valid_timestamps:\n    print(ts)\n\n\n# Define the 6 known working timestamps (one every hour)\ntimestamps = [\n    \"20250704-001040\",\n    \"20250704-011040\",\n    \"20250704-031040\",\n    \"20250704-054040\",\n    \"20250704-071040\",\n    \"20250704-091040\"\n]\n\n# Set up colormap and normalization for reflectivity\nrefl_norm, refl_cmap = ctables.registry.get_with_steps('NWSReflectivity', 5, 5)\n\n# Initialize animation container\nframes_six = []\n\n# Set up static map\nfig = plt.figure(figsize=(10, 8))\nax = plt.axes(projection=ccrs.PlateCarree())\nax.set_extent([-106, -93, 25, 36], crs=ccrs.PlateCarree())\nax.add_feature(cfeature.COASTLINE, linewidth=1)\nax.add_feature(cfeature.BORDERS, linewidth=1)\nax.add_feature(cfeature.STATES, linewidth=0.5)\n\n# Loop through timestamps and collect frames\nfor ts in timestamps:\n    print(f\"Loading {ts}...\")\n    try:\n        url = (\n            f\"https://noaa-mrms-pds.s3.amazonaws.com/CONUS/LayerCompositeReflectivity_Low_00.50/\"\n            f\"{ts[:8]}/MRMS_LayerCompositeReflectivity_Low_00.50_{ts}.grib2.gz\"\n        )\n        response = urllib.request.urlopen(url)\n        compressed_file = response.read()\n\n        with tempfile.NamedTemporaryFile(suffix=\".grib2\") as f:\n            f.write(gzip.decompress(compressed_file))\n            f.flush()\n            data_in = xr.load_dataarray(f.name, engine='cfgrib', decode_timedelta=True)\n\n        # Extract coordinates and reflectivity data\n        lons = data_in.longitude.values\n        lats = data_in.latitude.values\n        refl = data_in.values\n\n        if lons.ndim == 1 and lats.ndim == 1:\n            lons, lats = np.meshgrid(lons, lats)\n\n        # Plot single frame (no show)\n        mesh = ax.pcolormesh(\n            lons, lats, ma.masked_where(refl < 5, refl),\n            cmap=refl_cmap,\n            norm=refl_norm,\n            transform=ccrs.PlateCarree()\n        )\n\n        # Create a title text that updates with each frame\n        timestamp_label = f\"{ts[:4]}-{ts[4:6]}-{ts[6:8]} {ts[9:11]}:{ts[11:13]} UTC\"\n        title = ax.text(\n            0.5, 1.02,\n            f\"MRMS Low-Level Reflectivity (dBZ) – {timestamp_label}\",\n            transform=ax.transAxes,\n            ha=\"center\", va=\"bottom\", fontsize=14\n        )\n\n        # Save both mesh and title to animation frame\n        frames_six.append([mesh, title])\n\n    except Exception as e:\n        print(f\"Skipped {ts} → {e}\")\n        continue\n\n# Create and display an animation\nplt.close(fig)\nanim = ArtistAnimation(fig, frames_six, interval=500, blit=True)\nHTML(anim.to_jshtml())\n\nfrom matplotlib.animation import PillowWriter\n\n# Save animation as a .gif\nanim.save(\"mrms_reflectivity_animation.gif\", writer=PillowWriter(fps=2))\n\nprint(\"Animation saved as 'mrms_reflectivity_animation.gif'\")\n\n\n","type":"content","url":"/notebooks/ch3-txfloods#select-timestamps-and-animate-reflectivity","position":19},{"hierarchy":{"lvl1":"MRMS Reflectivity Animation: July 4, 2025","lvl2":"Reflectivity Animation: Summary"},"type":"lvl2","url":"/notebooks/ch3-txfloods#reflectivity-animation-summary","position":20},{"hierarchy":{"lvl1":"MRMS Reflectivity Animation: July 4, 2025","lvl2":"Reflectivity Animation: Summary"},"content":"We demonstrated how to access and animate low-level composite reflectivity data from the MRMS system using open-source Python tools. We focused on a short sequence from the July 4, 2025, Central Texas flood event to highlight how reflectivity features evolved.\n\nThis workflow is a flexible starting point for working with radar data, especially for case studies or quick visual diagnostics. The next section will continue building on this analysis with more approaches to explore the MRMS dataset!\n\n\n\n","type":"content","url":"/notebooks/ch3-txfloods#reflectivity-animation-summary","position":21},{"hierarchy":{"lvl1":"MRMS Reflectivity Animation: July 4, 2025","lvl3":"Another content subsection","lvl2":"Reflectivity Animation: Summary"},"type":"lvl3","url":"/notebooks/ch3-txfloods#another-content-subsection","position":22},{"hierarchy":{"lvl1":"MRMS Reflectivity Animation: July 4, 2025","lvl3":"Another content subsection","lvl2":"Reflectivity Animation: Summary"},"content":"Keep up the good work! A note, try to avoid using code comments as narrative, and instead let them only exist as brief clarifications where necessary.\n\n","type":"content","url":"/notebooks/ch3-txfloods#another-content-subsection","position":23},{"hierarchy":{"lvl1":"MRMS Reflectivity Animation: July 4, 2025","lvl2":"Your second content section"},"type":"lvl2","url":"/notebooks/ch3-txfloods#your-second-content-section","position":24},{"hierarchy":{"lvl1":"MRMS Reflectivity Animation: July 4, 2025","lvl2":"Your second content section"},"content":"Here we can move on to our second objective, and we can demonstrate...\n\n","type":"content","url":"/notebooks/ch3-txfloods#your-second-content-section","position":25},{"hierarchy":{"lvl1":"MRMS Reflectivity Animation: July 4, 2025","lvl3":"A subsection to the second section","lvl2":"Your second content section"},"type":"lvl3","url":"/notebooks/ch3-txfloods#a-subsection-to-the-second-section","position":26},{"hierarchy":{"lvl1":"MRMS Reflectivity Animation: July 4, 2025","lvl3":"A subsection to the second section","lvl2":"Your second content section"},"content":"","type":"content","url":"/notebooks/ch3-txfloods#a-subsection-to-the-second-section","position":27},{"hierarchy":{"lvl1":"MRMS Reflectivity Animation: July 4, 2025","lvl4":"a quick demonstration","lvl3":"A subsection to the second section","lvl2":"Your second content section"},"type":"lvl4","url":"/notebooks/ch3-txfloods#a-quick-demonstration","position":28},{"hierarchy":{"lvl1":"MRMS Reflectivity Animation: July 4, 2025","lvl4":"a quick demonstration","lvl3":"A subsection to the second section","lvl2":"Your second content section"},"content":"","type":"content","url":"/notebooks/ch3-txfloods#a-quick-demonstration","position":29},{"hierarchy":{"lvl1":"MRMS Reflectivity Animation: July 4, 2025","lvl5":"of further and further","lvl4":"a quick demonstration","lvl3":"A subsection to the second section","lvl2":"Your second content section"},"type":"lvl5","url":"/notebooks/ch3-txfloods#of-further-and-further","position":30},{"hierarchy":{"lvl1":"MRMS Reflectivity Animation: July 4, 2025","lvl5":"of further and further","lvl4":"a quick demonstration","lvl3":"A subsection to the second section","lvl2":"Your second content section"},"content":"","type":"content","url":"/notebooks/ch3-txfloods#of-further-and-further","position":31},{"hierarchy":{"lvl1":"MRMS Reflectivity Animation: July 4, 2025","lvl6":"header levels","lvl5":"of further and further","lvl4":"a quick demonstration","lvl3":"A subsection to the second section","lvl2":"Your second content section"},"type":"lvl6","url":"/notebooks/ch3-txfloods#header-levels","position":32},{"hierarchy":{"lvl1":"MRMS Reflectivity Animation: July 4, 2025","lvl6":"header levels","lvl5":"of further and further","lvl4":"a quick demonstration","lvl3":"A subsection to the second section","lvl2":"Your second content section"},"content":"\n\nas well as m = a * t / h text! Similarly, you have access to other \\LaTeX equation \n\nfunctionality via MathJax:\\begin{align}\n\\dot{x} & = \\sigma(y-x) \\\\\n\\dot{y} & = \\rho x - y - xz \\\\\n\\dot{z} & = -\\beta z + xy\n\\end{align}\n\nCheck out \n\nany number of helpful Markdown resources for further customizing your notebooks and the \n\nMyST Syntax Overview for MyST-specific formatting information. Don’t hesitate to ask questions if you have problems getting it to look just right.\n\n","type":"content","url":"/notebooks/ch3-txfloods#header-levels","position":33},{"hierarchy":{"lvl1":"MRMS Reflectivity Animation: July 4, 2025","lvl2":"Last Section"},"type":"lvl2","url":"/notebooks/ch3-txfloods#last-section","position":34},{"hierarchy":{"lvl1":"MRMS Reflectivity Animation: July 4, 2025","lvl2":"Last Section"},"content":"You can add \n\nadmonitions using MyST syntax:\n\nNote\n\nYour relevant information here!\n\nSome other admonitions you can put in (\n\nthere are 10 total):\n\nHint\n\nA helpful hint.\n\nWarning\n\nBe careful!\n\nDanger\n\nScary stuff be here.\n\nWe also suggest checking out Jupyter Book’s \n\nbrief demonstration on adding cell tags to your cells in Jupyter Notebook, Lab, or manually. Using these cell tags can allow you to \n\ncustomize how your code content is displayed and even \n\ndemonstrate errors without altogether crashing our loyal army of machines!\n\n\n\n","type":"content","url":"/notebooks/ch3-txfloods#last-section","position":35},{"hierarchy":{"lvl1":"MRMS Reflectivity Animation: July 4, 2025","lvl2":"Summary"},"type":"lvl2","url":"/notebooks/ch3-txfloods#summary","position":36},{"hierarchy":{"lvl1":"MRMS Reflectivity Animation: July 4, 2025","lvl2":"Summary"},"content":"Add one final --- marking the end of your body of content, and then conclude with a brief single paragraph summarizing at a high level the key pieces that were learned and how they tied to your objectives. Look to reiterate what the most important takeaways were.","type":"content","url":"/notebooks/ch3-txfloods#summary","position":37},{"hierarchy":{"lvl1":"MRMS Reflectivity Animation: July 4, 2025","lvl3":"What’s next?","lvl2":"Summary"},"type":"lvl3","url":"/notebooks/ch3-txfloods#whats-next","position":38},{"hierarchy":{"lvl1":"MRMS Reflectivity Animation: July 4, 2025","lvl3":"What’s next?","lvl2":"Summary"},"content":"Let Jupyter book tie this to the next (sequential) piece of content that people could move on to down below and in the sidebar. However, if this page uniquely enables your reader to tackle other nonsequential concepts throughout this book, or even external content, link to it here!\n\n","type":"content","url":"/notebooks/ch3-txfloods#whats-next","position":39},{"hierarchy":{"lvl1":"MRMS Reflectivity Animation: July 4, 2025","lvl2":"Resources and references"},"type":"lvl2","url":"/notebooks/ch3-txfloods#resources-and-references","position":40},{"hierarchy":{"lvl1":"MRMS Reflectivity Animation: July 4, 2025","lvl2":"Resources and references"},"content":"Finally, be rigorous in your citations and references as necessary. Give credit where credit is due. Also, feel free to link to relevant external material, further reading, documentation, etc. Then you’re done! Give yourself a quick review, a high five, and send us a pull request. A few final notes:\n\nKernel > Restart Kernel and Run All Cells... to confirm that your notebook will cleanly run from start to finish\n\nKernel > Restart Kernel and Clear All Outputs... before committing your notebook, our machines will do the heavy lifting\n\nTake credit! Provide author contact information if you’d like; if so, consider adding information here at the bottom of your notebook\n\nGive credit! Attribute appropriate authorship for referenced code, information, images, etc.\n\nOnly include what you’re legally allowed: no copyright infringement or plagiarism\n\nThank you for your contribution!","type":"content","url":"/notebooks/ch3-txfloods#resources-and-references","position":41},{"hierarchy":{"lvl1":"Real-time MRMS Visualization"},"type":"lvl1","url":"/notebooks/ch4-realtimedata","position":0},{"hierarchy":{"lvl1":"Real-time MRMS Visualization"},"content":"\n\nWelcome to the Real-time MRMS Visualization notebook! In this workflow, you will receive a quick briefing on the Multi-Radar/Multi-Sensor System (MRMS) content covered in \n\nChapter 1, learn about data access from Amazom Web Services (AWS), make a selection of MRMS data to request from AWS, and visualize the latest radar data in an interactive plot.\n\nIntent: This Project Pythia notebook allows a user to gain familiarity with the process of requesting real-time MRMS data from AWS S3 and provides the opportunity for further learning.Audience: Anyone with at least 5GB of memory on their computer or computing environment and a fundamental knowledge of MRMS.   No programming experience is required to go run this notebook, but it will help you understand where this data is coming from.Outcome: An interactive plot showing MRMS imagery from a selected region and radar product.Time to Learn: 15 minutes to run the notebook and read the documentation; 30 minutes to become familiar enough with the material to replicate these methods.\n\n","type":"content","url":"/notebooks/ch4-realtimedata","position":1},{"hierarchy":{"lvl1":"Real-time MRMS Visualization","lvl2":"Overview"},"type":"lvl2","url":"/notebooks/ch4-realtimedata#overview","position":2},{"hierarchy":{"lvl1":"Real-time MRMS Visualization","lvl2":"Overview"},"content":"Import required packages\n\nLearn about MRMS\n\nExplore near real-time MRMS data hosted on AWS\n\nSelect a region and product for viewing\n\nAccess selected MRMS data from AWS\n\nVisualize a selected variable using an interactive plot\n\n\n\n","type":"content","url":"/notebooks/ch4-realtimedata#overview","position":3},{"hierarchy":{"lvl1":"Real-time MRMS Visualization","lvl2":"Imports"},"type":"lvl2","url":"/notebooks/ch4-realtimedata#imports","position":4},{"hierarchy":{"lvl1":"Real-time MRMS Visualization","lvl2":"Imports"},"content":"\n\nHere are all required Python packages to run this code.\n\n# Packages required to request and open data from AWS S3\nimport s3fs\nimport urllib\nimport tempfile\nimport gzip\nimport xarray as xr\n\n# Packages required for data visualization\nimport datetime\nfrom datetime import timezone\nimport numpy.ma as ma\nfrom metpy.plots import ctables\nimport numpy as np\nimport holoviews as hv\nimport pandas as pd\nimport panel as pn\nimport hvplot.xarray \nimport matplotlib.colors as mcls\nfrom matplotlib.colors import Normalize\n#pn.extension(\"bokeh\")\nhv.extension('bokeh')\n\n\n\n","type":"content","url":"/notebooks/ch4-realtimedata#imports","position":5},{"hierarchy":{"lvl1":"Real-time MRMS Visualization","lvl2":"About MRMS"},"type":"lvl2","url":"/notebooks/ch4-realtimedata#about-mrms","position":6},{"hierarchy":{"lvl1":"Real-time MRMS Visualization","lvl2":"About MRMS"},"content":"\n\nimage\n\nThe Multi-Radar/Multi-Sensor System (MRMS) produces products for public infrastructure, weather forecasts and warnings, aviation, and numerical weather prediction. It provides high spatial (1-km) and temporal (2-min) resolution radar products at 31 vertical levels, and ingests data from numerous sources (including radar networks across the US and Canada, surface and upper air observations, lightning detection systems, satellite observations, and forecast models)\n\n1\n\nFor more information, please refer to Chapter 1 of this project: \n\nLearning about MRMS.\n\n\n\n","type":"content","url":"/notebooks/ch4-realtimedata#about-mrms","position":7},{"hierarchy":{"lvl1":"Real-time MRMS Visualization","lvl2":"About AWS and NODD"},"type":"lvl2","url":"/notebooks/ch4-realtimedata#about-aws-and-nodd","position":8},{"hierarchy":{"lvl1":"Real-time MRMS Visualization","lvl2":"About AWS and NODD"},"content":"\n\nlogo images\n\nThe Amazon Web Services Simple Storage Service (AWS S3) is cloud-based object storage service. Through a public-private partnership with the National Oceanic and Atmospheric Administration (NOAA)'s Open Data Dissemination Program (NODD), NOAA is able to store multiple petabytes of open-access earth science data on AWS S3, including the MRMS dataset. This allows users to quickly and freely access MRMS data in real-time (with an update frequency of two minutes) without having to download the data to their personal systems.\n\nBecause of this partnership, we can access the data as an anonymous client -- no login required!\n\n# Initialize the S3 filesystem as anonymous\naws = s3fs.S3FileSystem(anon=True)\n\nYou can explore the S3 bucket that holds MRMS data to assess data availability and structure -- just visit \n\nthis link, which takes you to the MRMS bucket.\n\n# Here's a hint -- you can run aws.ls to see the file structure in code. Try it yourself!\naws.ls(f'noaa-mrms-pds/CONUS/', refresh=True)[0:5]\n\n\n\n","type":"content","url":"/notebooks/ch4-realtimedata#about-aws-and-nodd","position":9},{"hierarchy":{"lvl1":"Real-time MRMS Visualization","lvl2":"Data selection"},"type":"lvl2","url":"/notebooks/ch4-realtimedata#data-selection","position":10},{"hierarchy":{"lvl1":"Real-time MRMS Visualization","lvl2":"Data selection"},"content":"For ease of use, I’ve integrated ipywidgets (drop-down menus!) that allow you to make selections from AWS, and refined a selection of data variables as a demonstration. You can choose between the QC’d Merged Reflectivity Composite (the maximum reflectivity in a column, as a composite), a 12-hour multisensor QPE from Pass 1 (12h rainfall accumulation estimate, using data from multiple sensors), and the Probability of Severe Hail (probability of 0.75-inch diameter hail).\n\nNow, you have the option to select a region and a radar product to visualize in near real-time. Go ahead and use the drop-down menus to select a region, a radar product, then run the next cell. If you run the drop-down cell again, it will reset your values.\n\n# Define dropdown options\nregion_options = [\"CONUS\", \"ALASKA\", \"CARIB\", \"GUAM\", \"HAWAII\"]\nproduct_options = [\n    \"MergedReflectivityQCComposite_00.50\",\n    \"MultiSensor_QPE_12H_Pass1_00.00\",\n    \"POSH_00.50\"\n]\n\n# Create the dropdowns with similar layout/formatting\nregion_choice = pn.widgets.Select(name='Region', options=region_options, width=325)\nproduct_choice = pn.widgets.Select(name='MRMS product', options=product_options, width=325)\n\n# Display the widgets together in a vertical layout (Column)\npn.Column(region_choice, product_choice)\n\nCongratulations, you’ve made your data selection!\n\nIf you choose to adapt this notebook to your own workflow, this section can easily be adjusted to your own use case. Simply delete the cell above, then update the cell below to reflect the region and data variable you wish to use. If you decide to use a product that is not covered in this notebook, you can search through \n\nall available data products on AWS and paste it in verbatim. It may be helpful to cross-reference these variables against the \n\nNSSL variable table and\n\n\nChapter 1.\n\n# Retrieve the user selection from 'region' \nregion = region_choice.value\n\n# Retrieve the user selection from 'MRMS product'\nproduct = product_choice.value\n\nprint(region, product)\n\n\n\n","type":"content","url":"/notebooks/ch4-realtimedata#data-selection","position":11},{"hierarchy":{"lvl1":"Real-time MRMS Visualization","lvl2":"Data request"},"type":"lvl2","url":"/notebooks/ch4-realtimedata#data-request","position":12},{"hierarchy":{"lvl1":"Real-time MRMS Visualization","lvl2":"Data request"},"content":"Now that you’ve made your variable selection, it’s time to read in the data from AWS. First, we retrieve the current UTC datetime so that we can request files from today’s S3 bucket.\n\n# Retrieve the current datetime in UTC to know which bucket to query\nnow = datetime.datetime.now(datetime.UTC)\ndatestring = now.strftime('%Y%m%d')\n\nNext, we query the S3 bucket to make sure the data is available on AWS. If this section errors, reference \n\nthe S3 bucket to confirm that your requested region, date, and product exists and is entered correctly.\n\n# Query the S3 bucket for the available files that meet the criteria\ntry:\n    data_files = aws.ls(f'noaa-mrms-pds/{region}/{product}/{datestring}/', refresh=True)  \nexcept Exception as e:\n    print(f\"Error accessing S3 bucket: {e}\")\n    data_files = []\n\nFinally, we make the data request and read it in using xarray. This block of code finds the most recent file that fits your criteria, ensures that the file was created recently (within two hours), then makes the data request. Due to way the data was uploaded to S3, the file arrives as a compressed grib2 file. This code decompresses the file and reads it in using xarray, making the format more easily incorporated into our workflow.\n\nif data_files:\n    # Choose the last file from S3 for the most recent data\n    most_recent_file = data_files[-1]\n\n    # Check that the most recent file is within 2 hours of current time\n    timestamp_str = most_recent_file.split('_')[-1].replace('.grib2.gz', '')\n    dt = datetime.datetime.strptime(timestamp_str, \"%Y%m%d-%H%M%S\").replace(tzinfo=timezone.utc)\n    if abs((now - dt).total_seconds()) <= 120 * 60:\n        # Download file to memory, decompress from .gz, and read into xarray\n        try:\n            response = urllib.request.urlopen(f\"https://noaa-mrms-pds.s3.amazonaws.com/{most_recent_file[14:]}\")\n            compressed_file = response.read()\n\n            with tempfile.NamedTemporaryFile(suffix=\".grib2\") as f:\n                f.write(gzip.decompress(compressed_file))\n                f.flush()\n                data = xr.load_dataarray(f.name, engine=\"cfgrib\", decode_timedelta=True)\n        except Exception as e:\n            print(f\"Failed to process {product}: {e}\")\n\n\n\n","type":"content","url":"/notebooks/ch4-realtimedata#data-request","position":13},{"hierarchy":{"lvl1":"Real-time MRMS Visualization","lvl2":"Visualization"},"type":"lvl2","url":"/notebooks/ch4-realtimedata#visualization","position":14},{"hierarchy":{"lvl1":"Real-time MRMS Visualization","lvl2":"Visualization"},"content":"Now that we have the data read into memory using xarray, it is quite simple to plot. Here, we use hvplot to make an interactive visualization that allows the user to zoom in to a region of interest and mouse over values to better understand the product’s functionality over a specific region.\n\n# Mask data for neater visualization\ndata = data.where(data > 0, np.nan)\n\n# Get the NWS Reflectivity colormap and normalize range\nref_norm, ref_cmap = ctables.registry.get_with_steps('NWSReflectivity', 5, 5)\n\n# Convert to hex colors for Bokeh\nnorm = Normalize(vmin=ref_norm.vmin, vmax=ref_norm.vmax)\nhex_cmap = [ref_cmap(norm(val)) for val in range(ref_norm.vmin, ref_norm.vmax + 5, 5)]\nhex_cmap = [mcls.to_hex(c) for c in hex_cmap]\n\n# Plot using hvplot\nreflectivity_plot = data.hvplot.image(\n    x=\"longitude\", y=\"latitude\",\n    cmap=hex_cmap,\n    colorbar=True,\n    geo=True, \n    tiles=True, \n    alpha=0.7,\n    clim=(ref_norm.vmin, ref_norm.vmax),\n    title=f\"{product} - {pd.to_datetime(data.time.values).strftime('%b %d, %Y at %H:%M:%S')} UTC\",\n    frame_width=700,\n    frame_height=500,\n    xlabel='Longitude',\n    ylabel='Latitude',\n    tools=['hover']\n)\n\nreflectivity_plot\n\nAbove is your visualization! You can use the menu bar at the upper right side of the plot to pan around the plot, zoom in to a region of interest, and reset your selections to the default map. If you mouse over the values on the screen, you will see the latitude, longitude, and value associated with the selected product.\n\n","type":"content","url":"/notebooks/ch4-realtimedata#visualization","position":15},{"hierarchy":{"lvl1":"Real-time MRMS Visualization","lvl2":"Parting thoughts"},"type":"lvl2","url":"/notebooks/ch4-realtimedata#parting-thoughts","position":16},{"hierarchy":{"lvl1":"Real-time MRMS Visualization","lvl2":"Parting thoughts"},"content":"Congratulations on the completion of this notebook! You have successfully selected a region and product, queried the AWS S3 bucket, and visualized MRMS data in near real-time.\n\nIf you’d like to continue this analysis, here are a couple of bonus challenges:\n\n","type":"content","url":"/notebooks/ch4-realtimedata#parting-thoughts","position":17},{"hierarchy":{"lvl1":"Real-time MRMS Visualization","lvl3":"Challenge (easy): Use the drop-down widgets in this notebook to plot a different project and region from your initial run!","lvl2":"Parting thoughts"},"type":"lvl3","url":"/notebooks/ch4-realtimedata#challenge-easy-use-the-drop-down-widgets-in-this-notebook-to-plot-a-different-project-and-region-from-your-initial-run","position":18},{"hierarchy":{"lvl1":"Real-time MRMS Visualization","lvl3":"Challenge (easy): Use the drop-down widgets in this notebook to plot a different project and region from your initial run!","lvl2":"Parting thoughts"},"content":"\n\n","type":"content","url":"/notebooks/ch4-realtimedata#challenge-easy-use-the-drop-down-widgets-in-this-notebook-to-plot-a-different-project-and-region-from-your-initial-run","position":19},{"hierarchy":{"lvl1":"Real-time MRMS Visualization","lvl3":"Challenge (medium): Delete the widget cell and use populate the notebook with a hard-coded “region” and “product” variable. Find a variable that was not covered in this notebook using the AWS S3 bucket.","lvl2":"Parting thoughts"},"type":"lvl3","url":"/notebooks/ch4-realtimedata#challenge-medium-delete-the-widget-cell-and-use-populate-the-notebook-with-a-hard-coded-region-and-product-variable-find-a-variable-that-was-not-covered-in-this-notebook-using-the-aws-s3-bucket","position":20},{"hierarchy":{"lvl1":"Real-time MRMS Visualization","lvl3":"Challenge (medium): Delete the widget cell and use populate the notebook with a hard-coded “region” and “product” variable. Find a variable that was not covered in this notebook using the AWS S3 bucket.","lvl2":"Parting thoughts"},"content":"Hint: Make sure to copy the variable names from the AWS Explorer exactly as you see them on screen, or your bucket access step will error.\nHint 2: The visualization step has the correct framework for a new product, but has been customized for the three examples in this notebook. Make sure to find a good color bar and reformat the name of your product to make a more beautiful plot.\n\n","type":"content","url":"/notebooks/ch4-realtimedata#challenge-medium-delete-the-widget-cell-and-use-populate-the-notebook-with-a-hard-coded-region-and-product-variable-find-a-variable-that-was-not-covered-in-this-notebook-using-the-aws-s3-bucket","position":21},{"hierarchy":{"lvl1":"Real-time MRMS Visualization","lvl3":"Challenge (difficult): Turn this notebook into a Python script, then use cron to create an updated plot from MRMS data every hour. Incorporate this plot into a web page, send it to your friend, or try it just for fun!","lvl2":"Parting thoughts"},"type":"lvl3","url":"/notebooks/ch4-realtimedata#challenge-difficult-turn-this-notebook-into-a-python-script-then-use-cron-to-create-an-updated-plot-from-mrms-data-every-hour-incorporate-this-plot-into-a-web-page-send-it-to-your-friend-or-try-it-just-for-fun","position":22},{"hierarchy":{"lvl1":"Real-time MRMS Visualization","lvl3":"Challenge (difficult): Turn this notebook into a Python script, then use cron to create an updated plot from MRMS data every hour. Incorporate this plot into a web page, send it to your friend, or try it just for fun!","lvl2":"Parting thoughts"},"content":"Hint: See the appendix for static plotting code to get you started.\n\n\n\n","type":"content","url":"/notebooks/ch4-realtimedata#challenge-difficult-turn-this-notebook-into-a-python-script-then-use-cron-to-create-an-updated-plot-from-mrms-data-every-hour-incorporate-this-plot-into-a-web-page-send-it-to-your-friend-or-try-it-just-for-fun","position":23},{"hierarchy":{"lvl1":"Real-time MRMS Visualization","lvl2":"Resources and references"},"type":"lvl2","url":"/notebooks/ch4-realtimedata#resources-and-references","position":24},{"hierarchy":{"lvl1":"Real-time MRMS Visualization","lvl2":"Resources and references"},"content":"\n\nThings\n\nSecond things\n\n","type":"content","url":"/notebooks/ch4-realtimedata#resources-and-references","position":25},{"hierarchy":{"lvl1":"Real-time MRMS Visualization","lvl2":"Appendix"},"type":"lvl2","url":"/notebooks/ch4-realtimedata#appendix","position":26},{"hierarchy":{"lvl1":"Real-time MRMS Visualization","lvl2":"Appendix"},"content":"If you’d prefer to plot these data as a static plot, below is some sample code to kickstart your plotting journey.\n\n\"\"\"\nimport matplotlib.pyplot as plt\nimport cartopy.crs as ccrs\nimport cartopy.feature as cfeature\n    \nlons = data.longitude\nlats = data.latitude\nvalues = data.values\ndate = data.time.values\n\nminLon = lons.min() \nmaxLon = lons.max()\nminLat = lats.min()\nmaxLat = lats.max()\n\nfig = plt.figure(figsize=(12,6), facecolor='w', edgecolor='k')\nax = fig.add_axes([0, 0, 1, 1], projection=ccrs.Mercator())\nax.set_extent([minLon, maxLon, minLat, maxLat], crs=ccrs.Geodetic())\n\n# Set colors\nref_norm, ref_cmap = ctables.registry.get_with_steps('NWSReflectivity', 5, 5)\nunits = \"Reflectivity (dBZ)\"\ntitle = \"MRMS Merged Reflectivity\"\n\n# Add Boundaries\nax.add_feature(cfeature.STATES, linewidth=0.25)\n\n# Plot Data\nradarplot = ax.pcolormesh(lons, lats, values, transform=ccrs.PlateCarree(), cmap=ref_cmap, norm=ref_norm)\ncbar = plt.colorbar(radarplot)\ncbar.set_label(units)\n\nplt.title(f\"{title}\", loc='left', fontweight='bold')\n#plt.title('{}'.format(pd.to_datetime(date).strftime('%d %B %Y at %H:%M UTC')), loc='right')\n\nplt.show()\n\n\"\"\"","type":"content","url":"/notebooks/ch4-realtimedata#appendix","position":27}]}