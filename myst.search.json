{"version":"1","records":[{"hierarchy":{"lvl1":"MRMS Cookbook"},"type":"lvl1","url":"/","position":0},{"hierarchy":{"lvl1":"MRMS Cookbook"},"content":"\n\n\n\n\n [![DOI](https://zenodo.org/badge/475509405.svg)](https://zenodo.org/badge/latestdoi/475509405) \n\nThis Project Pythia Cookbook covers how to access, analyze, and visualize Multi-radar, Multi-sensor (MRMS) Data.","type":"content","url":"/","position":1},{"hierarchy":{"lvl1":"MRMS Cookbook","lvl2":"Motivation"},"type":"lvl2","url":"/#motivation","position":2},{"hierarchy":{"lvl1":"MRMS Cookbook","lvl2":"Motivation"},"content":"The Multi-Radar, Multi-Sensor (MRMS) System combines radar, surface, and upper-air observation to produce a high-resolution (1 km) dataset used by researchers and forecasters alike. Despite its use, there are few published Python workflows that illustrate how to access MRMS data from Amazon Web Services (AWS) and produce beautiful, useful visualizations. We hope this cookbook serves the MRMS-user community well!","type":"content","url":"/#motivation","position":3},{"hierarchy":{"lvl1":"MRMS Cookbook","lvl2":"Authors"},"type":"lvl2","url":"/#authors","position":4},{"hierarchy":{"lvl1":"MRMS Cookbook","lvl2":"Authors"},"content":"","type":"content","url":"/#authors","position":5},{"hierarchy":{"lvl1":"MRMS Cookbook","lvl3":"Contributors","lvl2":"Authors"},"type":"lvl3","url":"/#contributors","position":6},{"hierarchy":{"lvl1":"MRMS Cookbook","lvl3":"Contributors","lvl2":"Authors"},"content":"","type":"content","url":"/#contributors","position":7},{"hierarchy":{"lvl1":"MRMS Cookbook","lvl2":"Structure"},"type":"lvl2","url":"/#structure","position":8},{"hierarchy":{"lvl1":"MRMS Cookbook","lvl2":"Structure"},"content":"Chapter 1 offers a brief overview of MRMS data and provides context for how the data is organized on AWS.\n\nChapter 2 contains a case study of the \n\nMarch 24–27 2023 Tornado Outbreak, showcasing fields relevant to severe weather prediction.\n\nChapter 3 examines another recent severe weather event, the \n\nJuly 2025 Central Texas Floods, instead focusing on precipitation fields and \n\nFLASH output, including comparisons to station observations.\n\nChapter 4 compares MRMS-derived precipitation estimates at Bankhead National Forest (BNF) Field Sites.\n\nChapter 5 offers a real-time look at MRMS data with the opportunity to select certain data fields.","type":"content","url":"/#structure","position":9},{"hierarchy":{"lvl1":"MRMS Cookbook","lvl2":"Running the Notebooks"},"type":"lvl2","url":"/#running-the-notebooks","position":10},{"hierarchy":{"lvl1":"MRMS Cookbook","lvl2":"Running the Notebooks"},"content":"You can either run the notebook using \n\nBinder or on your local machine.","type":"content","url":"/#running-the-notebooks","position":11},{"hierarchy":{"lvl1":"MRMS Cookbook","lvl3":"Running on Binder","lvl2":"Running the Notebooks"},"type":"lvl3","url":"/#running-on-binder","position":12},{"hierarchy":{"lvl1":"MRMS Cookbook","lvl3":"Running on Binder","lvl2":"Running the Notebooks"},"content":"The simplest way to interact with a Jupyter Notebook is through\n\n\nBinder, which enables the execution of a\n\n\nJupyter Book in the cloud. The details of how this works are not\nimportant for now. All you need to know is how to launch a Pythia\nCookbooks chapter via Binder. Simply navigate your mouse to\nthe top right corner of the book chapter you are viewing and click\non the rocket ship icon, (see figure below), and be sure to select\n“launch Binder”. After a moment you should be presented with a\nnotebook that you can interact with. I.e. you’ll be able to execute\nand even change the example programs. You’ll see that the code cells\nhave no output at first, until you execute them by pressing\nShift+Enter. Complete details on how to interact with\na live Jupyter notebook are described in \n\nGetting Started with\nJupyter.\n\nNote: not all Cookbook chapters are executable. If you do not see\nthe rocket ship icon, such as on this page, you are not viewing an\nexecutable book chapter.","type":"content","url":"/#running-on-binder","position":13},{"hierarchy":{"lvl1":"MRMS Cookbook","lvl3":"Running on Your Own Machine","lvl2":"Running the Notebooks"},"type":"lvl3","url":"/#running-on-your-own-machine","position":14},{"hierarchy":{"lvl1":"MRMS Cookbook","lvl3":"Running on Your Own Machine","lvl2":"Running the Notebooks"},"content":"If you are interested in running this material locally on your computer, you will need to follow this workflow:\n\nClone the https://github.com/ProjectPythia/mrms-cookbook repository: git clone https://github.com/ProjectPythia/mrms-cookbook.git\n\nMove into the mrms-cookbook directorycd mrms-cookbook\n\nCreate and activate your conda environment from the environment.yml fileconda env create -f environment.yml\nconda activate mrms-cookbook-dev\n\nMove into the notebooks directory and start up Jupyterlabcd notebooks/\njupyter lab","type":"content","url":"/#running-on-your-own-machine","position":15},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)"},"type":"lvl1","url":"/notebooks/bnf-mrms-qpe-hourly","position":0},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)"},"content":"\n\n","type":"content","url":"/notebooks/bnf-mrms-qpe-hourly","position":1},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)"},"type":"lvl1","url":"/notebooks/bnf-mrms-qpe-hourly#noaa-multi-radar-multi-sensor-system-mrms-at-the-bnf-field-site-s","position":2},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)"},"content":"\n\n","type":"content","url":"/notebooks/bnf-mrms-qpe-hourly#noaa-multi-radar-multi-sensor-system-mrms-at-the-bnf-field-site-s","position":3},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl2":"Overview"},"type":"lvl2","url":"/notebooks/bnf-mrms-qpe-hourly#overview","position":4},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl2":"Overview"},"content":"We’ll go through the steps of:\n\nDefine our region of verification sites\n\nQuery and Load Data from MRMS Buckets on AWS\n\nCreate a Multi-Panel Display of QPE for the different sites\n\n","type":"content","url":"/notebooks/bnf-mrms-qpe-hourly#overview","position":5},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl2":"Prerequisites"},"type":"lvl2","url":"/notebooks/bnf-mrms-qpe-hourly#prerequisites","position":6},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl2":"Prerequisites"},"content":"Concepts\n\nImportance\n\nNotes\n\nIntro to Cartopy\n\nNecessary\n\nMapping and Tiles\n\nIntro to Xarray\n\nNecessary\n\nFamiliarity with metadata structure\n\nTime to learn: 30 minutes\n\nSystem requirements:\n\nAny Operating System\n\nAt least 8 GB of RAM\n\n","type":"content","url":"/notebooks/bnf-mrms-qpe-hourly#prerequisites","position":7},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl2":"Imports"},"type":"lvl2","url":"/notebooks/bnf-mrms-qpe-hourly#imports","position":8},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl2":"Imports"},"content":"\n\nimport cfgrib\nimport xarray as xr\nimport fsspec\nimport glob\nimport tempfile\nimport gzip\nimport geopandas as gpd\nimport pandas as pd\nimport numpy as np\nimport warnings\n\nfrom cartopy import feature as cfeature\nimport cartopy.crs as ccrs\nfrom cartopy.io.img_tiles import OSM\nfrom matplotlib.transforms import offset_copy\nfrom matplotlib import pyplot as plt\n\nfrom metpy.plots import USCOUNTIES\n\nimport cmweather\n\n# To ignore all RuntimeWarnings globally\nwarnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n\n","type":"content","url":"/notebooks/bnf-mrms-qpe-hourly#imports","position":9},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl2":"Hourly QPE BNF Mosaic"},"type":"lvl2","url":"/notebooks/bnf-mrms-qpe-hourly#hourly-qpe-bnf-mosaic","position":10},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl2":"Hourly QPE BNF Mosaic"},"content":"The \n\nNOAA Multi-Radar / Multi-Sensor System (MRMS) was created to produce products of preciptiation impacts on transportation and aviation.\n\nUsing the \n\nNOAA MRMS AWS Bucket, this notebook details creation of quicklooks to investigate a Quantitative Preciptiation Estimates (QPE) for the U.S. Department of Energy Atmospheric Radiation Measurement (ARM) AMF-3 Deployment to Bankhead National Forest.\n\nWe start first with a dictionary containing our sites of interest, these are located Southwest of Decatur, Alabama.\n\nMore about the BNF Site can be found on the \n\nARM Website.\n\nglobal_sites = {\"M1\" : [34.34525, -87.33842],\n                \"S4\" : [34.46451, -87.23598],\n                \"S3\" : [34.63080, -87.13311],\n                \"S20\" : [34.65401, -87.29264],\n                \"S30\" : [34.38501, -86.92757],\n                \"S40\" : [34.17932, -87.45349]}\n\n\n# Define a domain to set the extent of the figures\nbnf_domain = [272.0, 274.0, 34.1, 35.1]\n\n","type":"content","url":"/notebooks/bnf-mrms-qpe-hourly#hourly-qpe-bnf-mosaic","position":11},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl3":"Visualize the Site Locations Using Cartopy","lvl2":"Hourly QPE BNF Mosaic"},"type":"lvl3","url":"/notebooks/bnf-mrms-qpe-hourly#visualize-the-site-locations-using-cartopy","position":12},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl3":"Visualize the Site Locations Using Cartopy","lvl2":"Hourly QPE BNF Mosaic"},"content":"\n\nfig = plt.figure(figsize=(12,8))\nax = plt.subplot(projection=ccrs.PlateCarree())\n\ntiler = OSM()\nax.add_image(tiler, 12, zorder=0, alpha=0.7)\nfor site in global_sites:\n    ax.scatter(global_sites[site][1], global_sites[site][0], label=site)\n\nax.set_extent(bnf_domain)\n\nplt.legend(loc=\"upper right\")\nplt.title(\"ARM Bankhead National Forest Sites\", fontsize=16);\n\n","type":"content","url":"/notebooks/bnf-mrms-qpe-hourly#visualize-the-site-locations-using-cartopy","position":13},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl2":"Query and Load Data from MRMS Buckets on AWS"},"type":"lvl2","url":"/notebooks/bnf-mrms-qpe-hourly#query-and-load-data-from-mrms-buckets-on-aws","position":14},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl2":"Query and Load Data from MRMS Buckets on AWS"},"content":"Note the Multi-Sensor (i.e. gauge adjusted) QPE product is split into two categories (Pass 1 and Pass 2), which defines the gauge latency used to adjust radar dervied QPE.\n\n# Define a Date for Analysis [YYYYMMDD format]\nDATE = \"20250524\"\nHOUR = \"000000\"\n\n## Setup the AWS S3 filesystem\nfs = fsspec.filesystem(\"s3\", anon=True)\n\ns3_multi_bucket = [f\"s3://noaa-mrms-pds/CONUS/MultiSensor_QPE_01H_Pass1_00.00/{DATE}/*.gz\"]\ns3_pass2_bucket = [f\"s3://noaa-mrms-pds/CONUS/MultiSensor_QPE_01H_Pass2_00.00/{DATE}/*.gz\"]\ns3_radar_bucket = [f\"s3://noaa-mrms-pds/CONUS/RadarOnly_QPE_01H_00.00/{DATE}/*[0-9]0000.grib2.gz\"]\n\n","type":"content","url":"/notebooks/bnf-mrms-qpe-hourly#query-and-load-data-from-mrms-buckets-on-aws","position":15},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl3":"Loop through and Create Lists of Datasets","lvl2":"Query and Load Data from MRMS Buckets on AWS"},"type":"lvl3","url":"/notebooks/bnf-mrms-qpe-hourly#loop-through-and-create-lists-of-datasets","position":16},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl3":"Loop through and Create Lists of Datasets","lvl2":"Query and Load Data from MRMS Buckets on AWS"},"content":"Our next step is to search, access, and load our data into merged datasets, adding some additional metadata such as units. We apply this for each our our multipass, pass2, and radar datasets.\n\nds_multi_list = []\nfor scan in s3_multi_bucket:\n    file_path = sorted(fs.glob(scan))\n    for mrms in file_path:\n        with fs.open(mrms, 'rb') as gzip_file:\n            with tempfile.NamedTemporaryFile(suffix=\".grib2\") as f:\n                # Uncompress and read the file\n                f.write(gzip.decompress(gzip_file.read()))\n                ds = xr.load_dataset(f.name, decode_timedelta=False)\n                # Parameters are stored as 'unknown'; meta data in filename\n                ds = ds.rename({\"unknown\" : \"multisensor_qpe_1hr\"})\n                ds[\"multisensor_qpe_1hr\"].attrs[\"units\"] = \"mm\"\n                ds[\"multisensor_qpe_1hr\"].attrs[\"long_name\"] = \"Precipitation Accumulation (1-Hr latency)\"\n                # Subset for the desired bounding box and take out all missing values\n                ds = ds.sel(latitude=slice(bnf_domain[3], bnf_domain[2]), longitude=slice(bnf_domain[0], bnf_domain[1])).where(ds.multisensor_qpe_1hr > 0)\n                ds_multi_list.append(ds)\n\nds_radar_list = []\nfor scan in s3_radar_bucket:\n    file_path = sorted(fs.glob(scan))\n    for mrms in file_path:\n        with fs.open(mrms, 'rb') as gzip_file:\n            with tempfile.NamedTemporaryFile(suffix=\".grib2\") as f:\n                # Uncompress and read the file\n                f.write(gzip.decompress(gzip_file.read()))\n                ds = xr.load_dataset(f.name, decode_timedelta=False)\n                ds = ds.rename({\"unknown\" : \"radar_qpe_1hr\"})\n                ds[\"radar_qpe_1hr\"].attrs[\"units\"] = \"mm\"\n                ds[\"radar_qpe_1hr\"].attrs[\"long_name\"] = \"Precipitation Accumulation\"\n                 # Subset for the desired bounding box and take out all missing values\n                ds = ds.sel(latitude=slice(bnf_domain[3], bnf_domain[2]), longitude=slice(bnf_domain[0], bnf_domain[1])).where(ds.radar_qpe_1hr > 0)\n                ds_radar_list.append(ds)\n\nds_pass2_list = []\nfor scan in s3_pass2_bucket:\n    file_path = sorted(fs.glob(scan))\n    for mrms in file_path:\n        with fs.open(mrms, 'rb') as gzip_file:\n            with tempfile.NamedTemporaryFile(suffix=\".grib2\") as f:\n                # Uncompress and read the file\n                f.write(gzip.decompress(gzip_file.read()))\n                ds = xr.load_dataset(f.name, decode_timedelta=False)\n                ds = ds.rename({\"unknown\" : \"multisensor_qpe_pass2\"})\n                ds[\"multisensor_qpe_pass2\"].attrs[\"units\"] = \"mm\"\n                ds[\"multisensor_qpe_pass2\"].attrs[\"long_name\"] = \"Precipitation Accumulation (2-Hr latency)\"\n                # Subset for the desired bounding box and take out all missing values\n                ds = ds.sel(latitude=slice(bnf_domain[3], bnf_domain[2]), longitude=slice(bnf_domain[0], bnf_domain[1])).where(ds.multisensor_qpe_pass2 > 0)\n                ds_pass2_list.append(ds)\n\n","type":"content","url":"/notebooks/bnf-mrms-qpe-hourly#loop-through-and-create-lists-of-datasets","position":17},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl3":"Merge our Files Together","lvl2":"Query and Load Data from MRMS Buckets on AWS"},"type":"lvl3","url":"/notebooks/bnf-mrms-qpe-hourly#merge-our-files-together","position":18},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl3":"Merge our Files Together","lvl2":"Query and Load Data from MRMS Buckets on AWS"},"content":"Once we have lists of files, we can merge based on the time dimension.\n\n# Concatenate all hourly files into xarray datasets\nds_radar_merged = xr.concat(ds_radar_list, dim=\"time\")\nds_multi_merged = xr.concat(ds_multi_list, dim=\"time\")\nds_pass2_merged = xr.concat(ds_pass2_list, dim=\"time\")\n\nAnd finally merge our various passes and QPE data into one single dataset.\n\n# Merge Radar, Multi-Sensor Pass 1 and Multi-Sensor Pass 2 QPE into single dataset\nds_merged = xr.merge([ds_radar_merged, ds_multi_merged, ds_pass2_merged])\n\n","type":"content","url":"/notebooks/bnf-mrms-qpe-hourly#merge-our-files-together","position":19},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl3":"Calculate Precipitation Accumulation","lvl2":"Query and Load Data from MRMS Buckets on AWS"},"type":"lvl3","url":"/notebooks/bnf-mrms-qpe-hourly#calculate-precipitation-accumulation","position":20},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl3":"Calculate Precipitation Accumulation","lvl2":"Query and Load Data from MRMS Buckets on AWS"},"content":"Our last step is to calculate our preciptiation accumulation as observed from radar data. We do this by using the xarray cumulative sum \n\ncumsum function.\n\n# Calculate the Cumulative Distribution\nradar_cumulative = ds_merged['radar_qpe_1hr'].cumsum(dim='time')\nmultisensor = ds_merged['multisensor_qpe_1hr'].cumsum(dim=\"time\")\nmultisensor_pass2 = ds_merged['multisensor_qpe_pass2'].cumsum(dim=\"time\")\n\nds_merged['cumulative_radar_qpe'] = radar_cumulative\nds_merged[\"cumulative_radar_qpe\"].attrs[\"units\"] = \"mm\"\nds_merged[\"cumulative_radar_qpe\"].attrs[\"long_name\"] = \"Precipitation Accumulation\"\n\nds_merged['cumulative_multisensor'] = multisensor\nds_merged[\"cumulative_multisensor\"].attrs[\"units\"] = \"mm\"\nds_merged[\"cumulative_multisensor\"].attrs[\"long_name\"] = \"Precipitation Accumulation (1-Hr latency)\"\n\nds_merged['cumulative_ms_pass2'] = multisensor_pass2\nds_merged[\"cumulative_ms_pass2\"].attrs[\"units\"] = \"mm\"\nds_merged[\"cumulative_ms_pass2\"].attrs[\"long_name\"] = \"Precipitation Accumulation (2-Hr latency)\"\nds_merged\n\n","type":"content","url":"/notebooks/bnf-mrms-qpe-hourly#calculate-precipitation-accumulation","position":21},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl2":"Create a Multi-Panel QPE Display"},"type":"lvl2","url":"/notebooks/bnf-mrms-qpe-hourly#create-a-multi-panel-qpe-display","position":22},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl2":"Create a Multi-Panel QPE Display"},"content":"Now that we have our merged, cleaned data, we can create a single graphic summarizing the cumulative precipitation at our different sites. We use nearest neighbor here to subset from the broader region.\n\n#---------------------------------------------------\n# Define the Figure for Detailed Subplot Placement\n#---------------------------------------------------\nfig = plt.figure(figsize=(24, 10))\ntiler = OSM()\nmercator = tiler.crs\nax = fig.add_subplot(1, 3, 1, projection=ccrs.PlateCarree())\n\n# adjust the subplot widths\nplt.subplots_adjust(wspace=0.3)\n\n# Find the maximum value at each position\nda_max = ds_merged.isel(time=-1).radar_qpe_1hr.max()\n\n# Find the minimum value at each position\nda_min = 0\n\n# ---------------------------------------------\n# Display the Radar Precipitation Accumulation\n# ---------------------------------------------\n\n## subset the data\nds_merged.isel(time=15).radar_qpe_1hr.plot(transform=ccrs.PlateCarree(),\n                                           ax=ax,\n                                           cmap=\"ChaseSpectral\",\n                                           vmin=da_min,\n                                           vmax=da_max,\n                                           cbar_kwargs={\"location\" : \"bottom\"})\n\n# Add some various map elements to the plot to make it recognizable.\nax.add_feature(cfeature.LAND)\nax.add_feature(cfeature.OCEAN)\nax.add_feature(cfeature.BORDERS)\nax.add_image(tiler, 12, zorder=1, alpha=0.55)\nax.gridlines(draw_labels=True)\n\n# Set plot bounds\nax.set_extent(bnf_domain)\n\n# add in crosshairs to indicate the lat/lon slices\nax.axhline(y=global_sites[\"M1\"][0], color=\"black\", linestyle=\"--\")\nax.axvline(x=global_sites[\"M1\"][1], color=\"red\", linestyle=\"--\")\n\n# Display the location of the BNF supplementarly sites\nfor key in global_sites:\n    # Add a marker for the BNF sites.\n    ax.plot(global_sites[key][1], \n            global_sites[key][0], \n            marker='o', \n            color='black', \n            markersize=10, \n            alpha=0.7, \n            transform=ccrs.PlateCarree())\n\n    # Use the cartopy interface to create a matplotlib transform object\n    # for the Geodetic coordinate system. We will use this along with\n    # matplotlib's offset_copy function to define a coordinate system which\n    # translates the text by 25 pixels to the left.\n    geodetic_transform = ccrs.PlateCarree()._as_mpl_transform(ax)\n    text_transform = offset_copy(geodetic_transform, units='dots', x=+50, y=+15)\n\n    # Add text to the right of the symbol.\n    ax.text(global_sites[key][1]-0.1, \n            global_sites[key][0], \n            key, \n            verticalalignment='center', \n            horizontalalignment='right', \n            transform=text_transform,\n            bbox=dict(facecolor='sandybrown', \n            alpha=0.5, \n            boxstyle='round'))\n    \n# update the title of the display\nax.set_title(np.datetime_as_string(ds_merged['valid_time'].isel(time=15).data, unit='s').replace(\"T\", \" - \") + \n             \"Z\\n\" + \"Radar Derived 1-Hr QPE - MRMS\")\n\n# ----------------------------\n# Display the Multisensor QPE\n# ----------------------------\n## subset the data\nax1 = fig.add_subplot(1, 3, 2, projection=ccrs.PlateCarree())\nds_merged.isel(time=15).multisensor_qpe_1hr.plot(transform=ccrs.PlateCarree(),\n                                                 ax=ax1,\n                                                 cmap=\"ChaseSpectral\",\n                                                 vmin=da_min,\n                                                 vmax=da_max,\n                                                 cbar_kwargs={\"location\" : \"bottom\"})\n\n# Add some various map elements to the plot to make it recognizable.\nax1.add_feature(cfeature.LAND)\nax1.add_feature(cfeature.OCEAN)\nax1.add_feature(cfeature.BORDERS)\nax1.add_image(tiler, 12, zorder=1, alpha=0.55)\nax1.gridlines(draw_labels=True)\n\n# Set plot bounds\nax1.set_extent(bnf_domain)\n\n# add in crosshairs to indicate the lat/lon slices\nax1.axhline(y=global_sites[\"M1\"][0], color=\"black\", linestyle=\"--\")\nax1.axvline(x=global_sites[\"M1\"][1], color=\"red\", linestyle=\"--\")\n\n# Display the location of the BNF Supplementary Site\nfor key in global_sites:\n    # Add a marker for the BNF sites.\n    ax1.plot(global_sites[key][1], \n            global_sites[key][0], \n            marker='o', \n            color='black', \n            markersize=10, \n            alpha=0.7, \n            transform=ccrs.PlateCarree())\n\n    # Use the cartopy interface to create a matplotlib transform object\n    # for the Geodetic coordinate system. We will use this along with\n    # matplotlib's offset_copy function to define a coordinate system which\n    # translates the text by 25 pixels to the left.\n    geodetic_transform = ccrs.PlateCarree()._as_mpl_transform(ax1)\n    text_transform = offset_copy(geodetic_transform, units='dots', x=+50, y=+15)\n\n\n    # Add text to the right of the site marker.\n    ax1.text(global_sites[key][1]-0.1, \n             global_sites[key][0], \n             key, \n             verticalalignment='center', \n             horizontalalignment='right', \n             transform=text_transform,\n             bbox=dict(facecolor='sandybrown', \n             alpha=0.5, \n             boxstyle='round')\n    )\n    \n# update the title of the display\nax1.set_title(np.datetime_as_string(ds_merged['valid_time'].isel(time=15).data, unit='s').replace(\"T\", \" - \") + \n             \"Z\\n\" + \"Multisensor 1-Hr QPE - Pass 1\")\n\n# ----------------------------\n# Display the QPE Difference\n# ----------------------------\n## subset the data\nax3 = fig.add_subplot(1, 3, 3, projection=ccrs.PlateCarree())\nds_merged.isel(time=15).multisensor_qpe_pass2.plot(transform=ccrs.PlateCarree(),\n                                                   ax=ax3,\n                                                   cmap=\"ChaseSpectral\",\n                                                   vmin=da_min,\n                                                   vmax=da_max,\n                                                   cbar_kwargs={\"location\" : \"bottom\"})\n\n# Add some various map elements to the plot to make it recognizable.\nax3.add_feature(cfeature.LAND)\nax3.add_feature(cfeature.OCEAN)\nax3.add_feature(cfeature.BORDERS)\nax3.add_image(tiler, 12, zorder=1, alpha=0.55)\nax3.gridlines(draw_labels=True)\n\n# Set plot bounds\nax3.set_extent(bnf_domain)\n\n# add in crosshairs to indicate the lat/lon slices\nax3.axhline(y=global_sites[\"M1\"][0], color=\"black\", linestyle=\"--\")\nax3.axvline(x=global_sites[\"M1\"][1], color=\"red\", linestyle=\"--\")\n\n# Display the location of the BNF Supplementary Sites\nfor key in global_sites:\n    # Add a marker for the BNF sites.\n    ax3.plot(global_sites[key][1], \n            global_sites[key][0], \n            marker='o', \n            color='black', \n            markersize=10, \n            alpha=0.7, \n            transform=ccrs.PlateCarree())\n\n    # Use the cartopy interface to create a matplotlib transform object\n    # for the Geodetic coordinate system. We will use this along with\n    # matplotlib's offset_copy function to define a coordinate system which\n    # translates the text by 25 pixels to the left.\n    geodetic_transform = ccrs.PlateCarree()._as_mpl_transform(ax3)\n    text_transform = offset_copy(geodetic_transform, units='dots', x=+50, y=+15)\n\n    # Add text to the right of the site marker.\n    ax3.text(global_sites[key][1]-0.1, \n             global_sites[key][0], \n             key, \n             verticalalignment='center', \n             horizontalalignment='right', \n             transform=text_transform,\n             bbox=dict(facecolor='sandybrown', \n             alpha=0.5, \n             boxstyle='round'))\n    \n# update the title of the display\nax3.set_title(np.datetime_as_string(ds_merged['valid_time'].isel(time=15).data, unit='s').replace(\"T\", \" - \") + \n             \"Z\\n\" + \"MultiSensor 24-Hr QPE - Pass 2\");\n\n","type":"content","url":"/notebooks/bnf-mrms-qpe-hourly#create-a-multi-panel-qpe-display","position":23},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl2":"Summary"},"type":"lvl2","url":"/notebooks/bnf-mrms-qpe-hourly#summary","position":24},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl2":"Summary"},"content":"Within this notebook, we explored plotting a set of a field sites, accessing MRMS data, and visualizing a case over the ARM DOE Bankhead National Forest field site. We hope this serves as a framework for verification and understanding precipitation values in specific regions of interest.","type":"content","url":"/notebooks/bnf-mrms-qpe-hourly#summary","position":25},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl3":"What’s Next","lvl2":"Summary"},"type":"lvl3","url":"/notebooks/bnf-mrms-qpe-hourly#whats-next","position":26},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl3":"What’s Next","lvl2":"Summary"},"content":"We can extend this workflow by investigating timeseries for the various sites and looking into more robust verification techniques.","type":"content","url":"/notebooks/bnf-mrms-qpe-hourly#whats-next","position":27},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl2":"References"},"type":"lvl2","url":"/notebooks/bnf-mrms-qpe-hourly#references","position":28},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl2":"References"},"content":"Notebook originally modified from Joseph O’Brien\n\nNOAA Multi-Radar/Multi-Sensor System (MRMS) was accessed on from https://registry.opendata.aws/noaa-mrms-pds","type":"content","url":"/notebooks/bnf-mrms-qpe-hourly#references","position":29},{"hierarchy":{"lvl1":"Chapter 1: Multi Radar/ Multi Sensor (MRMS) System: Overview, Case Studies, and More!"},"type":"lvl1","url":"/notebooks/ch1-introduction","position":0},{"hierarchy":{"lvl1":"Chapter 1: Multi Radar/ Multi Sensor (MRMS) System: Overview, Case Studies, and More!"},"content":"\n\n","type":"content","url":"/notebooks/ch1-introduction","position":1},{"hierarchy":{"lvl1":"Chapter 1: Multi Radar/ Multi Sensor (MRMS) System: Overview, Case Studies, and More!","lvl2":"Overview"},"type":"lvl2","url":"/notebooks/ch1-introduction#overview","position":2},{"hierarchy":{"lvl1":"Chapter 1: Multi Radar/ Multi Sensor (MRMS) System: Overview, Case Studies, and More!","lvl2":"Overview"},"content":"This notebook introduces users to MRMS, informs users on MRMS data sources, shows useful websites, and provides context on variable names. Follow through the notebook to learn more about MRMS and ways it can be used to aid in your research and decision-making!\n\n\n\n","type":"content","url":"/notebooks/ch1-introduction#overview","position":3},{"hierarchy":{"lvl1":"Chapter 1: Multi Radar/ Multi Sensor (MRMS) System: Overview, Case Studies, and More!","lvl2":"MRMS System Overview"},"type":"lvl2","url":"/notebooks/ch1-introduction#mrms-system-overview","position":4},{"hierarchy":{"lvl1":"Chapter 1: Multi Radar/ Multi Sensor (MRMS) System: Overview, Case Studies, and More!","lvl2":"MRMS System Overview"},"content":"\n\n","type":"content","url":"/notebooks/ch1-introduction#mrms-system-overview","position":5},{"hierarchy":{"lvl1":"Chapter 1: Multi Radar/ Multi Sensor (MRMS) System: Overview, Case Studies, and More!","lvl3":"What is MRMS?","lvl2":"MRMS System Overview"},"type":"lvl3","url":"/notebooks/ch1-introduction#what-is-mrms","position":6},{"hierarchy":{"lvl1":"Chapter 1: Multi Radar/ Multi Sensor (MRMS) System: Overview, Case Studies, and More!","lvl3":"What is MRMS?","lvl2":"MRMS System Overview"},"content":"The Multi-Radar/ Multi-Sensor (MRMS) System is a radar system developed by the National Severe Storms Laboratory (NSSL) that integrates data from satellites, radars, numerical prediction models, rain gauges, observations, and lightning reports into a standardized grid. Its goal is to provide smooth, high-resolution, and consistent weather products to inform decision-support services, aviation, transportation, numerical weather forecasting, hydrology, and public messaging.\n\nKey features include:\n\n3D radar mosaics\n\n1-km x 2-minute update cycle\n\nSevere weather and aviation products\n\nCovers CONUS, Alaska, Hawaii, (parts of) the Caribbean, Guam, and parts of southern Canada\n\n","type":"content","url":"/notebooks/ch1-introduction#what-is-mrms","position":7},{"hierarchy":{"lvl1":"Chapter 1: Multi Radar/ Multi Sensor (MRMS) System: Overview, Case Studies, and More!","lvl3":"MRMS Data Sources","lvl2":"MRMS System Overview"},"type":"lvl3","url":"/notebooks/ch1-introduction#mrms-data-sources","position":8},{"hierarchy":{"lvl1":"Chapter 1: Multi Radar/ Multi Sensor (MRMS) System: Overview, Case Studies, and More!","lvl3":"MRMS Data Sources","lvl2":"MRMS System Overview"},"content":"The MRMS integrates data from various sources to produce advanced weather products.\n\nRadars: Weather Surveillance Radar (WSR-88D), Canadian radar networks, Terminal Doppler Weather Radars (TDWRs), commercial radars, and more.\n\nSatellite: Geostationary Operational Environmental Satellite (GOES). Provides continuous data on atmospheric conditions.\n\nNumerical prediction models: High Resolution Rapid Refresh (HRRR), Rapid Refresh (RAP).\n\nSurface observations\n\nRain gauges: approximately 7,000 hourly rain gauge sensors, Hydrometeorological Automated Data System (HADS)\n\nLightning reports: National Lightning Detection Network (NLDN)\n\n","type":"content","url":"/notebooks/ch1-introduction#mrms-data-sources","position":9},{"hierarchy":{"lvl1":"Chapter 1: Multi Radar/ Multi Sensor (MRMS) System: Overview, Case Studies, and More!","lvl3":"AWS Structure & Access","lvl2":"MRMS System Overview"},"type":"lvl3","url":"/notebooks/ch1-introduction#aws-structure-access","position":10},{"hierarchy":{"lvl1":"Chapter 1: Multi Radar/ Multi Sensor (MRMS) System: Overview, Case Studies, and More!","lvl3":"AWS Structure & Access","lvl2":"MRMS System Overview"},"content":"To meet the demand for accessible, scalable, reliable, and timely data, MRMS hosts its data on Amazon Web Services (AWS).\n\nAccessing NOAA MRMS data on AWS is simple. \n\nJust click this link to navigate to the dedicated MRMS suite on AWS, select your area of interest, e.g., Alaska, CONUS, Hawaii, etc., then select the variable(s) you wish to study.\n\nThe next section talks more about some of the variables available and what they are.\n\n","type":"content","url":"/notebooks/ch1-introduction#aws-structure-access","position":11},{"hierarchy":{"lvl1":"Chapter 1: Multi Radar/ Multi Sensor (MRMS) System: Overview, Case Studies, and More!","lvl3":"MRMS Naming","lvl2":"MRMS System Overview"},"type":"lvl3","url":"/notebooks/ch1-introduction#mrms-naming","position":12},{"hierarchy":{"lvl1":"Chapter 1: Multi Radar/ Multi Sensor (MRMS) System: Overview, Case Studies, and More!","lvl3":"MRMS Naming","lvl2":"MRMS System Overview"},"content":"The MRMS has a wide range of variables you can use for your research and operations. \n\nBy clicking here, you can find the Operational MRMS GRIB2 Tables that detail the name of a dataset, frequencies, what unit the data is measured in, missing data, range folded, instances of no coverage, a description, and a notes column.\n\nIn this Cookbook, we use the following variables:\n\nVariable\n\nDescription\n\nRadarOnly_QPE_24H_00.00\n\nRadar precipitation accumulation 24-hour\n\nMergedReflectivityQCComposite_00.50\n\nComposite Reflectivity Mosaic (optimal method)\n\nMultiSensor_QPE_12H_Pass1_00.00\n\nMulti-sensor accumulation 12-hour (1-hour latency)\n\nPOSH_00.50\"\n\nProb of Severe Hail\n\nCREF_1HR_MAX_00.50\n\nComposite Reflectivity Hourly Maximum\n\nPrecipRate_00.00\n\nRadar Precipitation Rate\n\nMultiSensor_QPE_01H_Pass1_00.00\n\nMulti-sensor accumulation 1-hour (1-hour latency)\n\nMultiSensor_QPE_01H_Pass2_00.00\n\nMulti-sensor accumulation 1-hour (2-hour latency)\n\nRadarOnly_QPE_01H_00.00\n\nRadar precipitation accumulation 1-hour\n\nLowLevelCompositeReflectivity\n\nLow-Level Composite Reflectivity Mosaic (0-4km)\n\n\n\n","type":"content","url":"/notebooks/ch1-introduction#mrms-naming","position":13},{"hierarchy":{"lvl1":"Chapter 1: Multi Radar/ Multi Sensor (MRMS) System: Overview, Case Studies, and More!","lvl2":"Summary"},"type":"lvl2","url":"/notebooks/ch1-introduction#summary","position":14},{"hierarchy":{"lvl1":"Chapter 1: Multi Radar/ Multi Sensor (MRMS) System: Overview, Case Studies, and More!","lvl2":"Summary"},"content":"In summary, the MRMS System represents a robust and evolving platform that serves current research and operational needs, while paving ways for other innovations in decision-support services, aviation, transportation, numerical weather forecasting, hydrology, and public messaging.","type":"content","url":"/notebooks/ch1-introduction#summary","position":15},{"hierarchy":{"lvl1":"Chapter 1: Multi Radar/ Multi Sensor (MRMS) System: Overview, Case Studies, and More!","lvl4":"What’s next?","lvl2":"Summary"},"type":"lvl4","url":"/notebooks/ch1-introduction#whats-next","position":16},{"hierarchy":{"lvl1":"Chapter 1: Multi Radar/ Multi Sensor (MRMS) System: Overview, Case Studies, and More!","lvl4":"What’s next?","lvl2":"Summary"},"content":"In the following notebooks, you will be introduced to MRMS use case scenarios. We look into the March 2023 Rolling Fork, MS Tornado, the 2025 Texas Flood, and more!\n\n","type":"content","url":"/notebooks/ch1-introduction#whats-next","position":17},{"hierarchy":{"lvl1":"Chapter 1: Multi Radar/ Multi Sensor (MRMS) System: Overview, Case Studies, and More!","lvl2":"Resources"},"type":"lvl2","url":"/notebooks/ch1-introduction#resources","position":18},{"hierarchy":{"lvl1":"Chapter 1: Multi Radar/ Multi Sensor (MRMS) System: Overview, Case Studies, and More!","lvl2":"Resources"},"content":"To learn more about MRMS and its products, check out the links below!\n\nMulti Radar Multi Sensor Overview\n\nNSSL Multi-Radar/Multi-Sensor System (MRMS)\n\nOperational MRMS GRIB2 Table\n\nMRMS on AWS\n\nArticle on MRMS Severe Weather and Aviation Products\n\nArticle on MRMS Quantitative Precipitation Estimates","type":"content","url":"/notebooks/ch1-introduction#resources","position":19},{"hierarchy":{"lvl1":"Chapter 3: July 2025 Central TX Floods"},"type":"lvl1","url":"/notebooks/ch3-txfloods","position":0},{"hierarchy":{"lvl1":"Chapter 3: July 2025 Central TX Floods"},"content":"","type":"content","url":"/notebooks/ch3-txfloods","position":1},{"hierarchy":{"lvl1":"Chapter 3: July 2025 Central TX Floods","lvl2":"Overview"},"type":"lvl2","url":"/notebooks/ch3-txfloods#overview","position":2},{"hierarchy":{"lvl1":"Chapter 3: July 2025 Central TX Floods","lvl2":"Overview"},"content":"","type":"content","url":"/notebooks/ch3-txfloods#overview","position":3},{"hierarchy":{"lvl1":"Chapter 3: July 2025 Central TX Floods","lvl4":"This notebook walks through how to access, visualize, and animate low-level composite reflectivity data from the Multi-Radar/Multi-Sensor (MRMS) system.","lvl2":"Overview"},"type":"lvl4","url":"/notebooks/ch3-txfloods#this-notebook-walks-through-how-to-access-visualize-and-animate-low-level-composite-reflectivity-data-from-the-multi-radar-multi-sensor-mrms-system","position":4},{"hierarchy":{"lvl1":"Chapter 3: July 2025 Central TX Floods","lvl4":"This notebook walks through how to access, visualize, and animate low-level composite reflectivity data from the Multi-Radar/Multi-Sensor (MRMS) system.","lvl2":"Overview"},"content":"The case study focuses on the Central Texas flood event in July 2025, using reflectivity data hosted on AWS. The main steps include:\n\nSelecting and downloading MRMS data for specific timestamps\n\nCreating a static reflectivity map\n\nBuilding an animation to show reflectivity changes over time\n\nThis notebook is intended for students, forecasters, or researchers looking to explore radar visualization techniques or build familiarity with remote sensing workflows using Python.\n\n","type":"content","url":"/notebooks/ch3-txfloods#this-notebook-walks-through-how-to-access-visualize-and-animate-low-level-composite-reflectivity-data-from-the-multi-radar-multi-sensor-mrms-system","position":5},{"hierarchy":{"lvl1":"Chapter 3: July 2025 Central TX Floods","lvl3":"What is MRMS?","lvl2":"Overview"},"type":"lvl3","url":"/notebooks/ch3-txfloods#what-is-mrms","position":6},{"hierarchy":{"lvl1":"Chapter 3: July 2025 Central TX Floods","lvl3":"What is MRMS?","lvl2":"Overview"},"content":"The Multi-Radar/Multi-Sensor (MRMS) system is a set of real-time analysis products developed by NOAA’s National Severe Storms Laboratory (NSSL). It brings together data from:\n\nDozens of NEXRAD radars\n\nSurface observations\n\nSatellites\n\nLightning detection networks\n\nto create high-resolution snapshots of precipitation, severe weather, and related hazards.\n\nMRMS updates every 2.5 minutes and is commonly used in operational forecasting, hydrology, aviation, and research.","type":"content","url":"/notebooks/ch3-txfloods#what-is-mrms","position":7},{"hierarchy":{"lvl1":"Chapter 3: July 2025 Central TX Floods","lvl3":"Goal of This Notebook","lvl2":"Overview"},"type":"lvl3","url":"/notebooks/ch3-txfloods#goal-of-this-notebook","position":8},{"hierarchy":{"lvl1":"Chapter 3: July 2025 Central TX Floods","lvl3":"Goal of This Notebook","lvl2":"Overview"},"content":"The goal of this notebook is to walk through a simple, practical workflow for visualizing radar reflectivity data using Python. Specifically, we’ll:\n\nAccess MRMS Layer Composite Reflectivity Low data from AWS Open Data\n\nPlot a single reflectivity frame as a static map\n\nAnimate a 6-frame sequence from July 4, 2025, during the Central Texas flood event\n\nDemonstrate how to work with gridded radar data using open-source tools like MetPy, Cartopy, and xarray\n\n","type":"content","url":"/notebooks/ch3-txfloods#goal-of-this-notebook","position":9},{"hierarchy":{"lvl1":"Chapter 3: July 2025 Central TX Floods","lvl2":"Imports"},"type":"lvl2","url":"/notebooks/ch3-txfloods#imports","position":10},{"hierarchy":{"lvl1":"Chapter 3: July 2025 Central TX Floods","lvl2":"Imports"},"content":"below are the python packages that are used for this code\n\n# Core packages\nimport gzip\nimport tempfile\n\n# File handling (if you're downloading MRMS .grib2.gz files manually)\nimport urllib.request\nfrom datetime import datetime, timedelta\nfrom io import StringIO\n\nimport cartopy.crs as ccrs\nimport cartopy.feature as cfeature\nimport cmweather  # noqa: F401\nimport matplotlib.colors as mcolors\n\n# Plotting\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport numpy.ma as ma\nimport pandas as pd\nimport requests\nimport s3fs\nimport xarray as xr\nfrom IPython.display import HTML  # To display the animation\n\n# Animation\nfrom matplotlib.animation import ArtistAnimation, PillowWriter\nfrom metpy.plots import ctables  # For NWS reflectivity colormap\nfrom scipy.interpolate import RegularGridInterpolator\n\n\n\n","type":"content","url":"/notebooks/ch3-txfloods#imports","position":11},{"hierarchy":{"lvl1":"Chapter 3: July 2025 Central TX Floods","lvl2":"Define Timestamps and Colormap"},"type":"lvl2","url":"/notebooks/ch3-txfloods#define-timestamps-and-colormap","position":12},{"hierarchy":{"lvl1":"Chapter 3: July 2025 Central TX Floods","lvl2":"Define Timestamps and Colormap"},"content":"To build the animation, we’ll use 6 hourly frames of MRMS data from the morning of July 4, 2025. Each timestamp matches a GRIB2 file available from the AWS MRMS archive.\n\nWe also define the standard NWS reflectivity colormap using MetPy, which gives us consistent color breaks every 5 dBZ which is a common setup for radar reflectivity plots.\n\n","type":"content","url":"/notebooks/ch3-txfloods#define-timestamps-and-colormap","position":13},{"hierarchy":{"lvl1":"Chapter 3: July 2025 Central TX Floods","lvl3":"Access and Load MRMS Data","lvl2":"Define Timestamps and Colormap"},"type":"lvl3","url":"/notebooks/ch3-txfloods#access-and-load-mrms-data","position":14},{"hierarchy":{"lvl1":"Chapter 3: July 2025 Central TX Floods","lvl3":"Access and Load MRMS Data","lvl2":"Define Timestamps and Colormap"},"content":"MRMS data is stored as .grib2.gz files on the AWS S3 public data bucket. Each file represents a single timestamp and product type.\n\nIn this step:\n\nWe use urllib.request.urlopen() to download the compressed file directly from AWS\n\nWe decompress it using Python’s built-in gzip module\n\nThen we load the GRIB2 file into an xarray.DataArray using the cfgrib engine\n\nThis approach lets us work with the data directly in Python without having to manually download or unzip anything ahead of time.\n\n# Define the URL to the compressed MRMS GRIB2 file for a specific timestamp\nurl = \"https://noaa-mrms-pds.s3.amazonaws.com/CONUS/LayerCompositeReflectivity_Low_00.50/20250704/MRMS_LayerCompositeReflectivity_Low_00.50_20250704-001040.grib2.gz\"\n\n# Download the file as bytes\nresponse = urllib.request.urlopen(url)\ncompressed_file = response.read()\n\n# Decompress and load into xarray using a temporary file\nwith tempfile.NamedTemporaryFile(suffix=\".grib2\") as f:\n    # Decompress the .gz content and write to temp file\n    f.write(gzip.decompress(compressed_file))\n\n    # Load GRIB2 data as an xarray DataArray\n    data_in = xr.load_dataarray(f.name, engine='cfgrib', decode_timedelta=True)\n\n\n\n","type":"content","url":"/notebooks/ch3-txfloods#access-and-load-mrms-data","position":15},{"hierarchy":{"lvl1":"Chapter 3: July 2025 Central TX Floods","lvl2":"Set Up Reflectivity Colormap and Extract Data"},"type":"lvl2","url":"/notebooks/ch3-txfloods#set-up-reflectivity-colormap-and-extract-data","position":16},{"hierarchy":{"lvl1":"Chapter 3: July 2025 Central TX Floods","lvl2":"Set Up Reflectivity Colormap and Extract Data"},"content":"This section gets the MRMS reflectivity data ready for plotting and builds a map to visualize it.\n\nColormap and Normalization:We use MetPy’s built-in NWSReflectivity colormap, which is designed for radar data in dBZ. The get_with_steps() function sets up color breaks every 5 dBZ — a common setup in operational radar displays.\n\nExtract Coordinates and Data:We pull out the longitude, latitude, and reflectivity values from the data array. If the coordinates are in 1D (which happens in some MRMS products), we convert them to 2D using np.meshgrid() so they work with the plotting function.\n\nMask Low Reflectivity Values:Reflectivity values below 5 dBZ are masked out with ma.masked_where() to remove light noise and clutter from the map.\n\nSet Up the Map:We create a static figure using matplotlib and Cartopy, with a PlateCarree projection centered over Texas. The domain is narrowed with set_extent() to focus on the region of interest.\n\nAdd Map Features:Coastlines, country borders, and U.S. state lines are added to give the plot geographic context.\n\nPlot the Reflectivity:The reflectivity field is plotted using pcolormesh() with our defined colormap and normalization. A horizontal colorbar is added to show the dBZ scale.\n\nFinal Touches:We include a plot title and display the final figure with \n\nplt.show().\n\nrefl_norm, refl_cmap = ctables.registry.get_with_steps('NWSReflectivity', 5, 5)\n\n# 2. Extract coords & data\nlons = data_in.longitude.values\nlats = data_in.latitude.values\nrefl = data_in.values\n\n# If coords are 1D, make them 2D\nif lons.ndim == 1 and lats.ndim == 1:\n    lons, lats = np.meshgrid(lons, lats)\n\n# 3. Plot\nfig = plt.figure(figsize=(10, 8))\nax = plt.axes(projection=ccrs.PlateCarree())\nax.set_extent([-106, -93, 25, 36], crs=ccrs.PlateCarree())\n\nax.add_feature(cfeature.COASTLINE, linewidth=1)\nax.add_feature(cfeature.BORDERS, linewidth=1)\nax.add_feature(cfeature.STATES, linewidth=0.5)\n\nmesh = ax.pcolormesh(\n    lons, lats, ma.masked_where(refl<5,refl),\n    cmap=refl_cmap,\n    norm=refl_norm,\n    transform=ccrs.PlateCarree()\n)\n\ncb = plt.colorbar(mesh, ax=ax, orientation='horizontal', pad=0.05, aspect=50)\ncb.set_label('Reflectivity (dBZ)')\n\nplt.title('MRMS Layer Composite Reflectivity – Texas', fontsize=14)\nplt.show()\n\n\n","type":"content","url":"/notebooks/ch3-txfloods#set-up-reflectivity-colormap-and-extract-data","position":17},{"hierarchy":{"lvl1":"Chapter 3: July 2025 Central TX Floods","lvl3":"Select Timestamps and Animate Reflectivity","lvl2":"Set Up Reflectivity Colormap and Extract Data"},"type":"lvl3","url":"/notebooks/ch3-txfloods#select-timestamps-and-animate-reflectivity","position":18},{"hierarchy":{"lvl1":"Chapter 3: July 2025 Central TX Floods","lvl3":"Select Timestamps and Animate Reflectivity","lvl2":"Set Up Reflectivity Colormap and Extract Data"},"content":"This part of the notebook automates the process of pulling in multiple MRMS reflectivity files and creating an animation to show how low-level reflectivity changed over time.\n\nCheck for Available Timestamps:We define a time range from July 4 to July 7, 2025, and loop through it in 30-minute steps. For each time, we generate a file path from the AWS-hosted MRMS archive and try downloading it. If the file exists, we save that timestamp. For this demo, we stop after grabbing six valid files.\n\nSet Up the Map and Colormap:After collecting the timestamps, we build a static map using Cartopy (Plate Carree projection), focused on Texas and surrounding areas. We also apply the MetPy NWSReflectivity colormap and mask out any reflectivity values below 5 dBZ to clean up the visualization.\n\nDownload and Plot Each Frame:For each timestamp:\n\nThe corresponding .grib2.gz file is downloaded and decompressed.\n\nWe extract the reflectivity data and coordinates using xarray.\n\nIf the coordinate arrays are 1D, we convert them to 2D for plotting.\n\nThe reflectivity data is plotted with pcolormesh(), and we add a dynamic title showing the UTC time.\n\nEach frame (plot + title) is saved for the animation.\n\nBuild the Animation:We use ArtistAnimation from Matplotlib to stitch the frames together into an animation. plt.close(fig) is used beforehand to prevent Jupyter from displaying a static image under the animation.\n\nExport as a GIF:The finished animation is saved as a .gif using Pillow so it can be easily shared or embedded in a presentation.\n\nThe result is a short radar loop showing how reflectivity evolved during the early hours of July 4, 2025, which is a period tied to widespread heavy rain and flash flooding across Central Texas.\n\nstart = datetime(2025, 7, 4, 0, 10, 40)\nend = datetime(2025, 7, 7, 0, 0, 0)\nstep = timedelta(minutes=30)\n\nvalid_timestamps = []\nt = start\n\nprint(\"Checking for available MRMS files...\\n\")\n\nwhile t <= end and len(valid_timestamps) < 6:\n    ts = t.strftime(\"%Y%m%d-%H%M%S\")\n    date_str = ts[:8]\n    url = (\n        f\"https://noaa-mrms-pds.s3.amazonaws.com/CONUS/LayerCompositeReflectivity_Low_00.50/\"\n        f\"{date_str}/MRMS_LayerCompositeReflectivity_Low_00.50_{ts}.grib2.gz\"\n    )\n    try:\n        resp = urllib.request.urlopen(url, timeout=5)\n        print(f\" Found: {ts}\")\n        valid_timestamps.append(ts)\n    except:\n        print(f\" Missing: {ts}\")\n    t += step\n\nprint(\"\\n Selected 6 timestamps:\")\nfor ts in valid_timestamps:\n    print(ts)\n\n\n# Define the 6 known working timestamps (one every hour)\ntimestamps = [\n    \"20250704-001040\",\n    \"20250704-011040\",\n    \"20250704-031040\",\n    \"20250704-054040\",\n    \"20250704-071040\",\n    \"20250704-091040\"\n]\n\n# Set up colormap and normalization for reflectivity\nrefl_norm, refl_cmap = ctables.registry.get_with_steps('NWSReflectivity', 5, 5)\n\n# Initialize animation container\nframes_six = []\n\n# Set up static map\nfig = plt.figure(figsize=(10, 8))\nax = plt.axes(projection=ccrs.PlateCarree())\nax.set_extent([-106, -93, 25, 36], crs=ccrs.PlateCarree())\nax.add_feature(cfeature.COASTLINE, linewidth=1)\nax.add_feature(cfeature.BORDERS, linewidth=1)\nax.add_feature(cfeature.STATES, linewidth=0.5)\n\n# Loop through timestamps and collect frames\nfor ts in timestamps:\n    print(f\"Loading {ts}...\")\n    try:\n        url = (\n            f\"https://noaa-mrms-pds.s3.amazonaws.com/CONUS/LayerCompositeReflectivity_Low_00.50/\"\n            f\"{ts[:8]}/MRMS_LayerCompositeReflectivity_Low_00.50_{ts}.grib2.gz\"\n        )\n        response = urllib.request.urlopen(url)\n        compressed_file = response.read()\n\n        with tempfile.NamedTemporaryFile(suffix=\".grib2\") as f:\n            f.write(gzip.decompress(compressed_file))\n            f.flush()\n            data_in = xr.load_dataarray(f.name, engine='cfgrib', decode_timedelta=True)\n\n        # Extract coordinates and reflectivity data\n        lons = data_in.longitude.values\n        lats = data_in.latitude.values\n        refl = data_in.values\n\n        if lons.ndim == 1 and lats.ndim == 1:\n            lons, lats = np.meshgrid(lons, lats)\n\n        # Plot single frame (no show)\n        mesh = ax.pcolormesh(\n            lons, lats, ma.masked_where(refl < 5, refl),\n            cmap=refl_cmap,\n            norm=refl_norm,\n            transform=ccrs.PlateCarree()\n        )\n\n        # Create a title text that updates with each frame\n        timestamp_label = f\"{ts[:4]}-{ts[4:6]}-{ts[6:8]} {ts[9:11]}:{ts[11:13]} UTC\"\n        title = ax.text(\n            0.5, 1.02,\n            f\"MRMS Low-Level Reflectivity (dBZ) – {timestamp_label}\",\n            transform=ax.transAxes,\n            ha=\"center\", va=\"bottom\", fontsize=14\n        )\n\n        # Save both mesh and title to animation frame\n        frames_six.append([mesh, title])\n\n    except Exception as e:\n        print(f\"Skipped {ts} → {e}\")\n        continue\n\n# Create and display an animation\nplt.close(fig)\nanim = ArtistAnimation(fig, frames_six, interval=500, blit=True)\nHTML(anim.to_jshtml())\n\n# Save animation as a .gif\nanim.save(\"mrms_reflectivity_animation.gif\", writer=PillowWriter(fps=2))\n\nprint(\"Animation saved as 'mrms_reflectivity_animation.gif'\")\n\n\n","type":"content","url":"/notebooks/ch3-txfloods#select-timestamps-and-animate-reflectivity","position":19},{"hierarchy":{"lvl1":"Chapter 3: July 2025 Central TX Floods","lvl2":"Reflectivity Animation: Summary"},"type":"lvl2","url":"/notebooks/ch3-txfloods#reflectivity-animation-summary","position":20},{"hierarchy":{"lvl1":"Chapter 3: July 2025 Central TX Floods","lvl2":"Reflectivity Animation: Summary"},"content":"We demonstrated how to access and animate low-level composite reflectivity data from the MRMS system using open-source Python tools. We focused on a short sequence from the July 4, 2025, Central Texas flood event to highlight how reflectivity features evolved.\n\nThis workflow is a flexible starting point for working with radar data, especially for case studies or quick visual diagnostics. The next section will continue building on this analysis with more approaches to explore the MRMS dataset!\n\n","type":"content","url":"/notebooks/ch3-txfloods#reflectivity-animation-summary","position":21},{"hierarchy":{"lvl1":"Chapter 3: July 2025 Central TX Floods","lvl2":"Comparison with ASOS Data"},"type":"lvl2","url":"/notebooks/ch3-txfloods#comparison-with-asos-data","position":22},{"hierarchy":{"lvl1":"Chapter 3: July 2025 Central TX Floods","lvl2":"Comparison with ASOS Data"},"content":"\n\n\naws = s3fs.S3FileSystem(anon=True)\npath = aws.ls(\"noaa-mrms-pds/CONUS/RadarOnly_QPE_24H_00.00/20250705/\")[0]\n\nresponse = urllib.request.urlopen(\"https://noaa-mrms-pds.s3.amazonaws.com/\" + path[14:])\ncompressed_file = response.read()\n\nwith tempfile.NamedTemporaryFile(suffix=\".grib2\") as f:\n            f.write(gzip.decompress(compressed_file))\n            f.flush()\n            data = xr.load_dataarray(f.name, engine='cfgrib', decode_timedelta=True)\n\n# Set lat and lon bounds\nlat_min, lat_max = 28, 33\nlon_min, lon_max = -102.5, -96.5\n\n# Subset data and delete original\nsubset = data.sel(\n    latitude=slice(lat_max, lat_min),\n    longitude=slice(360 - abs(lon_min), 360 - abs(lon_max)),\n).copy(deep=True)\n\n# Remove original data to free memory\ndel data\n\nurl = \"https://mesonet.agron.iastate.edu/cgi-bin/request/asos.py\"\n\nparams = {\n    \"network\": \"TX_ASOS\",  # Or just use \"ASOS\" for all U.S.\n    \"data\": \"p01i\",\n    \"year1\": \"2025\",\n    \"month1\": \"7\",\n    \"day1\": \"4\",\n    \"year2\": \"2025\",\n    \"month2\": \"7\",\n    \"day2\": \"4\",\n    \"format\": \"comma\",\n    \"latlon\": \"yes\",\n}\n\n# Make the request\nresponse = requests.get(url, params=params)\n\n# Parse CSV from response text\ndf = pd.read_csv(StringIO(response.text), skiprows=5)\n\n# Drop missing precip values\ndf = df[df[\"p01i\"] != \"M\"]\ndf[\"p01i\"] = df[\"p01i\"].astype(float)\n\n# Convert timestamp to datetime\ndf[\"valid\"] = pd.to_datetime(df[\"valid\"])\n\n# Group by station and sum hourly precip\ndaily_precip = (\n    df.groupby([\"station\", \"lon\", \"lat\"])[\"p01i\"]\n    .sum()\n    .reset_index()\n    .rename(columns={\"p01i\": \"precip_in\"})\n)\n\ndaily_precip\n\n# Set levels\nlevels = [\n    0,\n    0.01,\n    0.1,\n    0.25,\n    0.50,\n    1,\n    1.5,\n    2,\n    2.5,\n    3,\n    4,\n    5,\n    6,\n    7,\n    8,\n    9,\n    10,\n    12,\n    14,\n    16,\n    18,\n]\n\n# Create a normalization object\ncmap = plt.get_cmap(\"ChaseSpectral\")  # Use full-resolution colormap\nnorm = mcolors.BoundaryNorm(levels, ncolors=cmap.N, clip=False)\n\nfig = plt.figure(figsize=(10, 8))\nax = plt.axes(projection=ccrs.PlateCarree())\nax.set_extent([lon_min, lon_max, lat_min, lat_max], crs=ccrs.PlateCarree())\n\nax.add_feature(cfeature.COASTLINE, linewidth=1, edgecolor=\"white\")\nax.add_feature(cfeature.BORDERS, linewidth=1, edgecolor=\"white\")\nax.add_feature(cfeature.STATES, linewidth=0.5, edgecolor=\"white\")\n# Add counties\nax.add_feature(\n    cfeature.NaturalEarthFeature(\n        category=\"cultural\",\n        name=\"admin_2_counties\",\n        scale=\"10m\",\n        facecolor=\"none\",\n        edgecolor=\"white\",\n        linewidth=0.3,\n    )\n)\n\nmesh = ax.pcolormesh(\n    subset.longitude,\n    subset.latitude,\n    subset / 25.4,  # Convert mm to inches\n    norm=norm,\n    cmap=\"ChaseSpectral\",\n    transform=ccrs.PlateCarree(),\n)\n\n# Overlay ASOS bubble plot\nsc = ax.scatter(\n    daily_precip[\"lon\"],\n    daily_precip[\"lat\"],\n    s=daily_precip[\"precip_in\"] * 40,  # adjust bubble size scaling\n    c=daily_precip[\"precip_in\"],\n    cmap=cmap,\n    norm=norm,\n    alpha=0.9,\n    edgecolor=\"black\",\n    linewidth=0.4,\n    transform=ccrs.PlateCarree(),\n    zorder=10\n)\n\nfor size in [0.1, 0.5, 1.0, 2.0, 4.0]:\n    ax.scatter([], [], s=size * 40, c='gray', alpha=0.6, edgecolor='black', label=f\"{size:.1f}\\\"\")\n\nax.legend(scatterpoints=1, loc=\"lower right\", title=\"ASOS Daily Rain\", frameon=True)\n\n\ncb = plt.colorbar(\n    mesh, ax=ax, orientation=\"horizontal\", pad=0.05, aspect=50, shrink=0.8\n)\ncb.set_label(\"Rainfall (in)\")\n# Add tick labels to colorbar\ncb.set_ticks(levels)\ncb.set_ticklabels([f\"{level:.2f}\" for level in levels])\ncb.ax.tick_params(labelsize=10, rotation=45)\n\nplt.title(\"MRMS 24-Hour Radar Only QPE vs. ASOS Stations (July 4, 2025)\", fontsize=16)\nplt.tight_layout()\n\n# Convert lat/lon coordinates from MRMS subset\nlats = subset.latitude.values\nlons = subset.longitude.values\n\n# Ensure correct orientation (ascending order for interpolator)\nif lats[0] > lats[-1]:\n    lats = lats[::-1]\n    subset = subset[::-1, :]\n\n# Create interpolator (convert to inches)\ninterp_func = RegularGridInterpolator(\n    (lats, lons), (subset / 25.4).values, bounds_error=False, fill_value=np.nan\n)\n\n# Convert ASOS longitude from degrees west to degrees east (0–360)\ndaily_precip[\"lon_east\"] = daily_precip[\"lon\"].apply(lambda x: x if x >= 0 else 360 + x)\n\nstation_coords = list(zip(daily_precip[\"lat\"], daily_precip[\"lon_east\"]))\ndaily_precip[\"mrms_in\"] = interp_func(station_coords)\n\n\ndaily_precip[\"bias\"] = daily_precip[\"precip_in\"] - daily_precip[\"mrms_in\"]\n\n\n# Compute bias normalization\nvmax = np.nanmax(np.abs(daily_precip[\"bias\"]))\n\n# Define bias levels (nonlinear, symmetric)\nbias_levels = [-20, -10, -5, -2, -1, -0.5, -0.1, 0, 0.1, 0.5, 1, 2, 5, 10, 20]\n\n# Create BoundaryNorm\nnorm_bias = mcolors.BoundaryNorm(bias_levels, ncolors=plt.get_cmap(\"balance\").N, clip=True)\n\n\n# Compute scatter sizes based on bias magnitude (optional scaling factor)\nsizes = np.sqrt(np.abs(daily_precip[\"bias\"])) * 150  # tweak 100 as needed\n\n# Create figure and axis\nfig = plt.figure(figsize=(10, 8))\nax = plt.axes(projection=ccrs.PlateCarree())\nax.set_extent([lon_min, lon_max, lat_min, lat_max], crs=ccrs.PlateCarree())\n\n# Basemap features\nax.add_feature(cfeature.COASTLINE, linewidth=1, edgecolor=\"white\")\nax.add_feature(cfeature.BORDERS, linewidth=1, edgecolor=\"white\")\nax.add_feature(cfeature.STATES, linewidth=0.5, edgecolor=\"white\")\nax.add_feature(\n    cfeature.NaturalEarthFeature(\n        category=\"cultural\",\n        name=\"admin_2_counties\",\n        scale=\"10m\",\n        facecolor=\"none\",\n        edgecolor=\"white\",\n        linewidth=0.3,\n    )\n)\n\n# Pcolormesh for MRMS\nmesh = ax.pcolormesh(\n    subset.longitude,\n    subset.latitude,\n    subset / 25.4,  # Convert mm to inches\n    norm=norm,\n    cmap=\"ChaseSpectral\",\n    transform=ccrs.PlateCarree(),\n)\n\nsc = ax.scatter(\n    daily_precip[\"lon\"],\n    daily_precip[\"lat\"],\n    c=daily_precip[\"bias\"],\n    s=sizes,\n    cmap=\"balance\",  # cmocean or any diverging colormap\n    norm=norm_bias,\n    edgecolor=\"black\",\n    linewidth=0.4,\n    transform=ccrs.PlateCarree(),\n    zorder=10,\n)\n\n# Add text labels for each station's bias\nfor _, row in daily_precip.iterrows():\n    bias_val = row[\"bias\"]\n    if not np.isnan(bias_val):\n        ax.text(\n            row[\"lon\"], row[\"lat\"],\n            f\"{bias_val:.2f}\\\"\",\n            fontsize=6,\n            ha=\"center\", va=\"center\",\n            transform=ccrs.PlateCarree(),\n            zorder=11,\n            color=\"white\" if abs(bias_val) > 0.5 else \"black\",  # adjust for contrast\n        )\n\n\n\n# Bias colorbar (scatter)\ncb1 = plt.colorbar(sc, ax=ax, orientation=\"horizontal\", pad=0.05, shrink=0.8, aspect=50)\ncb1.set_label(\"ASOS - MRMS Bias (in)\")\ncb1.set_ticks(bias_levels)\ncb1.ax.tick_params(labelsize=10)\n\n\n\n# Add second colorbar (MRMS QPE from pcolormesh)\ncb2 = plt.colorbar(mesh, ax=ax, orientation=\"vertical\", pad=0.02, shrink=0.8)\ncb2.set_label(\"MRMS QPE (in)\")\ncb2.ax.tick_params(labelsize=10)\n\n# Title and layout\nax.set_title(\"ASOS vs. MRMS Radar-Only QPE Bias (July 4, 2025)\", fontsize=16)\nplt.tight_layout()\n\n\n","type":"content","url":"/notebooks/ch3-txfloods#comparison-with-asos-data","position":23},{"hierarchy":{"lvl1":"Chapter 3: July 2025 Central TX Floods","lvl2":"Compare MRMS Radar-Only to Pass 1 and Pass 2 QPE"},"type":"lvl2","url":"/notebooks/ch3-txfloods#compare-mrms-radar-only-to-pass-1-and-pass-2-qpe","position":24},{"hierarchy":{"lvl1":"Chapter 3: July 2025 Central TX Floods","lvl2":"Compare MRMS Radar-Only to Pass 1 and Pass 2 QPE"},"content":"\n\ndef load_mrms_qpe_24h(date_str, product=\"RadarOnly_QPE_24H_00.00\",\n                      lat_bounds=(28, 33), lon_bounds=(-102.5, -96.5)):\n    \"\"\"\n    Loads and subsets MRMS 24-hour radar-only QPE data from AWS.\n\n    Parameters:\n    ----------\n    date_str : str\n        Date in 'YYYYMMDD' format (e.g., '20250705')\n    product : str\n        MRMS product folder (default: 'RadarOnly_QPE_24H_00.00' for Pass1)\n    lat_bounds : tuple\n        Tuple of (lat_min, lat_max)\n    lon_bounds : tuple\n        Tuple of (lon_min, lon_max) in degrees west\n\n    Returns:\n    -------\n    subset : xarray.DataArray\n        Subset of MRMS QPE field for given domain and date\n    \"\"\"\n\n    # Access file listing on AWS\n    aws = s3fs.S3FileSystem(anon=True)\n    mrms_path = f\"noaa-mrms-pds/CONUS/{product}/{date_str}/\"\n    file_list = aws.ls(mrms_path)\n\n    # Only grab the first GRIB2 file for the day (should end in 0000.grib2.gz)\n    grib_path = next((f for f in file_list if f.endswith(\".grib2.gz\")), None)\n    if grib_path is None:\n        raise FileNotFoundError(f\"No GRIB2 file found for {date_str} in {product}\")\n\n    url = \"https://noaa-mrms-pds.s3.amazonaws.com/\" + grib_path[len(\"noaa-mrms-pds/\"):]\n    response = urllib.request.urlopen(url)\n    compressed_file = response.read()\n\n    with tempfile.NamedTemporaryFile(suffix=\".grib2\") as f:\n        f.write(gzip.decompress(compressed_file))\n        f.flush()\n        data = xr.load_dataarray(f.name, engine='cfgrib', decode_timedelta=True)\n\n    # Subset domain\n    lat_min, lat_max = lat_bounds\n    lon_min, lon_max = lon_bounds\n    subset = data.sel(\n        latitude=slice(lat_max, lat_min),\n        longitude=slice(360 - abs(lon_min), 360 - abs(lon_max)),\n    ).copy(deep=True)\n\n    # Clean up\n    del data\n\n    return subset\n\nsubset_pass1 = load_mrms_qpe_24h(\"20250705\", product=\"MultiSensor_QPE_24H_Pass1_00.00\")\nsubset_pass2 = load_mrms_qpe_24h(\"20250705\", product=\"MultiSensor_QPE_24H_Pass2_00.00\")\n\n# Define levels and normalization\nlevels = [\n    0, 0.01, 0.1, 0.25, 0.50, 1, 1.5, 2, 2.5,\n    3, 4, 5, 6, 7, 8, 9, 10, 12, 14, 16, 18\n]\ncmap = plt.get_cmap(\"ChaseSpectral\")\nnorm = mcolors.BoundaryNorm(levels, ncolors=cmap.N, clip=False)\n\n# Create figure and subplots\nfig, axes = plt.subplots(\n    1, 3, figsize=(15, 6),\n    subplot_kw={\"projection\": ccrs.PlateCarree()}\n)\n\n# Title mapping\ntitles = [\n    \"Radar-Only QPE\",\n    \"Gauge-Corrected QPE (Pass 1)\",\n    \"Gauge-Corrected QPE (Pass 2)\"\n]\n\n# Loop through datasets and plot\nfor ax, data, title in zip(\n    axes,\n    [subset, subset_pass1, subset_pass2],\n    titles\n):\n    ax.set_extent([lon_min, lon_max, lat_min, lat_max], crs=ccrs.PlateCarree())\n\n    # Basemap features\n    ax.add_feature(cfeature.COASTLINE, linewidth=1, edgecolor=\"white\")\n    ax.add_feature(cfeature.BORDERS, linewidth=1, edgecolor=\"white\")\n    ax.add_feature(cfeature.STATES, linewidth=0.5, edgecolor=\"white\")\n    ax.add_feature(\n        cfeature.NaturalEarthFeature(\n            category=\"cultural\",\n            name=\"admin_2_counties\",\n            scale=\"10m\",\n            facecolor=\"none\",\n            edgecolor=\"white\",\n            linewidth=0.3,\n        )\n    )\n\n    # Pcolormesh plot\n    mesh = ax.pcolormesh(\n        data.longitude,\n        data.latitude,\n        data / 25.4,  # mm to inches\n        norm=norm,\n        cmap=cmap,\n        transform=ccrs.PlateCarree(),\n    )\n\n    ax.set_title(title, fontsize=13)\n\n# Shared colorbar below all plots\ncb = fig.colorbar(\n    mesh, ax=axes, orientation=\"horizontal\", pad=0.08, aspect=50, shrink=0.8\n)\ncb.set_label(\"24-Hour Rainfall (in)\", fontsize=12)\ncb.set_ticks(levels)\ncb.set_ticklabels([f\"{level:.2f}\" for level in levels])\ncb.ax.tick_params(labelsize=10, rotation=45)\n\nplt.suptitle(\"MRMS 24-Hour QPE Products (July 4, 2025)\", fontsize=16)\nplt.tight_layout(rect=[0, 0.25, 1, 0.98])  # leave space for suptitle and colorbar\nplt.show()\n\n\n# Compute differences in inches\nbias_pass1 = (subset_pass1 - subset) / 25.4\nbias_pass2 = (subset_pass2 - subset) / 25.4\n\n# Define nonlinear boundaries for bias (symmetric)\nbias_levels = [-16, -10, -5, -2, -1, -0.5, -0.1, 0, 0.1, 0.5, 1, 2, 5, 10, 16]\nnorm_bias = mcolors.BoundaryNorm(bias_levels, ncolors=plt.get_cmap(\"balance\").N, clip=True)\n\n# Create figure and subplots\nfig, axes = plt.subplots(\n    1, 2, figsize=(12, 6), constrained_layout=True,\n    subplot_kw={\"projection\": ccrs.PlateCarree()}\n)\n\n# Titles\ntitles = [\n    \"Pass 1 – Radar-Only Bias (in)\",\n    \"Pass 2 – Radar-Only Bias (in)\"\n]\n\n# Loop through plots\nfor ax, bias_data, title in zip(\n    axes,\n    [bias_pass1, bias_pass2],\n    titles\n):\n    ax.set_extent([lon_min, lon_max, lat_min, lat_max], crs=ccrs.PlateCarree())\n\n    # Basemap features\n    ax.add_feature(cfeature.COASTLINE, linewidth=1, edgecolor=\"white\")\n    ax.add_feature(cfeature.BORDERS, linewidth=1, edgecolor=\"white\")\n    ax.add_feature(cfeature.STATES, linewidth=0.5, edgecolor=\"white\")\n    ax.add_feature(\n        cfeature.NaturalEarthFeature(\n            category=\"cultural\",\n            name=\"admin_2_counties\",\n            scale=\"10m\",\n            facecolor=\"none\",\n            edgecolor=\"white\",\n            linewidth=0.3,\n        )\n    )\n\n    # Pcolormesh\n    mesh = ax.pcolormesh(\n        bias_data.longitude,\n        bias_data.latitude,\n        bias_data,\n        cmap=\"balance\",  # diverging colormap\n        norm=norm_bias,\n        transform=ccrs.PlateCarree(),\n    )\n\n    ax.set_title(title, fontsize=13)\n\n# Shared colorbar\ncb = fig.colorbar(\n    mesh, ax=axes, orientation=\"horizontal\", pad=0.08, aspect=50, shrink=0.8\n)\ncb.set_label(\"Gauge-Corrected Bias from Radar-Only QPE (in)\", fontsize=12)\ncb.set_ticks(bias_levels)\ncb.ax.tick_params(labelsize=10, rotation=45)\n\n# Suptitle and layout\nplt.suptitle(\"MRMS 24-Hour Gauge Correction Bias (July 4, 2025)\", fontsize=16)\nplt.show()\n","type":"content","url":"/notebooks/ch3-txfloods#compare-mrms-radar-only-to-pass-1-and-pass-2-qpe","position":25},{"hierarchy":{"lvl1":"Chapter 5: Real-time MRMS Visualization"},"type":"lvl1","url":"/notebooks/ch4-realtimedata","position":0},{"hierarchy":{"lvl1":"Chapter 5: Real-time MRMS Visualization"},"content":"\n\n","type":"content","url":"/notebooks/ch4-realtimedata","position":1},{"hierarchy":{"lvl1":"Chapter 5: Real-time MRMS Visualization"},"type":"lvl1","url":"/notebooks/ch4-realtimedata#chapter-5-real-time-mrms-visualization","position":2},{"hierarchy":{"lvl1":"Chapter 5: Real-time MRMS Visualization"},"content":"This chapter walks you through the process of accessing and visualizing near real-time Multi-Radar/Multi-Sensor System (MRMS) data from Amazon Web Services (AWS). You will select a region and radar product from a list of pre-set options, retrieve the latest data corresponding to your selections, and display it in an interactive plot.","type":"content","url":"/notebooks/ch4-realtimedata#chapter-5-real-time-mrms-visualization","position":3},{"hierarchy":{"lvl1":"Chapter 5: Real-time MRMS Visualization","lvl3":"Purpose"},"type":"lvl3","url":"/notebooks/ch4-realtimedata#purpose","position":4},{"hierarchy":{"lvl1":"Chapter 5: Real-time MRMS Visualization","lvl3":"Purpose"},"content":"To provide hands-on experience in requesting and working with near real-time MRMS data from AWS S3.","type":"content","url":"/notebooks/ch4-realtimedata#purpose","position":5},{"hierarchy":{"lvl1":"Chapter 5: Real-time MRMS Visualization","lvl3":"Audience"},"type":"lvl3","url":"/notebooks/ch4-realtimedata#audience","position":6},{"hierarchy":{"lvl1":"Chapter 5: Real-time MRMS Visualization","lvl3":"Audience"},"content":"Users with at least 5 GB of memory in their computing environment and a basic familiarity with MRMS concepts.No programming experience is necessary to run the notebook, but a basic knowledge of Python (especially xarray) will help you apply these skills!","type":"content","url":"/notebooks/ch4-realtimedata#audience","position":7},{"hierarchy":{"lvl1":"Chapter 5: Real-time MRMS Visualization","lvl3":"Expected Outcome"},"type":"lvl3","url":"/notebooks/ch4-realtimedata#expected-outcome","position":8},{"hierarchy":{"lvl1":"Chapter 5: Real-time MRMS Visualization","lvl3":"Expected Outcome"},"content":"By the end of this chapter, you will produce an interactive visualization of MRMS imagery for your chosen region and product. If you wish to continue working with near real-time MRMS data beyond this notebook, there are three bonus challenges at the end of the notebook that encourage the user to further apply their skills.","type":"content","url":"/notebooks/ch4-realtimedata#expected-outcome","position":9},{"hierarchy":{"lvl1":"Chapter 5: Real-time MRMS Visualization","lvl3":"Estimated Time"},"type":"lvl3","url":"/notebooks/ch4-realtimedata#estimated-time","position":10},{"hierarchy":{"lvl1":"Chapter 5: Real-time MRMS Visualization","lvl3":"Estimated Time"},"content":"15 minutes — Run the notebook and review the code.\n\n30 minutes — Build enough familiarity to reproduce the workflow independently and begin to tackle the bonus challenges.\n\n2 hours - Complete all bonus steps and begin to integrate these concepts into your own workflow.\n\n\n\n","type":"content","url":"/notebooks/ch4-realtimedata#estimated-time","position":11},{"hierarchy":{"lvl1":"Chapter 5: Real-time MRMS Visualization","lvl2":"📦 Imports"},"type":"lvl2","url":"/notebooks/ch4-realtimedata#id-imports","position":12},{"hierarchy":{"lvl1":"Chapter 5: Real-time MRMS Visualization","lvl2":"📦 Imports"},"content":"\n\n# Packages required to request and open data from AWS S3\nimport s3fs\nimport urllib\nimport tempfile\nimport gzip\nimport xarray as xr\n\n# Packages required for data visualization\nimport datetime\nfrom datetime import timezone\nimport numpy.ma as ma\nfrom metpy.plots import ctables\nimport numpy as np\nimport holoviews as hv\nimport pandas as pd\nimport panel as pn\nimport hvplot.xarray \nimport matplotlib.colors as mcls\nfrom matplotlib.colors import Normalize\n\nhv.extension(\"bokeh\")\npn.extension()\n\n\n\n","type":"content","url":"/notebooks/ch4-realtimedata#id-imports","position":13},{"hierarchy":{"lvl1":"Chapter 5: Real-time MRMS Visualization","lvl2":"🌧️ About MRMS"},"type":"lvl2","url":"/notebooks/ch4-realtimedata#id-about-mrms","position":14},{"hierarchy":{"lvl1":"Chapter 5: Real-time MRMS Visualization","lvl2":"🌧️ About MRMS"},"content":"\n\nThe Multi-Radar/Multi-Sensor System (MRMS) produces products for public infrastructure, weather forecasts and warnings, aviation, and numerical weather prediction. It provides high spatial (1-km) and temporal (2-min) resolution radar products at 31 vertical levels, and ingests data from numerous sources (including radar networks across the US and Canada, surface and upper air observations, lightning detection systems, satellite observations, and forecast models)\n\n1.\n\nFor more information, please refer to Chapter 1 of this project: \n\nIntroduction to MRMS.\n\n\n\n","type":"content","url":"/notebooks/ch4-realtimedata#id-about-mrms","position":15},{"hierarchy":{"lvl1":"Chapter 5: Real-time MRMS Visualization","lvl2":"☁️ About AWS and NOAA’s Open Data Dissemination Program"},"type":"lvl2","url":"/notebooks/ch4-realtimedata#id-about-aws-and-noaas-open-data-dissemination-program","position":16},{"hierarchy":{"lvl1":"Chapter 5: Real-time MRMS Visualization","lvl2":"☁️ About AWS and NOAA’s Open Data Dissemination Program"},"content":"\n\nThe Amazon Web Services Simple Storage Service (\n\nAWS S3) is a cloud-based object storage service. Through a public-private partnership with the National Oceanic and Atmospheric Administration (NOAA)'s Open Data Dissemination Program (\n\nNODD), NOAA is able to store multiple petabytes of open-access earth science data on AWS S3, including the MRMS dataset. This allows users to quickly and freely access MRMS data in real-time (with an update frequency of two minutes) without having to download the data to their personal systems.\n\nBecause of this partnership, we can access the data as an anonymous client -- no login required!\n\n# Initialize the S3 filesystem as anonymous\naws = s3fs.S3FileSystem(anon=True)\n\nYou can explore the S3 bucket that holds MRMS data to assess data availability and structure -- just visit \n\nthis link, which takes you to the MRMS bucket.\n\nHint\n\nYou can run aws.ls to see the file structure in code. Try it yourself!# Example code to execute: first five items in the 'CONUS' directory of the MRMS bucket on S3\nprint(aws.ls(f'noaa-mrms-pds/CONUS/')[0:5])\n\n\n\n","type":"content","url":"/notebooks/ch4-realtimedata#id-about-aws-and-noaas-open-data-dissemination-program","position":17},{"hierarchy":{"lvl1":"Chapter 5: Real-time MRMS Visualization","lvl2":"🎯 Data selection"},"type":"lvl2","url":"/notebooks/ch4-realtimedata#id-data-selection","position":18},{"hierarchy":{"lvl1":"Chapter 5: Real-time MRMS Visualization","lvl2":"🎯 Data selection"},"content":"For ease of use, I’ve integrated widgets (drop-down menus!) that allow you to make selections from AWS, and refined a selection of data variables as a demonstration. You can choose between the QC’d Merged Reflectivity Composite, a 12-hour multisensor QPE from Pass 2, and the Probability of Severe Hail.\n\nNow, you have the option to select a region and a radar product to visualize in near real-time. Go ahead and run the cell below, then use the created drop-down menus to select a region, a radar product.\n\nMerged Reflectivity CompositeDescription: The maximum reflectivity in a vertical column, from the merged product.Spatial Resolution: 0.01º Latitude (~1.11 km) x 0.01º Longitude (~1.01 km at 25ºN and 0.73 km at 49ºN)Temporal Resolution: 2 minutesAWS Variable: “MergedReflectivityQCComposite_00.50”\n\n12-hour Multisensor Quantitative Precipitation Estimate (Pass 2)\nDescription: 12h rainfall accumulation estimate, using data from rain gauges and NWP QPF (HRRR/RAP blend for CONUS). This is the Pass 2 dataset, which has a higher latency but includes more rain gauge data than Pass 1 (Pass 1 has 20-minute latency and includes 10% of gauges, while Pass 2 has 60-minute latency and includes 60% of gauges).Spatial Resolution: 1km x 1kmTemporal Resolution: 60 minutesAWS Variable: “MultiSensor_QPE_12H_Pass2_00.00”\n\nProbability of Severe Hail\nDescription: The probability of 0.75-inch diameter hail.Spatial Resolution: 0.01º Latitude (~1.11 km) x 0.01º Longitude (~1.01 km at 25ºN and 0.73 km at 49ºN)Temporal Resolution: 2 minutesAWS Variable: “POSH_00.50”\n\n# Define dropdown options -- region and product from the AWS structure\nregion_options = [\n    \"CONUS\",\n    \"ALASKA\",\n    \"CARIB\",\n    \"GUAM\",\n    \"HAWAII\"\n]\n\nproduct_options = [\n    \"MergedReflectivityQCComposite_00.50\",\n    \"MultiSensor_QPE_12H_Pass2_00.00\",\n    \"POSH_00.50\"\n]\n\n# Create dropdown widgets for user selection\nregion_choice = pn.widgets.Select(name='Region', options=region_options, width=325)\nproduct_choice = pn.widgets.Select(name='MRMS product', options=product_options, width=325)\n\npn.Column(region_choice, product_choice)\n\n🎉 Congratulations, you’ve made your data selection!\n\nCaution\n\nIf you re-run the cell that generated your drop-down menus (above), it will reset your selection. Click into the next cell (below) and continue running the notebook from there!\n\n# Retrieve the user selection from 'Region' \nregion = region_choice.value\n\n# Retrieve the user selection from 'MRMS product'\nproduct = product_choice.value\n\n\n\n","type":"content","url":"/notebooks/ch4-realtimedata#id-data-selection","position":19},{"hierarchy":{"lvl1":"Chapter 5: Real-time MRMS Visualization","lvl2":"📡 Data request"},"type":"lvl2","url":"/notebooks/ch4-realtimedata#id-data-request","position":20},{"hierarchy":{"lvl1":"Chapter 5: Real-time MRMS Visualization","lvl2":"📡 Data request"},"content":"Now that you’ve made your variable selection, it’s time to read in the data from AWS. First, we retrieve the current UTC datetime so that we can request files from today’s S3 bucket.\n\n# Retrieve the current datetime in UTC to know which bucket to query\nnow = datetime.datetime.now(datetime.UTC)\ndatestring = now.strftime('%Y%m%d')\n\nNext, we query the S3 bucket to make sure the data is available on AWS. If the following cell errors, reference \n\nthe S3 bucket to confirm that your requested region, date, and product exists and is entered correctly.\n\n# Query the S3 bucket for the available files that meet the criteria\ntry:\n    data_files = aws.ls(f'noaa-mrms-pds/{region}/{product}/{datestring}/', refresh=True)  \nexcept Exception as e:\n    print(f\"Error accessing S3 bucket: {e}\")\n    data_files = []\n\nFinally, we make the data request and read it using xarray. The following block of code finds the most recent file that fits your criteria, ensures that the file was created recently (within the past two hours), then makes the data request. The MRMS data was uploaded to S3 as a compressed grib2 file, so that’s what our program receives. This code decompresses the grib2 file and reads it using xarray, making the format more easily incorporated into our workflow.\n\nif data_files:\n    # Choose the last file from S3 for the most recent data\n    most_recent_file = data_files[-1]\n\n    # Check that the most recent file is within 2 hours of current time\n    timestamp_str = most_recent_file.split('_')[-1].replace('.grib2.gz', '')\n    dt = datetime.datetime.strptime(timestamp_str, \"%Y%m%d-%H%M%S\").replace(tzinfo=timezone.utc)\n    if abs((now - dt).total_seconds()) <= 120 * 60:\n        # Download file to memory, decompress from .gz, and read into xarray\n        try:\n            response = urllib.request.urlopen(f\"https://noaa-mrms-pds.s3.amazonaws.com/{most_recent_file[14:]}\")\n            compressed_file = response.read()\n\n            with tempfile.NamedTemporaryFile(suffix=\".grib2\") as f:\n                f.write(gzip.decompress(compressed_file))\n                f.flush()\n                data = xr.load_dataarray(f.name, engine=\"cfgrib\", decode_timedelta=True)\n        except Exception as e:\n            print(f\"Failed to process {product}: {e}\")\n\nOur MRMS data is now contained as an xarray data array in the data variable!\n\n\n\n","type":"content","url":"/notebooks/ch4-realtimedata#id-data-request","position":21},{"hierarchy":{"lvl1":"Chapter 5: Real-time MRMS Visualization","lvl2":"🗺️ Visualization"},"type":"lvl2","url":"/notebooks/ch4-realtimedata#id-visualization","position":22},{"hierarchy":{"lvl1":"Chapter 5: Real-time MRMS Visualization","lvl2":"🗺️ Visualization"},"content":"Now that we have the data read into memory using xarray, it is quite simple to plot. Here, we use hvplot to make an interactive visualization that allows the user to zoom in to a region of interest and mouse over values to better understand the product’s functionality over a specific region.\n\n# Mask data for neater visualization\ndata = data.where(data > 0, np.nan)\n\n# Get the NWS Reflectivity colormap and normalize range\nref_norm, ref_cmap = ctables.registry.get_with_steps('NWSReflectivity', 5, 5)\n\n# Convert to hex colors for Bokeh\nnorm = Normalize(vmin=ref_norm.vmin, vmax=ref_norm.vmax)\nhex_cmap = [ref_cmap(norm(val)) for val in range(ref_norm.vmin, ref_norm.vmax + 5, 5)]\nhex_cmap = [mcls.to_hex(c) for c in hex_cmap]\n\n# Plot using hvplot\nreflectivity_plot = data.hvplot.image(\n    x=\"longitude\", y=\"latitude\",\n    cmap=hex_cmap,\n    colorbar=True,\n    geo=True, \n    tiles=True, \n    alpha=0.7,\n    clim=(ref_norm.vmin, ref_norm.vmax),\n    title=f\"{product} - {pd.to_datetime(data.time.values).strftime('%b %d, %Y at %H:%M:%S')} UTC\",\n    frame_width=700,\n    frame_height=500,\n    xlabel='Longitude',\n    ylabel='Latitude',\n    tools=['hover']\n)\n\nreflectivity_plot\n\nAbove is your visualization! You can use the menu bar at the upper right side of the plot to pan around the plot, zoom in to a region of interest, and reset your selections to the default map. If you mouse over the values on the screen, you will see the latitude, longitude, and value associated with the selected product.\n\n","type":"content","url":"/notebooks/ch4-realtimedata#id-visualization","position":23},{"hierarchy":{"lvl1":"Chapter 5: Real-time MRMS Visualization","lvl2":"🏆 Bonus Challenges"},"type":"lvl2","url":"/notebooks/ch4-realtimedata#id-bonus-challenges","position":24},{"hierarchy":{"lvl1":"Chapter 5: Real-time MRMS Visualization","lvl2":"🏆 Bonus Challenges"},"content":"Congratulations on the completion of this notebook! You have successfully selected a region and product, queried the AWS S3 bucket, and visualized MRMS data in near real-time.\n\nIf you’d like to continue this analysis, I’ve provided a couple of bonus challenges. Click on the drop-down menu to view the bonus challenge according to your desired level of difficulty.\n\n🟢 Challenge (easy) -- make a new data selection\n\nUse the drop-down widgets in this notebook to plot a different product and region from your initial run!\n\n💡 Hint\n\nScroll up to the drop-down menus, make new region/product selections, and run all cells below the drop-down menus to see your new visualization!\n\n🟡 Challenge (medium) -- plot a new variable from AWS\n\nBrowse the \n\nAWS S3 bucket and the \n\nNSSL Variable Table and find an MRMS product that was not covered in this notebook. Alter the provided code to read in and plot your new variable!\n\n💡 Hints\n\nStep-by-step:\n\nDelete the widget-generating cell in the “Data selection” section.\n\nHard-code the “region” and “product” variables with the exact strings that correspond to your data product on AWS. For example:region = \"CONUS\" \nproduct = \"MergedReflectivityQCComposite_00.50\"\n\nRun the rest of the notebook cells to produce your plot.\n\nTroubleshooting:\n\nIf your data request step returns an error, go to the \n\nAWS S3 bucket and manually click through your selection. Is the data there? Did you copy the product and region variable names exactly as they are in S3?\n\nSome datasets have different values to indicate that the data is missing, range folded, or not covered. You can find this information in the \n\nNSSL talbe. If your data has unique values, you may need to mask it in the plotting step to make sure the colorbar works for your dataset.\n\n🔴 Challenge (difficult) -- create a cron job to update your MRMS plot hourly\n\nTurn this notebook into a Python script, then use cron to create an updated plot from MRMS data every hour. Incorporate this plot into a web page, send it to your friend, or try it just for fun!\n\n💡 Hints\n\nStep-by-step:\n\nDelete the widget-generating cell in the “Data selection” section.\n\nHard-code the “region” and “product” variables with the exact strings that correspond to your data product on AWS. For example:region = \"CONUS\" \nproduct = \"MergedReflectivityQCComposite_00.50\"\n\nDelete the hvplot-generating cell in the “Visualization” section.\n\nUse the static plotting code located in the appendix for your visualization, or write your own static plotting code. Change the filepath in plt.savefig() to an absolute path to ensure that your plot will be saved in a known, designated location.\n\n(optional) Delete all markdown cells in the notebook to make your code sections more clearly delineated.\n\nOrganize the import statements, removing any unnecessary imports (such as those associated with widgets and the hvplot) and duplicates.\n\nRestart the notebook, clear all outputs, and run the cells again to confirm that the output is a single, static plot with the most recent time stamp. If everything executed as expected, you may continue. If you ran into any errors, now is the time to troubleshoot!\n\nCreate a .py file, and copy your Jupyter Notebook cells chronologically into this file.\n\nNow, the exact way you go about creating a cron-ready file is up to you. You can apply your current cron workflow (if one exists), paste your current .py script into your favorite GenAI programming tool for help, or find online resources that list cron best practices.\n\nHere is what I did:\n\nOrganized my Python code into two functions: retrieve_data() and plot_data(). I execute these functions under the block if __name__ == \"__main__\":, using input from retrieve_data() as an argument to plot_data().\n\nAdded “try” and “except” blocks and logging in case of failure.\n\nSaved the Python file as mrms_cron.py, tested my code manually in its virtual environment (~/myenv/bin/python ~/scripts/mrms_cron.py ; make sure to update the file paths to reflect your own environment), then ensured that the plotting output appeared in its designated location and looked correct.\n\nMade my script executable by typing chmod +x ~/scripts/mrms_cron.py (again, make sure you enter your own file path) into the command line.\n\nEdited my crontab (in the command line: crontab -e) to run my script 10 minutes after every hour (10 * * * * /home/user/myenv/bin/python /home/user/scripts/mrms_cron.py >> /home/user/mrms_output/mrms.log 2>&1).\n\nThe next time HH:10 rolled around, I waited a couple minutes for the plot to generate, then checked the file path that I designated to contain my images. There it was!\n\n\n\n","type":"content","url":"/notebooks/ch4-realtimedata#id-bonus-challenges","position":25},{"hierarchy":{"lvl1":"Chapter 5: Real-time MRMS Visualization","lvl2":"📚 Resources and references"},"type":"lvl2","url":"/notebooks/ch4-realtimedata#id-resources-and-references","position":26},{"hierarchy":{"lvl1":"Chapter 5: Real-time MRMS Visualization","lvl2":"📚 Resources and references"},"content":"\n\nAWS Data Access:\n\nAWS S3 bucket for MRMS data\n\nMRMS Information:\n\nNSSL Product Page\n\nNSSL Variable Table\n\nNSSL Operational Product Viewer\n\n","type":"content","url":"/notebooks/ch4-realtimedata#id-resources-and-references","position":27},{"hierarchy":{"lvl1":"Chapter 5: Real-time MRMS Visualization","lvl2":"🛠️ Appendix"},"type":"lvl2","url":"/notebooks/ch4-realtimedata#id-appendix","position":28},{"hierarchy":{"lvl1":"Chapter 5: Real-time MRMS Visualization","lvl2":"🛠️ Appendix"},"content":"If you’d prefer to plot these data as a static plot, below is some sample code to kickstart your plotting journey.\n\n\"\"\"\nimport matplotlib.pyplot as plt\nimport cartopy.crs as ccrs\nimport cartopy.feature as cfeature\nimport pandas as pd\nfrom metpy.plots import ctables\n\n# Mask data for neater visualization\ndata = data.where(data > 0, np.nan)\n\n# Extract data\nlons = data.longitude\nlats = data.latitude\nvalues = data.values\ndate = pd.to_datetime(data.time.values)\n\n# Domain bounds\nminLon, maxLon = lons.min(), lons.max()\nminLat, maxLat = lats.min(), lats.max()\n\n# Setup figure and axis\nfig, ax = plt.subplots(figsize=(12, 6),\n                       subplot_kw={\"projection\": ccrs.Mercator()})\n\nax.set_extent([minLon, maxLon, minLat, maxLat], crs=ccrs.PlateCarree())\n\n# Set colors\nref_norm, ref_cmap = ctables.registry.get_with_steps(\"NWSReflectivity\", 5, 5)\nunits = \"Reflectivity (dBZ)\"\ntitle = \"MRMS Merged Reflectivity\"\n\n# Add features\nax.add_feature(cfeature.STATES, linewidth=0.5)\nax.add_feature(cfeature.BORDERS, linewidth=0.7)\n\n# Plot data\nradarplot = ax.pcolormesh(\n    lons, lats, values,\n    transform=ccrs.PlateCarree(),\n    cmap=ref_cmap, norm=ref_norm,\n    shading=\"auto\"\n)\n\n# Colorbar\ncbar = fig.colorbar(radarplot, ax=ax, orientation=\"vertical\", pad=0.02)\ncbar.set_label(units)\n\n# Titles\nax.set_title(title, loc=\"left\", fontweight=\"bold\")\nax.set_title(date.strftime(\"%d %B %Y at %H:%M UTC\"), loc=\"right\")\n\npng_name = f\"mrms_{region}_{product}_{date.strftime('%Y%m%d_%H%M%S')}.png\"\nplt.savefig(png_name, dpi=150, bbox_inches=\"tight\")\nplt.close(fig)\n\"\"\"","type":"content","url":"/notebooks/ch4-realtimedata#id-appendix","position":29}]}