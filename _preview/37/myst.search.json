{"version":"1","records":[{"hierarchy":{"lvl1":"MRMS Cookbook"},"type":"lvl1","url":"/","position":0},{"hierarchy":{"lvl1":"MRMS Cookbook"},"content":"\n\n\n\n\n [![DOI](https://zenodo.org/badge/475509405.svg)](https://zenodo.org/badge/latestdoi/475509405) \n\nThis Project Pythia Cookbook covers how to access, analyze, and visualize Multi-radar, Multi-sensor (MRMS) Data.","type":"content","url":"/","position":1},{"hierarchy":{"lvl1":"MRMS Cookbook","lvl2":"Motivation"},"type":"lvl2","url":"/#motivation","position":2},{"hierarchy":{"lvl1":"MRMS Cookbook","lvl2":"Motivation"},"content":"The Multi-Radar, Multi-Sensor (MRMS) System combines radar, surface, and upper-air observation to produce a high-resolution (1 km) dataset used by researchers and forecasters alike. Despite its use, there are few published Python workflows that illustrate how to access MRMS data from Amazon Web Services (AWS) and produce beautiful, useful visualizations. We hope this cookbook serves the MRMS-user community well!","type":"content","url":"/#motivation","position":3},{"hierarchy":{"lvl1":"MRMS Cookbook","lvl2":"Authors"},"type":"lvl2","url":"/#authors","position":4},{"hierarchy":{"lvl1":"MRMS Cookbook","lvl2":"Authors"},"content":"","type":"content","url":"/#authors","position":5},{"hierarchy":{"lvl1":"MRMS Cookbook","lvl3":"Contributors","lvl2":"Authors"},"type":"lvl3","url":"/#contributors","position":6},{"hierarchy":{"lvl1":"MRMS Cookbook","lvl3":"Contributors","lvl2":"Authors"},"content":"","type":"content","url":"/#contributors","position":7},{"hierarchy":{"lvl1":"MRMS Cookbook","lvl2":"Structure"},"type":"lvl2","url":"/#structure","position":8},{"hierarchy":{"lvl1":"MRMS Cookbook","lvl2":"Structure"},"content":"Chapter 1 offers a brief overview of MRMS data and provides context for how the data is organized on AWS.\n\nChapter 2 contains a case study of the \n\nMarch 24–27 2023 Tornado Outbreak, showcasing fields relevant to severe weather prediction.\n\nChapter 3 examines another recent severe weather event, the \n\nJuly 2025 Central Texas Floods, instead focusing on precipitation fields and \n\nFLASH output, including comparisons to station observations.\n\nChapter 4 compares MRMS-derived precipitation estimates at Bankhead National Forest (BNF) Field Sites.\n\nChapter 5 offers a real-time look at MRMS data with the opportunity to select certain data fields.","type":"content","url":"/#structure","position":9},{"hierarchy":{"lvl1":"MRMS Cookbook","lvl2":"Running the Notebooks"},"type":"lvl2","url":"/#running-the-notebooks","position":10},{"hierarchy":{"lvl1":"MRMS Cookbook","lvl2":"Running the Notebooks"},"content":"You can either run the notebook using \n\nBinder or on your local machine.","type":"content","url":"/#running-the-notebooks","position":11},{"hierarchy":{"lvl1":"MRMS Cookbook","lvl3":"Running on Binder","lvl2":"Running the Notebooks"},"type":"lvl3","url":"/#running-on-binder","position":12},{"hierarchy":{"lvl1":"MRMS Cookbook","lvl3":"Running on Binder","lvl2":"Running the Notebooks"},"content":"The simplest way to interact with a Jupyter Notebook is through\n\n\nBinder, which enables the execution of a\n\n\nJupyter Book in the cloud. The details of how this works are not\nimportant for now. All you need to know is how to launch a Pythia\nCookbooks chapter via Binder. Simply navigate your mouse to\nthe top right corner of the book chapter you are viewing and click\non the rocket ship icon, (see figure below), and be sure to select\n“launch Binder”. After a moment you should be presented with a\nnotebook that you can interact with. I.e. you’ll be able to execute\nand even change the example programs. You’ll see that the code cells\nhave no output at first, until you execute them by pressing\nShift+Enter. Complete details on how to interact with\na live Jupyter notebook are described in \n\nGetting Started with\nJupyter.\n\nNote: not all Cookbook chapters are executable. If you do not see\nthe rocket ship icon, such as on this page, you are not viewing an\nexecutable book chapter.","type":"content","url":"/#running-on-binder","position":13},{"hierarchy":{"lvl1":"MRMS Cookbook","lvl3":"Running on Your Own Machine","lvl2":"Running the Notebooks"},"type":"lvl3","url":"/#running-on-your-own-machine","position":14},{"hierarchy":{"lvl1":"MRMS Cookbook","lvl3":"Running on Your Own Machine","lvl2":"Running the Notebooks"},"content":"If you are interested in running this material locally on your computer, you will need to follow this workflow:\n\nClone the https://github.com/ProjectPythia/mrms-cookbook repository: git clone https://github.com/ProjectPythia/mrms-cookbook.git\n\nMove into the mrms-cookbook directorycd mrms-cookbook\n\nCreate and activate your conda environment from the environment.yml fileconda env create -f environment.yml\nconda activate mrms-cookbook-dev\n\nMove into the notebooks directory and start up Jupyterlabcd notebooks/\njupyter lab","type":"content","url":"/#running-on-your-own-machine","position":15},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)"},"type":"lvl1","url":"/notebooks/bnf-mrms-qpe-hourly","position":0},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)"},"content":"\n\n","type":"content","url":"/notebooks/bnf-mrms-qpe-hourly","position":1},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)"},"type":"lvl1","url":"/notebooks/bnf-mrms-qpe-hourly#noaa-multi-radar-multi-sensor-system-mrms-at-the-bnf-field-site-s","position":2},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)"},"content":"\n\n","type":"content","url":"/notebooks/bnf-mrms-qpe-hourly#noaa-multi-radar-multi-sensor-system-mrms-at-the-bnf-field-site-s","position":3},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl2":"Overview"},"type":"lvl2","url":"/notebooks/bnf-mrms-qpe-hourly#overview","position":4},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl2":"Overview"},"content":"We’ll go through the steps of:\n\nDefine our region of verification sites\n\nQuery and Load Data from MRMS Buckets on AWS\n\nCreate a Multi-Panel Display of QPE for the different sites\n\n","type":"content","url":"/notebooks/bnf-mrms-qpe-hourly#overview","position":5},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl2":"Prerequisites"},"type":"lvl2","url":"/notebooks/bnf-mrms-qpe-hourly#prerequisites","position":6},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl2":"Prerequisites"},"content":"Concepts\n\nImportance\n\nNotes\n\nIntro to Cartopy\n\nNecessary\n\nMapping and Tiles\n\nIntro to Xarray\n\nNecessary\n\nFamiliarity with metadata structure\n\nTime to learn: 30 minutes\n\nSystem requirements:\n\nAny Operating System\n\nAt least 8 GB of RAM\n\n","type":"content","url":"/notebooks/bnf-mrms-qpe-hourly#prerequisites","position":7},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl2":"Imports"},"type":"lvl2","url":"/notebooks/bnf-mrms-qpe-hourly#imports","position":8},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl2":"Imports"},"content":"\n\nimport cfgrib\nimport xarray as xr\nimport fsspec\nimport glob\nimport tempfile\nimport gzip\nimport geopandas as gpd\nimport pandas as pd\nimport numpy as np\nimport warnings\n\nfrom cartopy import feature as cfeature\nimport cartopy.crs as ccrs\nfrom cartopy.io.img_tiles import OSM\nfrom matplotlib.transforms import offset_copy\nfrom matplotlib import pyplot as plt\n\nfrom metpy.plots import USCOUNTIES\n\nimport cmweather\n\n# To ignore all RuntimeWarnings globally\nwarnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n\n","type":"content","url":"/notebooks/bnf-mrms-qpe-hourly#imports","position":9},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl2":"Hourly QPE BNF Mosaic"},"type":"lvl2","url":"/notebooks/bnf-mrms-qpe-hourly#hourly-qpe-bnf-mosaic","position":10},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl2":"Hourly QPE BNF Mosaic"},"content":"The \n\nNOAA Multi-Radar / Multi-Sensor System (MRMS) was created to produce products of preciptiation impacts on transportation and aviation.\n\nUsing the \n\nNOAA MRMS AWS Bucket, this notebook details creation of quicklooks to investigate a Quantitative Preciptiation Estimates (QPE) for the U.S. Department of Energy Atmospheric Radiation Measurement (ARM) AMF-3 Deployment to Bankhead National Forest.\n\nWe start first with a dictionary containing our sites of interest, these are located Southwest of Decatur, Alabama.\n\nMore about the BNF Site can be found on the \n\nARM Website.\n\nglobal_sites = {\"M1\" : [34.34525, -87.33842],\n                \"S4\" : [34.46451, -87.23598],\n                \"S3\" : [34.63080, -87.13311],\n                \"S20\" : [34.65401, -87.29264],\n                \"S30\" : [34.38501, -86.92757],\n                \"S40\" : [34.17932, -87.45349]}\n\n\n# Define a domain to set the extent of the figures\nbnf_domain = [272.0, 274.0, 34.1, 35.1]\n\n","type":"content","url":"/notebooks/bnf-mrms-qpe-hourly#hourly-qpe-bnf-mosaic","position":11},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl3":"Visualize the Site Locations Using Cartopy","lvl2":"Hourly QPE BNF Mosaic"},"type":"lvl3","url":"/notebooks/bnf-mrms-qpe-hourly#visualize-the-site-locations-using-cartopy","position":12},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl3":"Visualize the Site Locations Using Cartopy","lvl2":"Hourly QPE BNF Mosaic"},"content":"\n\nfig = plt.figure(figsize=(12,8))\nax = plt.subplot(projection=ccrs.PlateCarree())\n\ntiler = OSM()\nax.add_image(tiler, 12, zorder=0, alpha=0.7)\nfor site in global_sites:\n    ax.scatter(global_sites[site][1], global_sites[site][0], label=site)\n\nax.set_extent(bnf_domain)\n\nplt.legend(loc=\"upper right\")\nplt.title(\"ARM Bankhead National Forest Sites\", fontsize=16);\n\n","type":"content","url":"/notebooks/bnf-mrms-qpe-hourly#visualize-the-site-locations-using-cartopy","position":13},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl2":"Query and Load Data from MRMS Buckets on AWS"},"type":"lvl2","url":"/notebooks/bnf-mrms-qpe-hourly#query-and-load-data-from-mrms-buckets-on-aws","position":14},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl2":"Query and Load Data from MRMS Buckets on AWS"},"content":"Note the Multi-Sensor (i.e. gauge adjusted) QPE product is split into two categories (Pass 1 and Pass 2), which defines the gauge latency used to adjust radar dervied QPE.\n\n# Define a Date for Analysis [YYYYMMDD format]\nDATE = \"20250524\"\nHOUR = \"000000\"\n\n## Setup the AWS S3 filesystem\nfs = fsspec.filesystem(\"s3\", anon=True)\n\ns3_multi_bucket = [f\"s3://noaa-mrms-pds/CONUS/MultiSensor_QPE_01H_Pass1_00.00/{DATE}/*.gz\"]\ns3_pass2_bucket = [f\"s3://noaa-mrms-pds/CONUS/MultiSensor_QPE_01H_Pass2_00.00/{DATE}/*.gz\"]\ns3_radar_bucket = [f\"s3://noaa-mrms-pds/CONUS/RadarOnly_QPE_01H_00.00/{DATE}/*[0-9]0000.grib2.gz\"]\n\n","type":"content","url":"/notebooks/bnf-mrms-qpe-hourly#query-and-load-data-from-mrms-buckets-on-aws","position":15},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl3":"Loop through and Create Lists of Datasets","lvl2":"Query and Load Data from MRMS Buckets on AWS"},"type":"lvl3","url":"/notebooks/bnf-mrms-qpe-hourly#loop-through-and-create-lists-of-datasets","position":16},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl3":"Loop through and Create Lists of Datasets","lvl2":"Query and Load Data from MRMS Buckets on AWS"},"content":"Our next step is to search, access, and load our data into merged datasets, adding some additional metadata such as units. We apply this for each our our multipass, pass2, and radar datasets.\n\nds_multi_list = []\nfor scan in s3_multi_bucket:\n    file_path = sorted(fs.glob(scan))\n    for mrms in file_path:\n        with fs.open(mrms, 'rb') as gzip_file:\n            with tempfile.NamedTemporaryFile(suffix=\".grib2\") as f:\n                # Uncompress and read the file\n                f.write(gzip.decompress(gzip_file.read()))\n                ds = xr.load_dataset(f.name, decode_timedelta=False)\n                # Parameters are stored as 'unknown'; meta data in filename\n                ds = ds.rename({\"unknown\" : \"multisensor_qpe_1hr\"})\n                ds[\"multisensor_qpe_1hr\"].attrs[\"units\"] = \"mm\"\n                ds[\"multisensor_qpe_1hr\"].attrs[\"long_name\"] = \"Precipitation Accumulation (1-Hr latency)\"\n                # Subset for the desired bounding box and take out all missing values\n                ds = ds.sel(latitude=slice(bnf_domain[3], bnf_domain[2]), longitude=slice(bnf_domain[0], bnf_domain[1])).where(ds.multisensor_qpe_1hr > 0)\n                ds_multi_list.append(ds)\n\nds_radar_list = []\nfor scan in s3_radar_bucket:\n    file_path = sorted(fs.glob(scan))\n    for mrms in file_path:\n        with fs.open(mrms, 'rb') as gzip_file:\n            with tempfile.NamedTemporaryFile(suffix=\".grib2\") as f:\n                # Uncompress and read the file\n                f.write(gzip.decompress(gzip_file.read()))\n                ds = xr.load_dataset(f.name, decode_timedelta=False)\n                ds = ds.rename({\"unknown\" : \"radar_qpe_1hr\"})\n                ds[\"radar_qpe_1hr\"].attrs[\"units\"] = \"mm\"\n                ds[\"radar_qpe_1hr\"].attrs[\"long_name\"] = \"Precipitation Accumulation\"\n                 # Subset for the desired bounding box and take out all missing values\n                ds = ds.sel(latitude=slice(bnf_domain[3], bnf_domain[2]), longitude=slice(bnf_domain[0], bnf_domain[1])).where(ds.radar_qpe_1hr > 0)\n                ds_radar_list.append(ds)\n\nds_pass2_list = []\nfor scan in s3_pass2_bucket:\n    file_path = sorted(fs.glob(scan))\n    for mrms in file_path:\n        with fs.open(mrms, 'rb') as gzip_file:\n            with tempfile.NamedTemporaryFile(suffix=\".grib2\") as f:\n                # Uncompress and read the file\n                f.write(gzip.decompress(gzip_file.read()))\n                ds = xr.load_dataset(f.name, decode_timedelta=False)\n                ds = ds.rename({\"unknown\" : \"multisensor_qpe_pass2\"})\n                ds[\"multisensor_qpe_pass2\"].attrs[\"units\"] = \"mm\"\n                ds[\"multisensor_qpe_pass2\"].attrs[\"long_name\"] = \"Precipitation Accumulation (2-Hr latency)\"\n                # Subset for the desired bounding box and take out all missing values\n                ds = ds.sel(latitude=slice(bnf_domain[3], bnf_domain[2]), longitude=slice(bnf_domain[0], bnf_domain[1])).where(ds.multisensor_qpe_pass2 > 0)\n                ds_pass2_list.append(ds)\n\n","type":"content","url":"/notebooks/bnf-mrms-qpe-hourly#loop-through-and-create-lists-of-datasets","position":17},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl3":"Merge our Files Together","lvl2":"Query and Load Data from MRMS Buckets on AWS"},"type":"lvl3","url":"/notebooks/bnf-mrms-qpe-hourly#merge-our-files-together","position":18},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl3":"Merge our Files Together","lvl2":"Query and Load Data from MRMS Buckets on AWS"},"content":"Once we have lists of files, we can merge based on the time dimension.\n\n# Concatenate all hourly files into xarray datasets\nds_radar_merged = xr.concat(ds_radar_list, dim=\"time\")\nds_multi_merged = xr.concat(ds_multi_list, dim=\"time\")\nds_pass2_merged = xr.concat(ds_pass2_list, dim=\"time\")\n\nAnd finally merge our various passes and QPE data into one single dataset.\n\n# Merge Radar, Multi-Sensor Pass 1 and Multi-Sensor Pass 2 QPE into single dataset\nds_merged = xr.merge([ds_radar_merged, ds_multi_merged, ds_pass2_merged])\n\n","type":"content","url":"/notebooks/bnf-mrms-qpe-hourly#merge-our-files-together","position":19},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl3":"Calculate Precipitation Accumulation","lvl2":"Query and Load Data from MRMS Buckets on AWS"},"type":"lvl3","url":"/notebooks/bnf-mrms-qpe-hourly#calculate-precipitation-accumulation","position":20},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl3":"Calculate Precipitation Accumulation","lvl2":"Query and Load Data from MRMS Buckets on AWS"},"content":"Our last step is to calculate our preciptiation accumulation as observed from radar data. We do this by using the xarray cumulative sum \n\ncumsum function.\n\n# Calculate the Cumulative Distribution\nradar_cumulative = ds_merged['radar_qpe_1hr'].cumsum(dim='time')\nmultisensor = ds_merged['multisensor_qpe_1hr'].cumsum(dim=\"time\")\nmultisensor_pass2 = ds_merged['multisensor_qpe_pass2'].cumsum(dim=\"time\")\n\nds_merged['cumulative_radar_qpe'] = radar_cumulative\nds_merged[\"cumulative_radar_qpe\"].attrs[\"units\"] = \"mm\"\nds_merged[\"cumulative_radar_qpe\"].attrs[\"long_name\"] = \"Precipitation Accumulation\"\n\nds_merged['cumulative_multisensor'] = multisensor\nds_merged[\"cumulative_multisensor\"].attrs[\"units\"] = \"mm\"\nds_merged[\"cumulative_multisensor\"].attrs[\"long_name\"] = \"Precipitation Accumulation (1-Hr latency)\"\n\nds_merged['cumulative_ms_pass2'] = multisensor_pass2\nds_merged[\"cumulative_ms_pass2\"].attrs[\"units\"] = \"mm\"\nds_merged[\"cumulative_ms_pass2\"].attrs[\"long_name\"] = \"Precipitation Accumulation (2-Hr latency)\"\nds_merged\n\n","type":"content","url":"/notebooks/bnf-mrms-qpe-hourly#calculate-precipitation-accumulation","position":21},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl2":"Create a Multi-Panel QPE Display"},"type":"lvl2","url":"/notebooks/bnf-mrms-qpe-hourly#create-a-multi-panel-qpe-display","position":22},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl2":"Create a Multi-Panel QPE Display"},"content":"Now that we have our merged, cleaned data, we can create a single graphic summarizing the cumulative precipitation at our different sites. We use nearest neighbor here to subset from the broader region.\n\n#---------------------------------------------------\n# Define the Figure for Detailed Subplot Placement\n#---------------------------------------------------\nfig = plt.figure(figsize=(24, 10))\ntiler = OSM()\nmercator = tiler.crs\nax = fig.add_subplot(1, 3, 1, projection=ccrs.PlateCarree())\n\n# adjust the subplot widths\nplt.subplots_adjust(wspace=0.3)\n\n# Find the maximum value at each position\nda_max = ds_merged.isel(time=-1).radar_qpe_1hr.max()\n\n# Find the minimum value at each position\nda_min = 0\n\n# ---------------------------------------------\n# Display the Radar Precipitation Accumulation\n# ---------------------------------------------\n\n## subset the data\nds_merged.isel(time=15).radar_qpe_1hr.plot(transform=ccrs.PlateCarree(),\n                                           ax=ax,\n                                           cmap=\"ChaseSpectral\",\n                                           vmin=da_min,\n                                           vmax=da_max,\n                                           cbar_kwargs={\"location\" : \"bottom\"})\n\n# Add some various map elements to the plot to make it recognizable.\nax.add_feature(cfeature.LAND)\nax.add_feature(cfeature.OCEAN)\nax.add_feature(cfeature.BORDERS)\nax.add_image(tiler, 12, zorder=1, alpha=0.55)\nax.gridlines(draw_labels=True)\n\n# Set plot bounds\nax.set_extent(bnf_domain)\n\n# add in crosshairs to indicate the lat/lon slices\nax.axhline(y=global_sites[\"M1\"][0], color=\"black\", linestyle=\"--\")\nax.axvline(x=global_sites[\"M1\"][1], color=\"red\", linestyle=\"--\")\n\n# Display the location of the BNF supplementarly sites\nfor key in global_sites:\n    # Add a marker for the BNF sites.\n    ax.plot(global_sites[key][1], \n            global_sites[key][0], \n            marker='o', \n            color='black', \n            markersize=10, \n            alpha=0.7, \n            transform=ccrs.PlateCarree())\n\n    # Use the cartopy interface to create a matplotlib transform object\n    # for the Geodetic coordinate system. We will use this along with\n    # matplotlib's offset_copy function to define a coordinate system which\n    # translates the text by 25 pixels to the left.\n    geodetic_transform = ccrs.PlateCarree()._as_mpl_transform(ax)\n    text_transform = offset_copy(geodetic_transform, units='dots', x=+50, y=+15)\n\n    # Add text to the right of the symbol.\n    ax.text(global_sites[key][1]-0.1, \n            global_sites[key][0], \n            key, \n            verticalalignment='center', \n            horizontalalignment='right', \n            transform=text_transform,\n            bbox=dict(facecolor='sandybrown', \n            alpha=0.5, \n            boxstyle='round'))\n    \n# update the title of the display\nax.set_title(np.datetime_as_string(ds_merged['valid_time'].isel(time=15).data, unit='s').replace(\"T\", \" - \") + \n             \"Z\\n\" + \"Radar Derived 1-Hr QPE - MRMS\")\n\n# ----------------------------\n# Display the Multisensor QPE\n# ----------------------------\n## subset the data\nax1 = fig.add_subplot(1, 3, 2, projection=ccrs.PlateCarree())\nds_merged.isel(time=15).multisensor_qpe_1hr.plot(transform=ccrs.PlateCarree(),\n                                                 ax=ax1,\n                                                 cmap=\"ChaseSpectral\",\n                                                 vmin=da_min,\n                                                 vmax=da_max,\n                                                 cbar_kwargs={\"location\" : \"bottom\"})\n\n# Add some various map elements to the plot to make it recognizable.\nax1.add_feature(cfeature.LAND)\nax1.add_feature(cfeature.OCEAN)\nax1.add_feature(cfeature.BORDERS)\nax1.add_image(tiler, 12, zorder=1, alpha=0.55)\nax1.gridlines(draw_labels=True)\n\n# Set plot bounds\nax1.set_extent(bnf_domain)\n\n# add in crosshairs to indicate the lat/lon slices\nax1.axhline(y=global_sites[\"M1\"][0], color=\"black\", linestyle=\"--\")\nax1.axvline(x=global_sites[\"M1\"][1], color=\"red\", linestyle=\"--\")\n\n# Display the location of the BNF Supplementary Site\nfor key in global_sites:\n    # Add a marker for the BNF sites.\n    ax1.plot(global_sites[key][1], \n            global_sites[key][0], \n            marker='o', \n            color='black', \n            markersize=10, \n            alpha=0.7, \n            transform=ccrs.PlateCarree())\n\n    # Use the cartopy interface to create a matplotlib transform object\n    # for the Geodetic coordinate system. We will use this along with\n    # matplotlib's offset_copy function to define a coordinate system which\n    # translates the text by 25 pixels to the left.\n    geodetic_transform = ccrs.PlateCarree()._as_mpl_transform(ax1)\n    text_transform = offset_copy(geodetic_transform, units='dots', x=+50, y=+15)\n\n\n    # Add text to the right of the site marker.\n    ax1.text(global_sites[key][1]-0.1, \n             global_sites[key][0], \n             key, \n             verticalalignment='center', \n             horizontalalignment='right', \n             transform=text_transform,\n             bbox=dict(facecolor='sandybrown', \n             alpha=0.5, \n             boxstyle='round')\n    )\n    \n# update the title of the display\nax1.set_title(np.datetime_as_string(ds_merged['valid_time'].isel(time=15).data, unit='s').replace(\"T\", \" - \") + \n             \"Z\\n\" + \"Multisensor 1-Hr QPE - Pass 1\")\n\n# ----------------------------\n# Display the QPE Difference\n# ----------------------------\n## subset the data\nax3 = fig.add_subplot(1, 3, 3, projection=ccrs.PlateCarree())\nds_merged.isel(time=15).multisensor_qpe_pass2.plot(transform=ccrs.PlateCarree(),\n                                                   ax=ax3,\n                                                   cmap=\"ChaseSpectral\",\n                                                   vmin=da_min,\n                                                   vmax=da_max,\n                                                   cbar_kwargs={\"location\" : \"bottom\"})\n\n# Add some various map elements to the plot to make it recognizable.\nax3.add_feature(cfeature.LAND)\nax3.add_feature(cfeature.OCEAN)\nax3.add_feature(cfeature.BORDERS)\nax3.add_image(tiler, 12, zorder=1, alpha=0.55)\nax3.gridlines(draw_labels=True)\n\n# Set plot bounds\nax3.set_extent(bnf_domain)\n\n# add in crosshairs to indicate the lat/lon slices\nax3.axhline(y=global_sites[\"M1\"][0], color=\"black\", linestyle=\"--\")\nax3.axvline(x=global_sites[\"M1\"][1], color=\"red\", linestyle=\"--\")\n\n# Display the location of the BNF Supplementary Sites\nfor key in global_sites:\n    # Add a marker for the BNF sites.\n    ax3.plot(global_sites[key][1], \n            global_sites[key][0], \n            marker='o', \n            color='black', \n            markersize=10, \n            alpha=0.7, \n            transform=ccrs.PlateCarree())\n\n    # Use the cartopy interface to create a matplotlib transform object\n    # for the Geodetic coordinate system. We will use this along with\n    # matplotlib's offset_copy function to define a coordinate system which\n    # translates the text by 25 pixels to the left.\n    geodetic_transform = ccrs.PlateCarree()._as_mpl_transform(ax3)\n    text_transform = offset_copy(geodetic_transform, units='dots', x=+50, y=+15)\n\n    # Add text to the right of the site marker.\n    ax3.text(global_sites[key][1]-0.1, \n             global_sites[key][0], \n             key, \n             verticalalignment='center', \n             horizontalalignment='right', \n             transform=text_transform,\n             bbox=dict(facecolor='sandybrown', \n             alpha=0.5, \n             boxstyle='round'))\n    \n# update the title of the display\nax3.set_title(np.datetime_as_string(ds_merged['valid_time'].isel(time=15).data, unit='s').replace(\"T\", \" - \") + \n             \"Z\\n\" + \"MultiSensor 24-Hr QPE - Pass 2\");\n\n","type":"content","url":"/notebooks/bnf-mrms-qpe-hourly#create-a-multi-panel-qpe-display","position":23},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl2":"Summary"},"type":"lvl2","url":"/notebooks/bnf-mrms-qpe-hourly#summary","position":24},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl2":"Summary"},"content":"Within this notebook, we explored plotting a set of a field sites, accessing MRMS data, and visualizing a case over the ARM DOE Bankhead National Forest field site. We hope this serves as a framework for verification and understanding precipitation values in specific regions of interest.","type":"content","url":"/notebooks/bnf-mrms-qpe-hourly#summary","position":25},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl3":"What’s Next","lvl2":"Summary"},"type":"lvl3","url":"/notebooks/bnf-mrms-qpe-hourly#whats-next","position":26},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl3":"What’s Next","lvl2":"Summary"},"content":"We can extend this workflow by investigating timeseries for the various sites and looking into more robust verification techniques.","type":"content","url":"/notebooks/bnf-mrms-qpe-hourly#whats-next","position":27},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl2":"References"},"type":"lvl2","url":"/notebooks/bnf-mrms-qpe-hourly#references","position":28},{"hierarchy":{"lvl1":"NOAA Multi-Radar / Multi-Sensor System (MRMS) at the BNF Field Site(s)","lvl2":"References"},"content":"Notebook originally modified from Joseph O’Brien\n\nNOAA Multi-Radar/Multi-Sensor System (MRMS) was accessed on from https://registry.opendata.aws/noaa-mrms-pds","type":"content","url":"/notebooks/bnf-mrms-qpe-hourly#references","position":29},{"hierarchy":{"lvl1":"Chapter 1: Multi Radar/ Multi Sensor (MRMS) System: Overview, Case Studies, and More!"},"type":"lvl1","url":"/notebooks/ch1-introduction","position":0},{"hierarchy":{"lvl1":"Chapter 1: Multi Radar/ Multi Sensor (MRMS) System: Overview, Case Studies, and More!"},"content":"\n\n","type":"content","url":"/notebooks/ch1-introduction","position":1},{"hierarchy":{"lvl1":"Chapter 1: Multi Radar/ Multi Sensor (MRMS) System: Overview, Case Studies, and More!","lvl2":"Overview"},"type":"lvl2","url":"/notebooks/ch1-introduction#overview","position":2},{"hierarchy":{"lvl1":"Chapter 1: Multi Radar/ Multi Sensor (MRMS) System: Overview, Case Studies, and More!","lvl2":"Overview"},"content":"This notebook introduces users to MRMS, informs users on MRMS data sources, shows useful websites, and provides context on variable names. Follow through the notebook to learn more about MRMS and ways it can be used to aid in your research and decision-making!\n\n\n\n","type":"content","url":"/notebooks/ch1-introduction#overview","position":3},{"hierarchy":{"lvl1":"Chapter 1: Multi Radar/ Multi Sensor (MRMS) System: Overview, Case Studies, and More!","lvl2":"MRMS System Overview"},"type":"lvl2","url":"/notebooks/ch1-introduction#mrms-system-overview","position":4},{"hierarchy":{"lvl1":"Chapter 1: Multi Radar/ Multi Sensor (MRMS) System: Overview, Case Studies, and More!","lvl2":"MRMS System Overview"},"content":"\n\n","type":"content","url":"/notebooks/ch1-introduction#mrms-system-overview","position":5},{"hierarchy":{"lvl1":"Chapter 1: Multi Radar/ Multi Sensor (MRMS) System: Overview, Case Studies, and More!","lvl3":"What is MRMS?","lvl2":"MRMS System Overview"},"type":"lvl3","url":"/notebooks/ch1-introduction#what-is-mrms","position":6},{"hierarchy":{"lvl1":"Chapter 1: Multi Radar/ Multi Sensor (MRMS) System: Overview, Case Studies, and More!","lvl3":"What is MRMS?","lvl2":"MRMS System Overview"},"content":"The Multi-Radar/ Multi-Sensor (MRMS) System is a radar system developed by the National Severe Storms Laboratory (NSSL) that integrates data from satellites, radars, numerical prediction models, rain gauges, observations, and lightning reports into a standardized grid. Its goal is to provide smooth, high-resolution, and consistent weather products to inform decision-support services, aviation, transportation, numerical weather forecasting, hydrology, and public messaging.\n\nKey features include:\n\n3D radar mosaics\n\n1-km x 2-minute update cycle\n\nSevere weather and aviation products\n\nCovers CONUS, Alaska, Hawaii, (parts of) the Caribbean, Guam, and parts of southern Canada\n\n","type":"content","url":"/notebooks/ch1-introduction#what-is-mrms","position":7},{"hierarchy":{"lvl1":"Chapter 1: Multi Radar/ Multi Sensor (MRMS) System: Overview, Case Studies, and More!","lvl3":"MRMS Data Sources","lvl2":"MRMS System Overview"},"type":"lvl3","url":"/notebooks/ch1-introduction#mrms-data-sources","position":8},{"hierarchy":{"lvl1":"Chapter 1: Multi Radar/ Multi Sensor (MRMS) System: Overview, Case Studies, and More!","lvl3":"MRMS Data Sources","lvl2":"MRMS System Overview"},"content":"The MRMS integrates data from various sources to produce advanced weather products.\n\nRadars: Weather Surveillance Radar (WSR-88D), Canadian radar networks, Terminal Doppler Weather Radars (TDWRs), commercial radars, and more.\n\nSatellite: Geostationary Operational Environmental Satellite (GOES). Provides continuous data on atmospheric conditions.\n\nNumerical prediction models: High Resolution Rapid Refresh (HRRR), Rapid Refresh (RAP).\n\nSurface observations\n\nRain gauges: approximately 7,000 hourly rain gauge sensors, Hydrometeorological Automated Data System (HADS)\n\nLightning reports: National Lightning Detection Network (NLDN)\n\n","type":"content","url":"/notebooks/ch1-introduction#mrms-data-sources","position":9},{"hierarchy":{"lvl1":"Chapter 1: Multi Radar/ Multi Sensor (MRMS) System: Overview, Case Studies, and More!","lvl3":"AWS Structure & Access","lvl2":"MRMS System Overview"},"type":"lvl3","url":"/notebooks/ch1-introduction#aws-structure-access","position":10},{"hierarchy":{"lvl1":"Chapter 1: Multi Radar/ Multi Sensor (MRMS) System: Overview, Case Studies, and More!","lvl3":"AWS Structure & Access","lvl2":"MRMS System Overview"},"content":"To meet the demand for accessible, scalable, reliable, and timely data, MRMS hosts its data on Amazon Web Services (AWS).\n\nAccessing NOAA MRMS data on AWS is simple. \n\nJust click this link to navigate to the dedicated MRMS suite on AWS, select your area of interest, e.g., Alaska, CONUS, Hawaii, etc., then select the variable(s) you wish to study.\n\nThe next section talks more about some of the variables available and what they are.\n\n","type":"content","url":"/notebooks/ch1-introduction#aws-structure-access","position":11},{"hierarchy":{"lvl1":"Chapter 1: Multi Radar/ Multi Sensor (MRMS) System: Overview, Case Studies, and More!","lvl3":"MRMS Naming","lvl2":"MRMS System Overview"},"type":"lvl3","url":"/notebooks/ch1-introduction#mrms-naming","position":12},{"hierarchy":{"lvl1":"Chapter 1: Multi Radar/ Multi Sensor (MRMS) System: Overview, Case Studies, and More!","lvl3":"MRMS Naming","lvl2":"MRMS System Overview"},"content":"The MRMS has a wide range of variables you can use for your research and operations. \n\nBy clicking here, you can find the Operational MRMS GRIB2 Tables that detail the name of a dataset, frequencies, what unit the data is measured in, missing data, range folded, instances of no coverage, a description, and a notes column.\n\nIn this Cookbook, we use the following variables:\n\nVariable\n\nDescription\n\nRadarOnly_QPE_24H_00.00\n\nRadar precipitation accumulation 24-hour\n\nMergedReflectivityQCComposite_00.50\n\nComposite Reflectivity Mosaic (optimal method)\n\nMultiSensor_QPE_12H_Pass1_00.00\n\nMulti-sensor accumulation 12-hour (1-hour latency)\n\nPOSH_00.50\"\n\nProb of Severe Hail\n\nCREF_1HR_MAX_00.50\n\nComposite Reflectivity Hourly Maximum\n\nPrecipRate_00.00\n\nRadar Precipitation Rate\n\nMultiSensor_QPE_01H_Pass1_00.00\n\nMulti-sensor accumulation 1-hour (1-hour latency)\n\nMultiSensor_QPE_01H_Pass2_00.00\n\nMulti-sensor accumulation 1-hour (2-hour latency)\n\nRadarOnly_QPE_01H_00.00\n\nRadar precipitation accumulation 1-hour\n\nLowLevelCompositeReflectivity\n\nLow-Level Composite Reflectivity Mosaic (0-4km)\n\n\n\n","type":"content","url":"/notebooks/ch1-introduction#mrms-naming","position":13},{"hierarchy":{"lvl1":"Chapter 1: Multi Radar/ Multi Sensor (MRMS) System: Overview, Case Studies, and More!","lvl2":"Summary"},"type":"lvl2","url":"/notebooks/ch1-introduction#summary","position":14},{"hierarchy":{"lvl1":"Chapter 1: Multi Radar/ Multi Sensor (MRMS) System: Overview, Case Studies, and More!","lvl2":"Summary"},"content":"In summary, the MRMS System represents a robust and evolving platform that serves current research and operational needs, while paving ways for other innovations in decision-support services, aviation, transportation, numerical weather forecasting, hydrology, and public messaging.","type":"content","url":"/notebooks/ch1-introduction#summary","position":15},{"hierarchy":{"lvl1":"Chapter 1: Multi Radar/ Multi Sensor (MRMS) System: Overview, Case Studies, and More!","lvl4":"What’s next?","lvl2":"Summary"},"type":"lvl4","url":"/notebooks/ch1-introduction#whats-next","position":16},{"hierarchy":{"lvl1":"Chapter 1: Multi Radar/ Multi Sensor (MRMS) System: Overview, Case Studies, and More!","lvl4":"What’s next?","lvl2":"Summary"},"content":"In the following notebooks, you will be introduced to MRMS use case scenarios. We look into the March 2023 Rolling Fork, MS Tornado, the 2025 Texas Flood, and more!\n\n","type":"content","url":"/notebooks/ch1-introduction#whats-next","position":17},{"hierarchy":{"lvl1":"Chapter 1: Multi Radar/ Multi Sensor (MRMS) System: Overview, Case Studies, and More!","lvl2":"Resources"},"type":"lvl2","url":"/notebooks/ch1-introduction#resources","position":18},{"hierarchy":{"lvl1":"Chapter 1: Multi Radar/ Multi Sensor (MRMS) System: Overview, Case Studies, and More!","lvl2":"Resources"},"content":"To learn more about MRMS and its products, check out the links below!\n\nMulti Radar Multi Sensor Overview\n\nNSSL Multi-Radar/Multi-Sensor System (MRMS)\n\nOperational MRMS GRIB2 Table\n\nMRMS on AWS\n\nArticle on MRMS Severe Weather and Aviation Products\n\nArticle on MRMS Quantitative Precipitation Estimates","type":"content","url":"/notebooks/ch1-introduction#resources","position":19},{"hierarchy":{"lvl1":"Chapter 2: Case Study"},"type":"lvl1","url":"/notebooks/ch2-mar-2023-tornado-jdh","position":0},{"hierarchy":{"lvl1":"Chapter 2: Case Study"},"content":"","type":"content","url":"/notebooks/ch2-mar-2023-tornado-jdh","position":1},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl3":"March 24-27, 2023 Tornado Outbreak"},"type":"lvl3","url":"/notebooks/ch2-mar-2023-tornado-jdh#march-24-27-2023-tornado-outbreak","position":2},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl3":"March 24-27, 2023 Tornado Outbreak"},"content":"\n\n\n\nNext, title your notebook appropriately with a top-level Markdown header, # (see the very first cell above). Do not use this level header anywhere else in the notebook. Our book build process will use this title in the navbar, table of contents, etc. Keep it short, keep it descriptive.\n\nFollow this with a --- cell to visually distinguish the transition to the prerequisites section.\n\n\n\n","type":"content","url":"/notebooks/ch2-mar-2023-tornado-jdh#march-24-27-2023-tornado-outbreak","position":3},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl2":"Overview"},"type":"lvl2","url":"/notebooks/ch2-mar-2023-tornado-jdh#overview","position":4},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl2":"Overview"},"content":"The tornado outbreak of March 24–27, 2023 was a devastating multi-day severe weather event that swept across the Southern United States, particularly impacting Mississippi, Alabama, Tennessee, and Georgia. Triggered by a slow-moving upper-level trough interacting with moist, unstable air from the Gulf of Mexico, the outbreak produced 35 confirmed tornadoes, including a violent EF4 that tore through Rolling Fork, Midnight, and Silver City, Mississippi with peak winds of 195 mph. This EF4 tornado alone caused catastrophic damage and multiple fatalities and brought tornado emergencies ahead of widespread destruction.\nOver the four-day span, the system also unleashed damaging straight-line winds, large hail, and flooding. In total, the outbreak resulted in 23 fatalities (plus two from non-tornadic causes), over 230 injuries, and an estimated $1.9 billion in damage. The event was notable not only for its intensity but also for its geographic breadth and the prolonged nature of the severe weather threat.\n\nThis chapter explores MRMS data from this tornado outbreak, specifically from the Rolling Fork–Silver City, MS tornado on March 24, 2023. The chapter investigates:\n\nReflectivity\n\nPrecipitation Rates\n\nRotation\n\nHail Swaths - Under Construction!\n\nStorm Intensity (Vertically integrated liquid) - Under Construction!\n\nTo support this analysis, the chapter introduces a practical method for accessing MRMS data directly from an AWS server. It guides readers through defining a map and customizing its spatial extent to filter and process data relevant to the event. By showcasing multiple variations of each MRMS variable, the chapter highlights the accessibility and versatility of these datasets for visualizing high-impact weather events. A focused case study on the Rolling Fork tornado illustrates how several hours of MRMS data can be leveraged to gain insight into storm properties of a significant weather event.\n\n\n\n","type":"content","url":"/notebooks/ch2-mar-2023-tornado-jdh#overview","position":5},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl3":"Imports","lvl2":"Overview"},"type":"lvl3","url":"/notebooks/ch2-mar-2023-tornado-jdh#imports","position":6},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl3":"Imports","lvl2":"Overview"},"content":"This section brings in packages for handling AWS requests, manipulating MRMS files, and rendering plots on a map.\n\nimport sys\nimport s3fs\nimport urllib\nimport tempfile\nimport gzip\nimport xarray as xr\nimport xarray\nimport io\nimport numpy as np\nimport cartopy\nimport datetime\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport cartopy.crs as ccrs\nimport cartopy.feature as cfeature\n\naws = s3fs.S3FileSystem(anon=True)\n\n\n\n","type":"content","url":"/notebooks/ch2-mar-2023-tornado-jdh#imports","position":7},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl3":"Build Map","lvl2":"Overview"},"type":"lvl3","url":"/notebooks/ch2-mar-2023-tornado-jdh#build-map","position":8},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl3":"Build Map","lvl2":"Overview"},"content":"This section uses Cartopy to build a blank map then define our extent for our case study.\n\n# Set up the map projection\nprojection = ccrs.LambertConformal(central_longitude=-96, central_latitude=39)\n\n# Create the figure and axes\nfig, ax = plt.subplots(figsize=(12, 8), subplot_kw={'projection': projection})\n\n# Set extent for CONUS (approximate)\nax.set_extent([-125, -66.5, 24, 50], crs=ccrs.PlateCarree())\n\n# Add geographic features\nax.add_feature(cfeature.STATES.with_scale('50m'), edgecolor='gray')\nax.add_feature(cfeature.BORDERS.with_scale('50m'), linestyle='--', edgecolor='black')\nax.add_feature(cfeature.COASTLINE.with_scale('50m'))\n\n# Optional: remove ticks\nax.set_xticks([])\nax.set_yticks([])\n\n# Add title\nplt.title(\"Blank Map\", fontsize=18)\n\nplt.show()\n\n","type":"content","url":"/notebooks/ch2-mar-2023-tornado-jdh#build-map","position":9},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl5":"We will be looking specifically at the tornado outbreak that occurred in Dixie Alley, so let’s set our extents specifically to Dixie Alley.","lvl3":"Build Map","lvl2":"Overview"},"type":"lvl5","url":"/notebooks/ch2-mar-2023-tornado-jdh#we-will-be-looking-specifically-at-the-tornado-outbreak-that-occurred-in-dixie-alley-so-lets-set-our-extents-specifically-to-dixie-alley","position":10},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl5":"We will be looking specifically at the tornado outbreak that occurred in Dixie Alley, so let’s set our extents specifically to Dixie Alley.","lvl3":"Build Map","lvl2":"Overview"},"content":"\n\nlon_min, lon_max = -96, -80\nlat_min, lat_max = 29, 38\n\n# Set up the map projection\nprojection = ccrs.LambertConformal(central_longitude=-88, central_latitude=34)\n\n# Create the figure and axes\nfig, ax = plt.subplots(figsize=(12, 8), subplot_kw={'projection': projection})\n\n# Set extent for CONUS (approximate)\nax.set_extent([lon_min, lon_max, lat_min, lat_max], crs=ccrs.PlateCarree())\n\n# Add geographic features\nax.add_feature(cfeature.STATES.with_scale('50m'), edgecolor='gray')\nax.add_feature(cfeature.BORDERS.with_scale('50m'), linestyle='--', edgecolor='black')\nax.add_feature(cfeature.COASTLINE.with_scale('50m'))\n\n# Optional: remove ticks\nax.set_xticks([])\nax.set_yticks([])\n\n# Add title\nplt.title(\"Blank Dixie Alley Map\", fontsize=18)\n\nplt.show()\n\n\n\n","type":"content","url":"/notebooks/ch2-mar-2023-tornado-jdh#we-will-be-looking-specifically-at-the-tornado-outbreak-that-occurred-in-dixie-alley-so-lets-set-our-extents-specifically-to-dixie-alley","position":11},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl3":"Fetch Data","lvl2":"Overview"},"type":"lvl3","url":"/notebooks/ch2-mar-2023-tornado-jdh#fetch-data","position":12},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl3":"Fetch Data","lvl2":"Overview"},"content":"","type":"content","url":"/notebooks/ch2-mar-2023-tornado-jdh#fetch-data","position":13},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl5":"This section uses s3 to pull in the data from the AWS s3 server. Following data acquisition, the module uses xarray to filter the resulting DataArray for the size of the desired map.","lvl3":"Fetch Data","lvl2":"Overview"},"type":"lvl5","url":"/notebooks/ch2-mar-2023-tornado-jdh#this-section-uses-s3-to-pull-in-the-data-from-the-aws-s3-server-following-data-acquisition-the-module-uses-xarray-to-filter-the-resulting-dataarray-for-the-size-of-the-desired-map","position":14},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl5":"This section uses s3 to pull in the data from the AWS s3 server. Following data acquisition, the module uses xarray to filter the resulting DataArray for the size of the desired map.","lvl3":"Fetch Data","lvl2":"Overview"},"content":"","type":"content","url":"/notebooks/ch2-mar-2023-tornado-jdh#this-section-uses-s3-to-pull-in-the-data-from-the-aws-s3-server-following-data-acquisition-the-module-uses-xarray-to-filter-the-resulting-dataarray-for-the-size-of-the-desired-map","position":15},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl6":"For variable names, see link here.","lvl5":"This section uses s3 to pull in the data from the AWS s3 server. Following data acquisition, the module uses xarray to filter the resulting DataArray for the size of the desired map.","lvl3":"Fetch Data","lvl2":"Overview"},"type":"lvl6","url":"/notebooks/ch2-mar-2023-tornado-jdh#for-variable-names-see-link-here","position":16},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl6":"For variable names, see link here.","lvl5":"This section uses s3 to pull in the data from the AWS s3 server. Following data acquisition, the module uses xarray to filter the resulting DataArray for the size of the desired map.","lvl3":"Fetch Data","lvl2":"Overview"},"content":"\n\n# def fetch_mrms_data(variable: str, yyyymmdd: str, hh: str) -> xr.DataArray:\n#     \"\"\"\n#     Downloads and loads MRMS data from NOAA PDS.\n\n#     Parameters:\n#         variable (str): MRMS product name (e.g., 'MergedReflectivityQC').\n#         yyyymmdd (str): Date in YYYYMMDD format.\n#         hh (str): Hour in HH format (00–23 UTC).\n\n#     Returns:\n#         xarray.DataArray: Decoded MRMS data array.\n#     \"\"\"\n#     url = (\n#         f\"https://noaa-mrms-pds.s3.amazonaws.com/CONUS/{variable}/\"\n#         f\"{yyyymmdd}/MRMS_{variable}_{yyyymmdd}-{hh}0000.grib2.gz\"\n#     )\n\n#     response = urllib.request.urlopen(url)\n#     compressed_file = response.read()\n\n#     with tempfile.NamedTemporaryFile(suffix=\".grib2\") as f:\n#         f.write(gzip.decompress(compressed_file))\n#         data_in = xr.load_dataarray(f.name, engine='cfgrib', decode_timedelta=True)\n\n#     return data_in\n\n# def fetch_mrms_data(\n#     variable: str,\n#     yyyymmdd: str,\n#     hh: str,\n#     lon_min: float = None,\n#     lat_min: float = None,\n#     lon_max: float = None,\n#     lat_max: float = None\n# ) -> xr.DataArray:\n#     \"\"\"\n#     Downloads and loads MRMS data from NOAA PDS, with optional spatial filtering.\n\n#     Parameters:\n#         variable (str): MRMS product name (e.g., 'MergedReflectivityQC').\n#         yyyymmdd (str): Date in YYYYMMDD format.\n#         hh (str): Hour in HH format (00–23 UTC).\n#         lon_min, lat_min, lon_max, lat_max (float, optional): Bounding box for spatial subset. \n\n#     Returns:\n#         xarray.DataArray: Decoded MRMS data array, optionally subset by lat/lon.\n\n#     Example use: \n#         data = fetch_mrms_data('MergedReflectivityQC', '20230325', '02', lon_min=-96, lat_min=29, lon_max=-80, lat_max=38)\n#     \"\"\"\n#     url = (\n#         f\"https://noaa-mrms-pds.s3.amazonaws.com/CONUS/{variable}/\"\n#         f\"{yyyymmdd}/MRMS_{variable}_{yyyymmdd}-{hh}0000.grib2.gz\"\n#     )\n\n#     response = urllib.request.urlopen(url)\n#     compressed_file = response.read()\n\n#     with tempfile.NamedTemporaryFile(suffix=\".grib2\") as f:\n#         f.write(gzip.decompress(compressed_file))\n#         data_in = xr.load_dataarray(f.name, engine='cfgrib', decode_timedelta=True)\n\n#     # Optional spatial filtering\n#     if all(v is not None for v in [lon_min, lat_min, lon_max, lat_max]):\n#         data_in = data_in.sel(\n#             latitude=slice(lat_max, lat_min),  # descending order\n#             longitude=slice(360 - abs(lon_min), 360 - abs(lon_max))        \n#         )\n\n#     return data_in\n\ndef find_available_files(\n    variable: str,\n    yyyymmdd: str,\n    hh: str\n):\n    \n    files_list = []\n\n    available_files = aws.ls(f'noaa-mrms-pds/CONUS/{variable}/{yyyymmdd}/', refresh=True)\n    for file in available_files:\n        file_hour = file[-15:-13]\n        if file_hour == hh:\n            files_list.append(file)\n\n    if len(files_list) == 0:\n        raise ValueError(f\"No files found for {variable} on {yyyymmdd} at hour {hh}.\")\n    else:    \n        return files_list\n\ndef fetch_mrms_data(    \n    file: str,\n    lon_min: float = None,\n    lat_min: float = None,\n    lon_max: float = None,\n    lat_max: float = None\n):\n    url = (f\"https://noaa-mrms-pds.s3.amazonaws.com/{file[14:]}\")\n    response = urllib.request.urlopen(url)\n    compressed_file = response.read()        \n    with tempfile.NamedTemporaryFile(suffix=\".grib2\") as f:\n        f.write(gzip.decompress(compressed_file))\n        data_in = xr.load_dataarray(f.name, engine='cfgrib', decode_timedelta=True)\n\n    # Optional spatial filtering\n    if all(v is not None for v in [lon_min, lat_min, lon_max, lat_max]):\n        data_in = data_in.sel(\n            latitude=slice(lat_max, lat_min),  # descending order\n            longitude=slice(360 - abs(lon_min), 360 - abs(lon_max))        \n        )\n\n    return data_in\n\n# response = urllib.request.urlopen(\"https://noaa-mrms-pds.s3.amazonaws.com/CONUS/CREF_1HR_MAX_00.50/20230325/MRMS_CREF_1HR_MAX_00.50_20230325-010000.grib2.gz\")\n\n# compressed_file = response.read()\n\n# with tempfile.NamedTemporaryFile(suffix=\".grib2\") as f:\n#             f.write(gzip.decompress(compressed_file))\n#             data_in = xr.load_dataarray(f.name, engine='cfgrib', decode_timedelta=True)\n\n\n\n","type":"content","url":"/notebooks/ch2-mar-2023-tornado-jdh#for-variable-names-see-link-here","position":17},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl2":"Case Study - March 24, 2023"},"type":"lvl2","url":"/notebooks/ch2-mar-2023-tornado-jdh#case-study-march-24-2023","position":18},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl2":"Case Study - March 24, 2023"},"content":"","type":"content","url":"/notebooks/ch2-mar-2023-tornado-jdh#case-study-march-24-2023","position":19},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl4":"Rolling Fork - Silver City, MS Tornado","lvl2":"Case Study - March 24, 2023"},"type":"lvl4","url":"/notebooks/ch2-mar-2023-tornado-jdh#rolling-fork-silver-city-ms-tornado","position":20},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl4":"Rolling Fork - Silver City, MS Tornado","lvl2":"Case Study - March 24, 2023"},"content":"","type":"content","url":"/notebooks/ch2-mar-2023-tornado-jdh#rolling-fork-silver-city-ms-tornado","position":21},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl4":"3/25/23 1z to 2z","lvl2":"Case Study - March 24, 2023"},"type":"lvl4","url":"/notebooks/ch2-mar-2023-tornado-jdh#id-3-25-23-1z-to-2z","position":22},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl4":"3/25/23 1z to 2z","lvl2":"Case Study - March 24, 2023"},"content":"\n\n# Lon mins and maxes for our projections:\nlon_min, lon_max = -96, -80\nlat_min, lat_max = 29, 38\n\n","type":"content","url":"/notebooks/ch2-mar-2023-tornado-jdh#id-3-25-23-1z-to-2z","position":23},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl3":"Maximum 1-Hour Composite Reflectivity","lvl2":"Case Study - March 24, 2023"},"type":"lvl3","url":"/notebooks/ch2-mar-2023-tornado-jdh#maximum-1-hour-composite-reflectivity","position":24},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl3":"Maximum 1-Hour Composite Reflectivity","lvl2":"Case Study - March 24, 2023"},"content":"","type":"content","url":"/notebooks/ch2-mar-2023-tornado-jdh#maximum-1-hour-composite-reflectivity","position":25},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl6":"The MRMS Max 1-Hour Composite Reflectivity product represents the highest reflectivity value observed within the past hour across all radar scans, providing a time-integrated view of storm intensity. It helps forecasters identify areas of persistent or intense convection, especially useful for tracking severe weather like hail or heavy rainfall. This product is derived from a seamless mosaic of multiple radars, quality-controlled to remove non-meteorological artifacts.","lvl3":"Maximum 1-Hour Composite Reflectivity","lvl2":"Case Study - March 24, 2023"},"type":"lvl6","url":"/notebooks/ch2-mar-2023-tornado-jdh#the-mrms-max-1-hour-composite-reflectivity-product-represents-the-highest-reflectivity-value-observed-within-the-past-hour-across-all-radar-scans-providing-a-time-integrated-view-of-storm-intensity-it-helps-forecasters-identify-areas-of-persistent-or-intense-convection-especially-useful-for-tracking-severe-weather-like-hail-or-heavy-rainfall-this-product-is-derived-from-a-seamless-mosaic-of-multiple-radars-quality-controlled-to-remove-non-meteorological-artifacts","position":26},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl6":"The MRMS Max 1-Hour Composite Reflectivity product represents the highest reflectivity value observed within the past hour across all radar scans, providing a time-integrated view of storm intensity. It helps forecasters identify areas of persistent or intense convection, especially useful for tracking severe weather like hail or heavy rainfall. This product is derived from a seamless mosaic of multiple radars, quality-controlled to remove non-meteorological artifacts.","lvl3":"Maximum 1-Hour Composite Reflectivity","lvl2":"Case Study - March 24, 2023"},"content":"\n\n#### March 24, 2023 - Rolling Fork - Silver City, MS Tornado -- EF4, 71 minutes long, est winds 195 mph\n## 3/25/23 1z to 2z, so we'll grab two hours of data shortly\n\n#Grab 2 hours of data for plotting\ncref1files = find_available_files('CREF_1HR_MAX_00.50', '20230325', '01')\ncref1z = fetch_mrms_data(cref1files[0])    \n\ncref2files = find_available_files('CREF_1HR_MAX_00.50', '20230325', '02')\ncref2z = fetch_mrms_data(cref2files[0])\n\n# Mask fill values for both datasets\nmasked1 = np.ma.masked_where(cref1z == -99.0, cref1z)\nmasked2 = np.ma.masked_where(cref2z == -99.0, cref2z)\n\n# Define bounds for Dixie Alley\nprojection = ccrs.LambertConformal(central_longitude=-88, central_latitude=34)\n\n# Create side-by-side subplots\nfig, axes = plt.subplots(\n    1, 2, figsize=(16, 8),\n    subplot_kw={'projection': projection},\n    gridspec_kw={'bottom': 0.2}  # leave room for shared colorbar\n)\n\nmeshes = []\nfor ax, masked, title in zip(axes, [masked1, masked2], [\"(a) 3/25/2023 @ 01z\", \"(b) 3/25/2023 @ 02z\"]):\n    ax.set_extent([lon_min, lon_max, lat_min, lat_max], crs=ccrs.PlateCarree())\n    ax.add_feature(cfeature.STATES.with_scale('50m'), edgecolor='gray')\n    ax.add_feature(cfeature.BORDERS.with_scale('50m'), linestyle='--', edgecolor='black')\n    ax.add_feature(cfeature.COASTLINE.with_scale('50m'))\n    \n    mesh = ax.pcolormesh(\n        cref2z.longitude, cref2z.latitude, masked,\n        cmap='turbo', transform=ccrs.PlateCarree(), shading='auto'\n    )\n    ax.set_title(title, fontsize=15)\n    meshes.append(mesh)\n\n# Add shared colorbar beneath both plots\ncbar_ax = fig.add_axes([0.25, 0.25, 0.5, 0.02])  # [left, bottom, width, height]\ncbar = fig.colorbar(meshes[0], cax=cbar_ax, orientation='horizontal')\ncbar.set_label('Reflectivity (dBZ)')\nplt.suptitle('Max 1HR Composite Reflectivity:', fontsize='20', x=0.5, y=0.85, horizontalalignment='center', verticalalignment='top')\n\nplt.show()\n\n\n\n","type":"content","url":"/notebooks/ch2-mar-2023-tornado-jdh#the-mrms-max-1-hour-composite-reflectivity-product-represents-the-highest-reflectivity-value-observed-within-the-past-hour-across-all-radar-scans-providing-a-time-integrated-view-of-storm-intensity-it-helps-forecasters-identify-areas-of-persistent-or-intense-convection-especially-useful-for-tracking-severe-weather-like-hail-or-heavy-rainfall-this-product-is-derived-from-a-seamless-mosaic-of-multiple-radars-quality-controlled-to-remove-non-meteorological-artifacts","position":27},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl3":"Surface Precip Rate","lvl2":"Case Study - March 24, 2023"},"type":"lvl3","url":"/notebooks/ch2-mar-2023-tornado-jdh#surface-precip-rate","position":28},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl3":"Surface Precip Rate","lvl2":"Case Study - March 24, 2023"},"content":"To describe Surface Precip Rate, there are three variables that can be used:","type":"content","url":"/notebooks/ch2-mar-2023-tornado-jdh#surface-precip-rate","position":29},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl5":"Surface Precipitation Rate Products","lvl3":"Surface Precip Rate","lvl2":"Case Study - March 24, 2023"},"type":"lvl5","url":"/notebooks/ch2-mar-2023-tornado-jdh#surface-precipitation-rate-products","position":30},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl5":"Surface Precipitation Rate Products","lvl3":"Surface Precip Rate","lvl2":"Case Study - March 24, 2023"},"content":"Variable Name\n\nDescription\n\nTemporal Resolution\n\nFilename Pattern\n\nInstantaneous PrecipRate\n\n- Estimates current rainfall intensity- Derived from dual-pol radar\n\n- Every 2 minutes\n\nPrecipRate_00.00\n\nMultiSensor QPE (Pass 1 & Pass 2)\n\n- Combines radar and precip gauge data- Available in 1-pass and 2-pass versions- Used for hourly accumulation\n\n- Hourly (Pass 1 and Pass 2)\n\nMRMS_QPE_01H_Pass1_00.00\n\nRadarOnly QPE\n\n- Estimates surface rainfall rate using dual-polarization radar reflectivity.- Captures rapid changes in precipitation intensity at high temporal resolution.\n\n- Every 2 minutes - Available in 15 minute as well as (1, 3, 6, 12, 24, 48) hour intervals- QPE since 12z also available\n\nRadarOnly_QPE_01H_00.00\n\n","type":"content","url":"/notebooks/ch2-mar-2023-tornado-jdh#surface-precipitation-rate-products","position":31},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl4":"Instantaneous Precip Rate","lvl3":"Surface Precip Rate","lvl2":"Case Study - March 24, 2023"},"type":"lvl4","url":"/notebooks/ch2-mar-2023-tornado-jdh#instantaneous-precip-rate","position":32},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl4":"Instantaneous Precip Rate","lvl3":"Surface Precip Rate","lvl2":"Case Study - March 24, 2023"},"content":"\n\nprecip1files= find_available_files('PrecipRate_00.00', '20230325', '01') # Precip Rate\nprecip_1z = fetch_mrms_data(precip1files[0]) \nprecip2files = find_available_files('PrecipRate_00.00', '20230325', '02')\nprecip_2z = fetch_mrms_data(precip2files[0])\nmasked1 = np.ma.masked_where(precip_1z <= 0, precip_1z)\nmasked2 = np.ma.masked_where(precip_2z <= 0, precip_2z)\n\n# Define bounds for Dixie Alley\nprojection = ccrs.LambertConformal(central_longitude=-88, central_latitude=34)\n\n# Create side-by-side subplots\nfig, axes = plt.subplots(\n    1, 2, figsize=(16, 8),\n    subplot_kw={'projection': projection},\n    gridspec_kw={'bottom': 0.2}  # leave room for shared colorbar\n)\n\nmeshes = []\nfor ax, masked, title in zip(axes, [masked1, masked2], [\"(a) 3/25/2023 @ 01z\", \"(b) 3/25/2023 @ 02z\"]):\n    ax.set_extent([lon_min, lon_max, lat_min, lat_max], crs=ccrs.PlateCarree())\n    ax.add_feature(cfeature.STATES.with_scale('50m'), edgecolor='gray')\n    ax.add_feature(cfeature.BORDERS.with_scale('50m'), linestyle='--', edgecolor='black')\n    ax.add_feature(cfeature.COASTLINE.with_scale('50m'))\n    \n    mesh = ax.pcolormesh(\n        precip_1z.longitude, precip_2z.latitude, masked,\n        cmap='turbo', transform=ccrs.PlateCarree(), shading='auto'\n    )\n    ax.set_title(title, fontsize=15)\n    meshes.append(mesh)\n\n# Add shared colorbar beneath both plots\ncbar_ax = fig.add_axes([0.25, 0.25, 0.5, 0.02])  # [left, bottom, width, height]\ncbar = fig.colorbar(meshes[0], cax=cbar_ax, orientation='horizontal')\ncbar.set_label('Precipitation (mm)')\nplt.suptitle('Instantaneous Precipitation', fontsize='20', x=0.5, y=0.85, horizontalalignment='center', verticalalignment='top')\n\nplt.show()\n\n","type":"content","url":"/notebooks/ch2-mar-2023-tornado-jdh#instantaneous-precip-rate","position":33},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl4":"MultiSensorQPE - 1 Hour - Pass 1","lvl3":"Surface Precip Rate","lvl2":"Case Study - March 24, 2023"},"type":"lvl4","url":"/notebooks/ch2-mar-2023-tornado-jdh#multisensorqpe-1-hour-pass-1","position":34},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl4":"MultiSensorQPE - 1 Hour - Pass 1","lvl3":"Surface Precip Rate","lvl2":"Case Study - March 24, 2023"},"content":"\n\n# MultiSensor_QPE_01H_Pass1_00.00\nQPE1files = find_available_files('MultiSensor_QPE_01H_Pass1_00.00', '20230325', '01') # QPE: Quantified Precip Estimation - Offered hourly.\nQPE_1z = fetch_mrms_data(QPE1files[0]) \nQPE2files = find_available_files('MultiSensor_QPE_01H_Pass1_00.00', '20230325', '02')\nQPE_2z = fetch_mrms_data(QPE2files[0])\nmasked1 = np.ma.masked_where(QPE_1z <= 0, QPE_1z)\nmasked2 = np.ma.masked_where(QPE_2z <= 0, QPE_2z)\n\n# Define bounds for Dixie Alley\nprojection = ccrs.LambertConformal(central_longitude=-88, central_latitude=34)\n\n# Create side-by-side subplots\nfig, axes = plt.subplots(\n    1, 2, figsize=(16, 8),\n    subplot_kw={'projection': projection},\n    gridspec_kw={'bottom': 0.2}  # leave room for shared colorbar\n)\n\nmeshes = []\nfor ax, masked, title in zip(axes, [masked1, masked2], [\"(a) 3/25/2023 @ 01z\", \"(b) 3/25/2023 @ 02z\"]):\n    ax.set_extent([lon_min, lon_max, lat_min, lat_max], crs=ccrs.PlateCarree())\n    ax.add_feature(cfeature.STATES.with_scale('50m'), edgecolor='gray')\n    ax.add_feature(cfeature.BORDERS.with_scale('50m'), linestyle='--', edgecolor='black')\n    ax.add_feature(cfeature.COASTLINE.with_scale('50m'))\n    \n    mesh = ax.pcolormesh(\n        QPE_1z.longitude, QPE_2z.latitude, masked,\n        cmap='turbo', transform=ccrs.PlateCarree(), shading='auto'\n    )\n    ax.set_title(title, fontsize=15)\n    meshes.append(mesh)\n\n# Add shared colorbar beneath both plots\ncbar_ax = fig.add_axes([0.25, 0.25, 0.5, 0.02])  # [left, bottom, width, height]\ncbar = fig.colorbar(meshes[0], cax=cbar_ax, orientation='horizontal')\ncbar.set_label('Precipitation (mm)')\nplt.suptitle('Multi-Sensor Quantified Precipitation Estimate (Pass 1):', fontsize='20', x=0.5, y=0.85, horizontalalignment='center', verticalalignment='top')\n\nplt.show()\n\n","type":"content","url":"/notebooks/ch2-mar-2023-tornado-jdh#multisensorqpe-1-hour-pass-1","position":35},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl4":"MultiSensorQPE - 1 Hour - Pass 2","lvl3":"Surface Precip Rate","lvl2":"Case Study - March 24, 2023"},"type":"lvl4","url":"/notebooks/ch2-mar-2023-tornado-jdh#multisensorqpe-1-hour-pass-2","position":36},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl4":"MultiSensorQPE - 1 Hour - Pass 2","lvl3":"Surface Precip Rate","lvl2":"Case Study - March 24, 2023"},"content":"\n\n# MultiSensor_QPE_01H_Pass2_00.00\nQPE1zp2files = find_available_files('MultiSensor_QPE_01H_Pass2_00.00', '20230325', '01') # QPE: Quantified Precip Estimation - last hour, 2nd pass\nQPE_1z_p2 = fetch_mrms_data(QPE1zp2files[0]) \nQPE2files = find_available_files('MultiSensor_QPE_01H_Pass2_00.00', '20230325', '02')\nQPE_2z_p2 = fetch_mrms_data(QPE2files[0])\nmasked1 = np.ma.masked_where(QPE_1z_p2 <= 0, QPE_1z_p2)\nmasked2 = np.ma.masked_where(QPE_2z_p2 <= 0, QPE_2z_p2)\n\n# Define bounds for Dixie Alley\nprojection = ccrs.LambertConformal(central_longitude=-88, central_latitude=34)\n\n# Create side-by-side subplots\nfig, axes = plt.subplots(\n    1, 2, figsize=(16, 8),\n    subplot_kw={'projection': projection},\n    gridspec_kw={'bottom': 0.2}  # leave room for shared colorbar\n)\n\nmeshes = []\nfor ax, masked, title in zip(axes, [masked1, masked2], [\"(a) 3/25/2023 @ 01z\", \"(b) 3/25/2023 @ 02z\"]):\n    ax.set_extent([lon_min, lon_max, lat_min, lat_max], crs=ccrs.PlateCarree())\n    ax.add_feature(cfeature.STATES.with_scale('50m'), edgecolor='gray')\n    ax.add_feature(cfeature.BORDERS.with_scale('50m'), linestyle='--', edgecolor='black')\n    ax.add_feature(cfeature.COASTLINE.with_scale('50m'))\n    \n    mesh = ax.pcolormesh(\n        QPE_1z_p2.longitude, QPE_2z_p2.latitude, masked,\n        cmap='turbo', transform=ccrs.PlateCarree(), shading='auto'\n    )\n    ax.set_title(title, fontsize=15)\n    meshes.append(mesh)\n\n# Add shared colorbar beneath both plots\ncbar_ax = fig.add_axes([0.25, 0.25, 0.5, 0.02])  # [left, bottom, width, height]\ncbar = fig.colorbar(meshes[0], cax=cbar_ax, orientation='horizontal')\ncbar.set_label('Precipitation (mm)')\nplt.suptitle('Multi-Sensor Quantified Precipitation Estimate (Pass 2):', fontsize='20', x=0.5, y=0.85, horizontalalignment='center', verticalalignment='top')\n\nplt.show()\n\n","type":"content","url":"/notebooks/ch2-mar-2023-tornado-jdh#multisensorqpe-1-hour-pass-2","position":37},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl4":"Radar Only QPE - Last Hour","lvl3":"Surface Precip Rate","lvl2":"Case Study - March 24, 2023"},"type":"lvl4","url":"/notebooks/ch2-mar-2023-tornado-jdh#radar-only-qpe-last-hour","position":38},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl4":"Radar Only QPE - Last Hour","lvl3":"Surface Precip Rate","lvl2":"Case Study - March 24, 2023"},"content":"\n\nRQPE1files = find_available_files('RadarOnly_QPE_01H_00.00', '20230325', '01') # RadarOnly_QPE: Radar Only Quantified Precip Estimation - last hour\nRQPE_1z = fetch_mrms_data(RQPE1files[0])\nRQPE2files = find_available_files('RadarOnly_QPE_01H_00.00', '20230325', '02')\nRQPE_2z = fetch_mrms_data(RQPE2files[0])\nmasked1 = np.ma.masked_where(RQPE_1z <= 0, RQPE_1z)\nmasked2 = np.ma.masked_where(RQPE_2z <= 0, RQPE_2z)\n\n# Define bounds for Dixie Alley\nprojection = ccrs.LambertConformal(central_longitude=-88, central_latitude=34)\n\n# Create side-by-side subplots\nfig, axes = plt.subplots(\n    1, 2, figsize=(16, 8),\n    subplot_kw={'projection': projection},\n    gridspec_kw={'bottom': 0.2}  # leave room for shared colorbar\n)\n\nmeshes = []\nfor ax, masked, title in zip(axes, [masked1, masked2], [\"(a) 3/25/2023 @ 01z\", \"(b) 3/25/2023 @ 02z\"]):\n    ax.set_extent([lon_min, lon_max, lat_min, lat_max], crs=ccrs.PlateCarree())\n    ax.add_feature(cfeature.STATES.with_scale('50m'), edgecolor='gray')\n    ax.add_feature(cfeature.BORDERS.with_scale('50m'), linestyle='--', edgecolor='black')\n    ax.add_feature(cfeature.COASTLINE.with_scale('50m'))\n    \n    mesh = ax.pcolormesh(\n        RQPE_1z.longitude, RQPE_2z.latitude, masked,\n        cmap='turbo', transform=ccrs.PlateCarree(), shading='auto'\n    )\n    ax.set_title(title, fontsize=15)\n    meshes.append(mesh)\n\n# Add shared colorbar beneath both plots\ncbar_ax = fig.add_axes([0.25, 0.25, 0.5, 0.02])  # [left, bottom, width, height]\ncbar = fig.colorbar(meshes[0], cax=cbar_ax, orientation='horizontal')\ncbar.set_label('Precipitation (mm)')\nplt.suptitle('Radar Only Quantified Precipitation Estimate:', fontsize='20', x=0.5, y=0.85, horizontalalignment='center', verticalalignment='top')\n\nplt.show()\n\n\n\n","type":"content","url":"/notebooks/ch2-mar-2023-tornado-jdh#radar-only-qpe-last-hour","position":39},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl3":"Rotation","lvl2":"Case Study - March 24, 2023"},"type":"lvl3","url":"/notebooks/ch2-mar-2023-tornado-jdh#rotation","position":40},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl3":"Rotation","lvl2":"Case Study - March 24, 2023"},"content":"","type":"content","url":"/notebooks/ch2-mar-2023-tornado-jdh#rotation","position":41},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl5":"These rotation products can be combined to assess both the intensity and persistence of storm-scale rotation across multiple atmospheric layers and time scales. By layering instantaneous azimuthal shear with rotation tracks—especially ML-enhanced versions—forecasters and researchers can better identify evolving mesocyclones, discriminate between transient and sustained rotation, and refine environmental risk assessments for severe weather.","lvl3":"Rotation","lvl2":"Case Study - March 24, 2023"},"type":"lvl5","url":"/notebooks/ch2-mar-2023-tornado-jdh#these-rotation-products-can-be-combined-to-assess-both-the-intensity-and-persistence-of-storm-scale-rotation-across-multiple-atmospheric-layers-and-time-scales-by-layering-instantaneous-azimuthal-shear-with-rotation-tracks-especially-ml-enhanced-versions-forecasters-and-researchers-can-better-identify-evolving-mesocyclones-discriminate-between-transient-and-sustained-rotation-and-refine-environmental-risk-assessments-for-severe-weather","position":42},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl5":"These rotation products can be combined to assess both the intensity and persistence of storm-scale rotation across multiple atmospheric layers and time scales. By layering instantaneous azimuthal shear with rotation tracks—especially ML-enhanced versions—forecasters and researchers can better identify evolving mesocyclones, discriminate between transient and sustained rotation, and refine environmental risk assessments for severe weather.","lvl3":"Rotation","lvl2":"Case Study - March 24, 2023"},"content":"Variable\n\nDescription\n\nTemporal Resolution\n\nFilename Pattern\n\nMerged AzShear (0-2km AGL)\n\nLow-level azimuthal shear (0–2 km AGL); highlights near-surface rotation.\n\nInstantaneous\n\nMergedAzShear_0-2kmAGL_00.50\n\nMerged AzShear (3-6km AGL)\n\nMid-level azimuthal shear (3–6 km AGL); captures elevated storm rotation.\n\nInstantaneous\n\nMergedAzShear_3-6kmAGL_00.50\n\nRotation Track (30-min)\n\n30-min accumulation of low-level rotation; useful for short-term tracking.\n\n30 minutes\n\nRotationTrack30min_00.50\n\nRotation Track (60-min)\n\n60-min accumulation of low-level rotation; highlights sustained activity.\n\n60 minutes\n\nRotationTrack60min_00.50\n\nRotation Track ML (30-min)\n\nML-enhanced 30-min rotation track; filters noise, boosts confidence.\n\n30 minutes\n\nRotationTrackML30min_00.50\n\nRotation Track ML (60-min)\n\nML-enhanced 60-min rotation track; detects short-lived intense rotation.\n\n60 minutes\n\nRotationTrackML60min_00.50\n\n","type":"content","url":"/notebooks/ch2-mar-2023-tornado-jdh#these-rotation-products-can-be-combined-to-assess-both-the-intensity-and-persistence-of-storm-scale-rotation-across-multiple-atmospheric-layers-and-time-scales-by-layering-instantaneous-azimuthal-shear-with-rotation-tracks-especially-ml-enhanced-versions-forecasters-and-researchers-can-better-identify-evolving-mesocyclones-discriminate-between-transient-and-sustained-rotation-and-refine-environmental-risk-assessments-for-severe-weather","position":43},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl4":"Merged AzShear (0-2km AGL)","lvl3":"Rotation","lvl2":"Case Study - March 24, 2023"},"type":"lvl4","url":"/notebooks/ch2-mar-2023-tornado-jdh#merged-azshear-0-2km-agl","position":44},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl4":"Merged AzShear (0-2km AGL)","lvl3":"Rotation","lvl2":"Case Study - March 24, 2023"},"content":"\n\n# MergedAzShear_0-2kmAGL_00.50\nAzshrfiles1_2km = find_available_files('MergedAzShear_0-2kmAGL_00.50', '20230325', '01') # Merged AzShr (0-2km AGL)\nAzshr_1z = fetch_mrms_data(Azshrfiles1_2km[0])\nAzshrfiles2_2km = find_available_files('MergedAzShear_0-2kmAGL_00.50', '20230325', '02')\nAzshr_2z = fetch_mrms_data(Azshrfiles2_2km[0])\nmasked1 = np.ma.masked_where(Azshr_1z <= 0, Azshr_1z)\nmasked2 = np.ma.masked_where(Azshr_2z <= 0, Azshr_2z)\n\n# Define bounds for Dixie Alley\nprojection = ccrs.LambertConformal(central_longitude=-88, central_latitude=34)\n\n# Create side-by-side subplots\nfig, axes = plt.subplots(\n    1, 2, figsize=(16, 8),\n    subplot_kw={'projection': projection},\n    gridspec_kw={'bottom': 0.2}  # leave room for shared colorbar\n)\n\nmeshes = []\nfor ax, masked, title in zip(axes, [masked1, masked2], [\"(a) 3/25/2023 @ 01z\", \"(b) 3/25/2023 @ 02z\"]):\n    ax.set_extent([lon_min, lon_max, lat_min, lat_max], crs=ccrs.PlateCarree())\n    ax.add_feature(cfeature.STATES.with_scale('50m'), edgecolor='gray')\n    ax.add_feature(cfeature.BORDERS.with_scale('50m'), linestyle='--', edgecolor='black')\n    ax.add_feature(cfeature.COASTLINE.with_scale('50m'))\n    \n    mesh = ax.pcolormesh(\n        Azshr_1z.longitude, Azshr_1z.latitude, masked,\n        cmap='turbo', transform=ccrs.PlateCarree(), shading='auto'\n    )\n    ax.set_title(title, fontsize=15)\n    meshes.append(mesh)\n\n# Add shared colorbar beneath both plots\ncbar_ax = fig.add_axes([0.25, 0.25, 0.5, 0.02])  # [left, bottom, width, height]\ncbar = fig.colorbar(meshes[0], cax=cbar_ax, orientation='horizontal')\ncbar.set_label('Azimuthal Shear (s^-1)')\nplt.suptitle('Merged AzShear (0-2km AGL):', fontsize='20', x=0.5, y=0.85, horizontalalignment='center', verticalalignment='top')\n\nplt.show()\n\n","type":"content","url":"/notebooks/ch2-mar-2023-tornado-jdh#merged-azshear-0-2km-agl","position":45},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl4":"Merged AzShear (3-6 km AGL)","lvl3":"Rotation","lvl2":"Case Study - March 24, 2023"},"type":"lvl4","url":"/notebooks/ch2-mar-2023-tornado-jdh#merged-azshear-3-6-km-agl","position":46},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl4":"Merged AzShear (3-6 km AGL)","lvl3":"Rotation","lvl2":"Case Study - March 24, 2023"},"content":"\n\n# MergedAzShear_3-6kmAGL_00.50\nAzshrfiles1_3km = find_available_files('MergedAzShear_3-6kmAGL_00.50', '20230325', '01') # Merged AzShr (3-6km AGL)\nAzshr3_1z = fetch_mrms_data(Azshrfiles1_3km[0])\nAzshrfiles2_3km = find_available_files('MergedAzShear_3-6kmAGL_00.50', '20230325', '02')\nAzshr3_2z = fetch_mrms_data(Azshrfiles2_3km[0])\nmasked1 = np.ma.masked_where(Azshr3_1z <= 0, Azshr3_1z)\nmasked2 = np.ma.masked_where(Azshr3_2z <= 0, Azshr3_2z)\n\n# Define bounds for Dixie Alley\nprojection = ccrs.LambertConformal(central_longitude=-88, central_latitude=34)\n\n# Create side-by-side subplots\nfig, axes = plt.subplots(\n    1, 2, figsize=(16, 8),\n    subplot_kw={'projection': projection},\n    gridspec_kw={'bottom': 0.2}  # leave room for shared colorbar\n)\n\nmeshes = []\nfor ax, masked, title in zip(axes, [masked1, masked2], [\"(a) 3/25/2023 @ 01z\", \"(b) 3/25/2023 @ 02z\"]):\n    ax.set_extent([lon_min, lon_max, lat_min, lat_max], crs=ccrs.PlateCarree())\n    ax.add_feature(cfeature.STATES.with_scale('50m'), edgecolor='gray')\n    ax.add_feature(cfeature.BORDERS.with_scale('50m'), linestyle='--', edgecolor='black')\n    ax.add_feature(cfeature.COASTLINE.with_scale('50m'))\n    \n    mesh = ax.pcolormesh(\n        Azshr3_1z.longitude, Azshr3_1z.latitude, masked,\n        cmap='turbo', transform=ccrs.PlateCarree(), shading='auto'\n    )\n    ax.set_title(title, fontsize=15)\n    meshes.append(mesh)\n\n# Add shared colorbar beneath both plots\ncbar_ax = fig.add_axes([0.25, 0.25, 0.5, 0.02])  # [left, bottom, width, height]\ncbar = fig.colorbar(meshes[0], cax=cbar_ax, orientation='horizontal')\ncbar.set_label('Azimuthal Shear (s^-1)')\nplt.suptitle('Merged AzShear (3-6km AGL):', fontsize='20', x=0.5, y=0.85, horizontalalignment='center', verticalalignment='top')\nplt.show()\n\n","type":"content","url":"/notebooks/ch2-mar-2023-tornado-jdh#merged-azshear-3-6-km-agl","position":47},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl4":"Rotation Track (30-minute)","lvl3":"Rotation","lvl2":"Case Study - March 24, 2023"},"type":"lvl4","url":"/notebooks/ch2-mar-2023-tornado-jdh#rotation-track-30-minute","position":48},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl4":"Rotation Track (30-minute)","lvl3":"Rotation","lvl2":"Case Study - March 24, 2023"},"content":"\n\n# RotationTrack30min_00.50 \nRoTrack_30mFiles1 = find_available_files('RotationTrack30min_00.50', '20230325', '01') # Rotation Tracks (30-min)\nRoTrack_30m_1z = fetch_mrms_data(RoTrack_30mFiles1[0])\nRoTrack_30mFiles2 = find_available_files('RotationTrack30min_00.50', '20230325', '02')\nRoTrack_30m_2z = fetch_mrms_data(RoTrack_30mFiles2[0])\nmasked1 = np.ma.masked_where(RoTrack_30m_1z <= 0, RoTrack_30m_1z)\nmasked2 = np.ma.masked_where(RoTrack_30m_2z <= 0, RoTrack_30m_2z)\n\n# Define bounds for Dixie Alley\nprojection = ccrs.LambertConformal(central_longitude=-88, central_latitude=34)\n\n# Create side-by-side subplots\nfig, axes = plt.subplots(\n    1, 2, figsize=(16, 8),\n    subplot_kw={'projection': projection},\n    gridspec_kw={'bottom': 0.2}  # leave room for shared colorbar\n)\n\nmeshes = []\nfor ax, masked, title in zip(axes, [masked1, masked2], [\"(a) 3/25/2023 @ 01z\", \"(b) 3/25/2023 @ 02z\"]):\n    ax.set_extent([lon_min, lon_max, lat_min, lat_max], crs=ccrs.PlateCarree())\n    ax.add_feature(cfeature.STATES.with_scale('50m'), edgecolor='gray')\n    ax.add_feature(cfeature.BORDERS.with_scale('50m'), linestyle='--', edgecolor='black')\n    ax.add_feature(cfeature.COASTLINE.with_scale('50m'))\n    \n    mesh = ax.pcolormesh(\n        RoTrack_30m_1z.longitude, RoTrack_30m_1z.latitude, masked,\n        cmap='turbo', transform=ccrs.PlateCarree(), shading='auto'\n    )\n    ax.set_title(title, fontsize=15)\n    meshes.append(mesh)\n\n# Add shared colorbar beneath both plots\ncbar_ax = fig.add_axes([0.25, 0.25, 0.5, 0.02])  # [left, bottom, width, height]\ncbar = fig.colorbar(meshes[0], cax=cbar_ax, orientation='horizontal')\ncbar.set_label('Units')\nplt.suptitle('Rotation Track (30-minutes):', fontsize='20', x=0.5, y=0.85, horizontalalignment='center', verticalalignment='top')\nplt.show()\n\n","type":"content","url":"/notebooks/ch2-mar-2023-tornado-jdh#rotation-track-30-minute","position":49},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl4":"Rotation Track (60 minutes)","lvl3":"Rotation","lvl2":"Case Study - March 24, 2023"},"type":"lvl4","url":"/notebooks/ch2-mar-2023-tornado-jdh#rotation-track-60-minutes","position":50},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl4":"Rotation Track (60 minutes)","lvl3":"Rotation","lvl2":"Case Study - March 24, 2023"},"content":"\n\n# RotationTrack60min_00.50\nRoTrack_60mFiles1 = find_available_files('RotationTrack60min_00.50', '20230325', '01') # Rotation Tracks (60-min)\nRoTrack_60m_1z = fetch_mrms_data(RoTrack_60mFiles1[0])\nRoTrack_60mFiles2 = find_available_files('RotationTrack30min_00.50', '20230325', '02')\nRoTrack_60m_2z = fetch_mrms_data(RoTrack_60mFiles2[0])\nmasked1 = np.ma.masked_where(RoTrack_60m_1z <= 0, RoTrack_60m_1z)\nmasked2 = np.ma.masked_where(RoTrack_60m_2z <= 0, RoTrack_60m_2z)\n\n# Define bounds for Dixie Alley\nprojection = ccrs.LambertConformal(central_longitude=-88, central_latitude=34)\n\n# Create side-by-side subplots\nfig, axes = plt.subplots(\n    1, 2, figsize=(16, 8),\n    subplot_kw={'projection': projection},\n    gridspec_kw={'bottom': 0.2}  # leave room for shared colorbar\n)\n\nmeshes = []\nfor ax, masked, title in zip(axes, [masked1, masked2], [\"(a) 3/25/2023 @ 01z\", \"(b) 3/25/2023 @ 02z\"]):\n    ax.set_extent([lon_min, lon_max, lat_min, lat_max], crs=ccrs.PlateCarree())\n    ax.add_feature(cfeature.STATES.with_scale('50m'), edgecolor='gray')\n    ax.add_feature(cfeature.BORDERS.with_scale('50m'), linestyle='--', edgecolor='black')\n    ax.add_feature(cfeature.COASTLINE.with_scale('50m'))\n    \n    mesh = ax.pcolormesh(\n        RoTrack_60m_1z.longitude, RoTrack_60m_1z.latitude, masked,\n        cmap='turbo', transform=ccrs.PlateCarree(), shading='auto'\n    )\n    ax.set_title(title, fontsize=15)\n    meshes.append(mesh)\n\n# Add shared colorbar beneath both plots\ncbar_ax = fig.add_axes([0.25, 0.25, 0.5, 0.02])  # [left, bottom, width, height]\ncbar = fig.colorbar(meshes[0], cax=cbar_ax, orientation='horizontal')\ncbar.set_label('Units')\nplt.suptitle('Rotation Track (Last 60-minutes):', fontsize='20', x=0.5, y=0.85, horizontalalignment='center', verticalalignment='top')\nplt.show()\n\n#Coming soon:\n# RotationTrackML60min_00.50 -  for the sake of time, hold on this\n# RotationTrackML30min_00.50 -  for the sake of time, hold on this\n\n\n\n","type":"content","url":"/notebooks/ch2-mar-2023-tornado-jdh#rotation-track-60-minutes","position":51},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl4":"Hail Swaths","lvl3":"Rotation","lvl2":"Case Study - March 24, 2023"},"type":"lvl4","url":"/notebooks/ch2-mar-2023-tornado-jdh#hail-swaths","position":52},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl4":"Hail Swaths","lvl3":"Rotation","lvl2":"Case Study - March 24, 2023"},"content":"\n\n# MESH_00.50 - Maximum Expected Size of Hail\nMeshFiles1 = find_available_files('MESH_00.50', '20230325', '01') # MESH\nMesh1z = fetch_mrms_data(MeshFiles1[0])\nMeshFiles2 = find_available_files('MESH_00.50', '20230325', '02')\nMesh2z = fetch_mrms_data(MeshFiles2[0])\nmasked1 = np.ma.masked_where(Mesh1z <= 0, Mesh1z)\nmasked2 = np.ma.masked_where(Mesh2z <= 0, Mesh2z)\n\n# Define bounds for Dixie Alley\nprojection = ccrs.LambertConformal(central_longitude=-88, central_latitude=34)\n\n# Create side-by-side subplots\nfig, axes = plt.subplots(\n    1, 2, figsize=(16, 8),\n    subplot_kw={'projection': projection},\n    gridspec_kw={'bottom': 0.2}  # leave room for shared colorbar\n)\n\nmeshes = []\nfor ax, masked, title in zip(axes, [masked1, masked2], [\"(a) 3/25/2023 @ 01z\", \"(b) 3/25/2023 @ 02z\"]):\n    ax.set_extent([lon_min, lon_max, lat_min, lat_max], crs=ccrs.PlateCarree())\n    ax.add_feature(cfeature.STATES.with_scale('50m'), edgecolor='gray')\n    ax.add_feature(cfeature.BORDERS.with_scale('50m'), linestyle='--', edgecolor='black')\n    ax.add_feature(cfeature.COASTLINE.with_scale('50m'))\n    \n    mesh = ax.pcolormesh(\n        Mesh1z.longitude, Mesh1z.latitude, masked,\n        cmap='turbo', transform=ccrs.PlateCarree(), shading='auto'\n    )\n    ax.set_title(title, fontsize=15)\n    meshes.append(mesh)\n\n# Add shared colorbar beneath both plots\ncbar_ax = fig.add_axes([0.25, 0.25, 0.5, 0.02])  # [left, bottom, width, height]\ncbar = fig.colorbar(meshes[0], cax=cbar_ax, orientation='horizontal')\ncbar.set_label('Units')\nplt.suptitle('Maximum Expected Size of Hail:', fontsize='20', x=0.5, y=0.85, horizontalalignment='center', verticalalignment='top')\nplt.show()\n\n","type":"content","url":"/notebooks/ch2-mar-2023-tornado-jdh#hail-swaths","position":53},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl4":"Severe Hail Index","lvl3":"Rotation","lvl2":"Case Study - March 24, 2023"},"type":"lvl4","url":"/notebooks/ch2-mar-2023-tornado-jdh#severe-hail-index","position":54},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl4":"Severe Hail Index","lvl3":"Rotation","lvl2":"Case Study - March 24, 2023"},"content":"\n\n# SHI_00.50 - Severe Hail Index\nSHIFiles1 = find_available_files('SHI_00.50', '20230325', '01') # SHI\nSHI1z = fetch_mrms_data(SHIFiles1[0])\nSHIFiles2 = find_available_files('SHI_00.50', '20230325', '02')\nSHI2z = fetch_mrms_data(SHIFiles2[0])\nmasked1 = np.ma.masked_where(SHI1z <= 0, SHI1z)\nmasked2 = np.ma.masked_where(SHI2z <= 0, SHI2z)\n\n# Define bounds for Dixie Alley\nprojection = ccrs.LambertConformal(central_longitude=-88, central_latitude=34)\n\n# Create side-by-side subplots\nfig, axes = plt.subplots(\n    1, 2, figsize=(16, 8),\n    subplot_kw={'projection': projection},\n    gridspec_kw={'bottom': 0.2}  # leave room for shared colorbar\n)\n\nmeshes = []\nfor ax, masked, title in zip(axes, [masked1, masked2], [\"(a) 3/25/2023 @ 01z\", \"(b) 3/25/2023 @ 02z\"]):\n    ax.set_extent([lon_min, lon_max, lat_min, lat_max], crs=ccrs.PlateCarree())\n    ax.add_feature(cfeature.STATES.with_scale('50m'), edgecolor='gray')\n    ax.add_feature(cfeature.BORDERS.with_scale('50m'), linestyle='--', edgecolor='black')\n    ax.add_feature(cfeature.COASTLINE.with_scale('50m'))\n    \n    mesh = ax.pcolormesh(\n        SHI1z.longitude, SHI1z.latitude, masked,\n        cmap='turbo', transform=ccrs.PlateCarree(), shading='auto'\n    )\n    ax.set_title(title, fontsize=15)\n    meshes.append(mesh)\n\n# Add shared colorbar beneath both plots\ncbar_ax = fig.add_axes([0.25, 0.25, 0.5, 0.02])  # [left, bottom, width, height]\ncbar = fig.colorbar(meshes[0], cax=cbar_ax, orientation='horizontal')\ncbar.set_label('Units')\nplt.suptitle('Severe Hail Index:', fontsize='20', x=0.5, y=0.85, horizontalalignment='center', verticalalignment='top')\nplt.show()\n\n","type":"content","url":"/notebooks/ch2-mar-2023-tornado-jdh#severe-hail-index","position":55},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl4":"Vertically Integrated Ice","lvl3":"Rotation","lvl2":"Case Study - March 24, 2023"},"type":"lvl4","url":"/notebooks/ch2-mar-2023-tornado-jdh#vertically-integrated-ice","position":56},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl4":"Vertically Integrated Ice","lvl3":"Rotation","lvl2":"Case Study - March 24, 2023"},"content":"\n\n# VII_00.50 - Vertically Integrated Ice\nVIIFiles1 = find_available_files('VII_00.50', '20230325', '01')\nVII1z = fetch_mrms_data(VIIFiles1[0])\nVIIFiles2 = find_available_files('VII_00.50', '20230325', '02')\nVII2z = fetch_mrms_data(VIIFiles2[0])\nmasked1 = np.ma.masked_where(VII1z <= 0, VII1z)\nmasked2 = np.ma.masked_where(VII2z <= 0, VII2z)\n\n# Define bounds for Dixie Alley\nprojection = ccrs.LambertConformal(central_longitude=-88, central_latitude=34)\n\n# Create side-by-side subplots\nfig, axes = plt.subplots(\n    1, 2, figsize=(16, 8),\n    subplot_kw={'projection': projection},\n    gridspec_kw={'bottom': 0.2}  # leave room for shared colorbar\n)\n\nmeshes = []\nfor ax, masked, title in zip(axes, [masked1, masked2], [\"(a) 3/25/2023 @ 01z\", \"(b) 3/25/2023 @ 02z\"]):\n    ax.set_extent([lon_min, lon_max, lat_min, lat_max], crs=ccrs.PlateCarree())\n    ax.add_feature(cfeature.STATES.with_scale('50m'), edgecolor='gray')\n    ax.add_feature(cfeature.BORDERS.with_scale('50m'), linestyle='--', edgecolor='black')\n    ax.add_feature(cfeature.COASTLINE.with_scale('50m'))\n    \n    mesh = ax.pcolormesh(\n        VII1z.longitude, VII1z.latitude, masked,\n        cmap='turbo', transform=ccrs.PlateCarree(), shading='auto'\n    )\n    ax.set_title(title, fontsize=15)\n    meshes.append(mesh)\n\n# Add shared colorbar beneath both plots\ncbar_ax = fig.add_axes([0.25, 0.25, 0.5, 0.02])  # [left, bottom, width, height]\ncbar = fig.colorbar(meshes[0], cax=cbar_ax, orientation='horizontal')\ncbar.set_label('Units')\nplt.suptitle('Vertically Integrated Ice:', fontsize='20', x=0.5, y=0.85, horizontalalignment='center', verticalalignment='top')\nplt.show()\n\n","type":"content","url":"/notebooks/ch2-mar-2023-tornado-jdh#vertically-integrated-ice","position":57},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl4":"Probability of Severe Hail","lvl3":"Rotation","lvl2":"Case Study - March 24, 2023"},"type":"lvl4","url":"/notebooks/ch2-mar-2023-tornado-jdh#probability-of-severe-hail","position":58},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl4":"Probability of Severe Hail","lvl3":"Rotation","lvl2":"Case Study - March 24, 2023"},"content":"\n\n# POSH_00.50\nPOSHFiles1 = find_available_files('POSH_00.50', '20230325', '01')\nPOSH1z = fetch_mrms_data(POSHFiles1[0])\nPOSHFiles2 = find_available_files('POSH_00.50', '20230325', '02')\nPOSH2z = fetch_mrms_data(POSHFiles2[0])\nmasked1 = np.ma.masked_where(POSH1z <= 0, POSH1z)\nmasked2 = np.ma.masked_where(POSH2z <= 0, POSH2z)\n\nprojection = ccrs.LambertConformal(central_longitude=-88, central_latitude=34)\n\n# Create side-by-side subplots\nfig, axes = plt.subplots(\n    1, 2, figsize=(16, 8),\n    subplot_kw={'projection': projection},\n    gridspec_kw={'bottom': 0.2}  # leave room for shared colorbar\n)\n\nmeshes = []\nfor ax, masked, title in zip(axes, [masked1, masked2], [\"(a) 3/25/2023 @ 01z\", \"(b) 3/25/2023 @ 02z\"]):\n    ax.set_extent([lon_min, lon_max, lat_min, lat_max], crs=ccrs.PlateCarree())\n    ax.add_feature(cfeature.STATES.with_scale('50m'), edgecolor='gray')\n    ax.add_feature(cfeature.BORDERS.with_scale('50m'), linestyle='--', edgecolor='black')\n    ax.add_feature(cfeature.COASTLINE.with_scale('50m'))\n    \n    mesh = ax.pcolormesh(\n        POSH1z.longitude, POSH1z.latitude, masked,\n        cmap='turbo', transform=ccrs.PlateCarree(), shading='auto'\n    )\n    ax.set_title(title, fontsize=15)\n    meshes.append(mesh)\n\n# Add shared colorbar beneath both plots\ncbar_ax = fig.add_axes([0.25, 0.25, 0.5, 0.02])  # [left, bottom, width, height]\ncbar = fig.colorbar(meshes[0], cax=cbar_ax, orientation='horizontal')\ncbar.set_label('Units')\nplt.suptitle('Probability of Severe Hail', fontsize='20', x=0.5, y=0.85, horizontalalignment='center', verticalalignment='top')\nplt.show()\n\n\n\n","type":"content","url":"/notebooks/ch2-mar-2023-tornado-jdh#probability-of-severe-hail","position":59},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl3":"Storm Intensity - Vertically Integrated Liquid","lvl2":"Case Study - March 24, 2023"},"type":"lvl3","url":"/notebooks/ch2-mar-2023-tornado-jdh#storm-intensity-vertically-integrated-liquid","position":60},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl3":"Storm Intensity - Vertically Integrated Liquid","lvl2":"Case Study - March 24, 2023"},"content":"\n\n# VIL_00.50\nVILFiles1 = find_available_files('VIL_00.50', '20230325', '01')\nVIL1z = fetch_mrms_data(VILFiles1[0])\nVILFiles2 = find_available_files('VIL_00.50', '20230325', '02')\nVIL2z = fetch_mrms_data(VILFiles2[0])\nmasked1 = np.ma.masked_where(VIL1z <= 0, VIL1z)\nmasked2 = np.ma.masked_where(VIL2z <= 0, VIL2z)\n\n# Define bounds for Dixie Alley\nprojection = ccrs.LambertConformal(central_longitude=-88, central_latitude=34)\n\n# Create side-by-side subplots\nfig, axes = plt.subplots(\n    1, 2, figsize=(16, 8),\n    subplot_kw={'projection': projection},\n    gridspec_kw={'bottom': 0.2}  # leave room for shared colorbar\n)\n\nmeshes = []\nfor ax, masked, title in zip(axes, [masked1, masked2], [\"(a) 3/25/2023 @ 01z\", \"(b) 3/25/2023 @ 02z\"]):\n    ax.set_extent([lon_min, lon_max, lat_min, lat_max], crs=ccrs.PlateCarree())\n    ax.add_feature(cfeature.STATES.with_scale('50m'), edgecolor='gray')\n    ax.add_feature(cfeature.BORDERS.with_scale('50m'), linestyle='--', edgecolor='black')\n    ax.add_feature(cfeature.COASTLINE.with_scale('50m'))\n    \n    mesh = ax.pcolormesh(\n        VIL1z.longitude, VIL1z.latitude, masked,\n        cmap='turbo', transform=ccrs.PlateCarree(), shading='auto'\n    )\n    ax.set_title(title, fontsize=15)\n    meshes.append(mesh)\n\n# Add shared colorbar beneath both plots\ncbar_ax = fig.add_axes([0.25, 0.25, 0.5, 0.02])  # [left, bottom, width, height]\ncbar = fig.colorbar(meshes[0], cax=cbar_ax, orientation='horizontal')\ncbar.set_label('Units')\nplt.suptitle('Vertically Integrated Liquid:', fontsize='20', x=0.5, y=0.85, horizontalalignment='center', verticalalignment='top')\nplt.show()\n\n","type":"content","url":"/notebooks/ch2-mar-2023-tornado-jdh#storm-intensity-vertically-integrated-liquid","position":61},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl4":"Vertically Integrated Liquid Density","lvl3":"Storm Intensity - Vertically Integrated Liquid","lvl2":"Case Study - March 24, 2023"},"type":"lvl4","url":"/notebooks/ch2-mar-2023-tornado-jdh#vertically-integrated-liquid-density","position":62},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl4":"Vertically Integrated Liquid Density","lvl3":"Storm Intensity - Vertically Integrated Liquid","lvl2":"Case Study - March 24, 2023"},"content":"\n\n# VIL_Density_00.50\nVILDFiles1 = find_available_files('VIL_Density_00.50', '20230325', '01')\nVILD1z = fetch_mrms_data(VILDFiles1[0])\nVILDFiles2 = find_available_files('VIL_Density_00.50', '20230325', '02')\nVILD2z = fetch_mrms_data(VILDFiles2[0])\nmasked1 = np.ma.masked_where(VILD1z <= 0, VILD1z)\nmasked2 = np.ma.masked_where(VILD2z <= 0, VILD2z)\n\n# Define bounds for Dixie Alley\nprojection = ccrs.LambertConformal(central_longitude=-88, central_latitude=34)\n\n# Create side-by-side subplots\nfig, axes = plt.subplots(\n    1, 2, figsize=(16, 8),\n    subplot_kw={'projection': projection},\n    gridspec_kw={'bottom': 0.2}  # leave room for shared colorbar\n)\n\nmeshes = []\nfor ax, masked, title in zip(axes, [masked1, masked2], [\"(a) 3/25/2023 @ 01z\", \"(b) 3/25/2023 @ 02z\"]):\n    ax.set_extent([lon_min, lon_max, lat_min, lat_max], crs=ccrs.PlateCarree())\n    ax.add_feature(cfeature.STATES.with_scale('50m'), edgecolor='gray')\n    ax.add_feature(cfeature.BORDERS.with_scale('50m'), linestyle='--', edgecolor='black')\n    ax.add_feature(cfeature.COASTLINE.with_scale('50m'))\n    \n    mesh = ax.pcolormesh(\n        VILD1z.longitude, VILD1z.latitude, masked,\n        cmap='turbo', transform=ccrs.PlateCarree(), shading='auto'\n    )\n    ax.set_title(title, fontsize=15)\n    meshes.append(mesh)\n\n# Add shared colorbar beneath both plots\ncbar_ax = fig.add_axes([0.25, 0.25, 0.5, 0.02])  # [left, bottom, width, height]\ncbar = fig.colorbar(meshes[0], cax=cbar_ax, orientation='horizontal')\ncbar.set_label('Units')\nplt.suptitle('Vertically Integrated Liquid Density:', fontsize='20', x=0.5, y=0.85, horizontalalignment='center', verticalalignment='top')\nplt.show()\n\n","type":"content","url":"/notebooks/ch2-mar-2023-tornado-jdh#vertically-integrated-liquid-density","position":63},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl4":"120-Minute Vertically Integrated Liquid Maximum","lvl3":"Storm Intensity - Vertically Integrated Liquid","lvl2":"Case Study - March 24, 2023"},"type":"lvl4","url":"/notebooks/ch2-mar-2023-tornado-jdh#id-120-minute-vertically-integrated-liquid-maximum","position":64},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl4":"120-Minute Vertically Integrated Liquid Maximum","lvl3":"Storm Intensity - Vertically Integrated Liquid","lvl2":"Case Study - March 24, 2023"},"content":"\n\n# VIL_Max_120min_00.50\nVILMFiles1 = find_available_files('VIL_Max_120min_00.50', '20230325', '01')\nVILM1z = fetch_mrms_data(VILMFiles1[0])\nVILMFiles2 = find_available_files('VIL_Max_120min_00.50', '20230325', '02')\nVILM2z = fetch_mrms_data(VILMFiles2[0])\nmasked1 = np.ma.masked_where(VILM1z <= 0, VILM1z)\nmasked2 = np.ma.masked_where(VILM2z <= 0, VILM2z)\n\n# Define bounds for Dixie Alley\nprojection = ccrs.LambertConformal(central_longitude=-88, central_latitude=34)\n\n# Create side-by-side subplots\nfig, axes = plt.subplots(\n    1, 2, figsize=(16, 8),\n    subplot_kw={'projection': projection},\n    gridspec_kw={'bottom': 0.2}  # leave room for shared colorbar\n)\n\nmeshes = []\nfor ax, masked, title in zip(axes, [masked1, masked2], [\"(a) 3/25/2023 @ 01z\", \"(b) 3/25/2023 @ 02z\"]):\n    ax.set_extent([lon_min, lon_max, lat_min, lat_max], crs=ccrs.PlateCarree())\n    ax.add_feature(cfeature.STATES.with_scale('50m'), edgecolor='gray')\n    ax.add_feature(cfeature.BORDERS.with_scale('50m'), linestyle='--', edgecolor='black')\n    ax.add_feature(cfeature.COASTLINE.with_scale('50m'))\n    \n    mesh = ax.pcolormesh(\n        VILM1z.longitude, VILM1z.latitude, masked,\n        cmap='turbo', transform=ccrs.PlateCarree(), shading='auto'\n    )\n    ax.set_title(title, fontsize=15)\n    meshes.append(mesh)\n\n# Add shared colorbar beneath both plots\ncbar_ax = fig.add_axes([0.25, 0.25, 0.5, 0.02])  # [left, bottom, width, height]\ncbar = fig.colorbar(meshes[0], cax=cbar_ax, orientation='horizontal')\ncbar.set_label('Units')\nplt.suptitle('120-Minute Vertically Integrated Liqud Maximum:', fontsize='20', x=0.5, y=0.85, horizontalalignment='center', verticalalignment='top')\nplt.show()\n\n\n\n","type":"content","url":"/notebooks/ch2-mar-2023-tornado-jdh#id-120-minute-vertically-integrated-liquid-maximum","position":65},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl3":"Conclusion","lvl2":"Case Study - March 24, 2023"},"type":"lvl3","url":"/notebooks/ch2-mar-2023-tornado-jdh#conclusion","position":66},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl3":"Conclusion","lvl2":"Case Study - March 24, 2023"},"content":"This chapter demonstrated how MRMS data can be efficiently accessed, processed, and visualized to analyze severe weather events, using the Rolling Fork–Silver City tornado as a case study. By leveraging AWS-hosted datasets and customizing spatial extents, users can explore multiple dimensions of storm structure—from reflectivity and rotation to hail swaths and precipitation rates.\n\nThe workflow presented here not only underscores the value of MRMS products for post-event analysis but also equips researchers and practitioners with tools to rapidly assess and interpret high-impact weather. As severe weather threats continue to evolve, accessible and scalable data pipelines like this one are essential for advancing situational awareness and scientific understanding.","type":"content","url":"/notebooks/ch2-mar-2023-tornado-jdh#conclusion","position":67},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl3":"Next Steps","lvl2":"Case Study - March 24, 2023"},"type":"lvl3","url":"/notebooks/ch2-mar-2023-tornado-jdh#next-steps","position":68},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl3":"Next Steps","lvl2":"Case Study - March 24, 2023"},"content":"In the next chapter, we shift focus from tornadic activity to flood impacts by examining the Texas Floods of early July 2025. Using the same MRMS data pipeline introduced here, we explore how radar reflectivity can be used to assess flood severity and spatial extent.\n\nThis upcoming case study highlights the adaptability of MRMS datasets for analyzing diverse weather hazards—demonstrating how a unified data approach can support both convective and flood event investigations.\n\n","type":"content","url":"/notebooks/ch2-mar-2023-tornado-jdh#next-steps","position":69},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl3":"Resources and references","lvl2":"Case Study - March 24, 2023"},"type":"lvl3","url":"/notebooks/ch2-mar-2023-tornado-jdh#resources-and-references","position":70},{"hierarchy":{"lvl1":"Chapter 2: Case Study","lvl3":"Resources and references","lvl2":"Case Study - March 24, 2023"},"content":"\n\nNOAA/NSSL, 2025: Multi-Radar/Multi-Sensor System (MRMS). National Severe Storms Laboratory. \n\nhttps://​www​.nssl​.noaa​.gov​/projects​/mrms/","type":"content","url":"/notebooks/ch2-mar-2023-tornado-jdh#resources-and-references","position":71},{"hierarchy":{"lvl1":"Chapter 3: July 2025 Central TX Floods"},"type":"lvl1","url":"/notebooks/ch3-txfloods","position":0},{"hierarchy":{"lvl1":"Chapter 3: July 2025 Central TX Floods"},"content":"","type":"content","url":"/notebooks/ch3-txfloods","position":1},{"hierarchy":{"lvl1":"Chapter 3: July 2025 Central TX Floods","lvl2":"Overview"},"type":"lvl2","url":"/notebooks/ch3-txfloods#overview","position":2},{"hierarchy":{"lvl1":"Chapter 3: July 2025 Central TX Floods","lvl2":"Overview"},"content":"","type":"content","url":"/notebooks/ch3-txfloods#overview","position":3},{"hierarchy":{"lvl1":"Chapter 3: July 2025 Central TX Floods","lvl4":"This notebook walks through how to access, visualize, and animate low-level composite reflectivity data from the Multi-Radar/Multi-Sensor (MRMS) system.","lvl2":"Overview"},"type":"lvl4","url":"/notebooks/ch3-txfloods#this-notebook-walks-through-how-to-access-visualize-and-animate-low-level-composite-reflectivity-data-from-the-multi-radar-multi-sensor-mrms-system","position":4},{"hierarchy":{"lvl1":"Chapter 3: July 2025 Central TX Floods","lvl4":"This notebook walks through how to access, visualize, and animate low-level composite reflectivity data from the Multi-Radar/Multi-Sensor (MRMS) system.","lvl2":"Overview"},"content":"The case study focuses on the Central Texas flood event in July 2025, using reflectivity data hosted on AWS. The main steps include:\n\nSelecting and downloading MRMS data for specific timestamps\n\nCreating a static reflectivity map\n\nBuilding an animation to show reflectivity changes over time\n\nThis notebook is intended for students, forecasters, or researchers looking to explore radar visualization techniques or build familiarity with remote sensing workflows using Python.\n\n","type":"content","url":"/notebooks/ch3-txfloods#this-notebook-walks-through-how-to-access-visualize-and-animate-low-level-composite-reflectivity-data-from-the-multi-radar-multi-sensor-mrms-system","position":5},{"hierarchy":{"lvl1":"Chapter 3: July 2025 Central TX Floods","lvl3":"What is MRMS?","lvl2":"Overview"},"type":"lvl3","url":"/notebooks/ch3-txfloods#what-is-mrms","position":6},{"hierarchy":{"lvl1":"Chapter 3: July 2025 Central TX Floods","lvl3":"What is MRMS?","lvl2":"Overview"},"content":"The Multi-Radar/Multi-Sensor (MRMS) system is a set of real-time analysis products developed by NOAA’s National Severe Storms Laboratory (NSSL). It brings together data from:\n\nDozens of NEXRAD radars\n\nSurface observations\n\nSatellites\n\nLightning detection networks\n\nto create high-resolution snapshots of precipitation, severe weather, and related hazards.\n\nMRMS updates every 2.5 minutes and is commonly used in operational forecasting, hydrology, aviation, and research.","type":"content","url":"/notebooks/ch3-txfloods#what-is-mrms","position":7},{"hierarchy":{"lvl1":"Chapter 3: July 2025 Central TX Floods","lvl3":"Goal of This Notebook","lvl2":"Overview"},"type":"lvl3","url":"/notebooks/ch3-txfloods#goal-of-this-notebook","position":8},{"hierarchy":{"lvl1":"Chapter 3: July 2025 Central TX Floods","lvl3":"Goal of This Notebook","lvl2":"Overview"},"content":"The goal of this notebook is to walk through a simple, practical workflow for visualizing radar reflectivity data using Python. Specifically, we’ll:\n\nAccess MRMS Layer Composite Reflectivity Low data from AWS Open Data\n\nPlot a single reflectivity frame as a static map\n\nAnimate a 6-frame sequence from July 4, 2025, during the Central Texas flood event\n\nDemonstrate how to work with gridded radar data using open-source tools like MetPy, Cartopy, and xarray\n\n","type":"content","url":"/notebooks/ch3-txfloods#goal-of-this-notebook","position":9},{"hierarchy":{"lvl1":"Chapter 3: July 2025 Central TX Floods","lvl2":"Imports"},"type":"lvl2","url":"/notebooks/ch3-txfloods#imports","position":10},{"hierarchy":{"lvl1":"Chapter 3: July 2025 Central TX Floods","lvl2":"Imports"},"content":"below are the python packages that are used for this code\n\n# Core packages\nimport gzip\nimport tempfile\n\n# File handling (if you're downloading MRMS .grib2.gz files manually)\nimport urllib.request\nfrom datetime import datetime, timedelta\nfrom io import StringIO\n\nimport cartopy.crs as ccrs\nimport cartopy.feature as cfeature\nimport cmweather  # noqa: F401\nimport matplotlib.colors as mcolors\n\n# Plotting\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport numpy.ma as ma\nimport pandas as pd\nimport requests\nimport s3fs\nimport xarray as xr\nfrom IPython.display import HTML  # To display the animation\n\n# Animation\nfrom matplotlib.animation import ArtistAnimation, PillowWriter\nfrom metpy.plots import ctables  # For NWS reflectivity colormap\nfrom scipy.interpolate import RegularGridInterpolator\n\n\n\n","type":"content","url":"/notebooks/ch3-txfloods#imports","position":11},{"hierarchy":{"lvl1":"Chapter 3: July 2025 Central TX Floods","lvl2":"Define Timestamps and Colormap"},"type":"lvl2","url":"/notebooks/ch3-txfloods#define-timestamps-and-colormap","position":12},{"hierarchy":{"lvl1":"Chapter 3: July 2025 Central TX Floods","lvl2":"Define Timestamps and Colormap"},"content":"To build the animation, we’ll use 6 hourly frames of MRMS data from the morning of July 4, 2025. Each timestamp matches a GRIB2 file available from the AWS MRMS archive.\n\nWe also define the standard NWS reflectivity colormap using MetPy, which gives us consistent color breaks every 5 dBZ which is a common setup for radar reflectivity plots.\n\n","type":"content","url":"/notebooks/ch3-txfloods#define-timestamps-and-colormap","position":13},{"hierarchy":{"lvl1":"Chapter 3: July 2025 Central TX Floods","lvl3":"Access and Load MRMS Data","lvl2":"Define Timestamps and Colormap"},"type":"lvl3","url":"/notebooks/ch3-txfloods#access-and-load-mrms-data","position":14},{"hierarchy":{"lvl1":"Chapter 3: July 2025 Central TX Floods","lvl3":"Access and Load MRMS Data","lvl2":"Define Timestamps and Colormap"},"content":"MRMS data is stored as .grib2.gz files on the AWS S3 public data bucket. Each file represents a single timestamp and product type.\n\nIn this step:\n\nWe use urllib.request.urlopen() to download the compressed file directly from AWS\n\nWe decompress it using Python’s built-in gzip module\n\nThen we load the GRIB2 file into an xarray.DataArray using the cfgrib engine\n\nThis approach lets us work with the data directly in Python without having to manually download or unzip anything ahead of time.\n\n# Define the URL to the compressed MRMS GRIB2 file for a specific timestamp\nurl = \"https://noaa-mrms-pds.s3.amazonaws.com/CONUS/LayerCompositeReflectivity_Low_00.50/20250704/MRMS_LayerCompositeReflectivity_Low_00.50_20250704-001040.grib2.gz\"\n\n# Download the file as bytes\nresponse = urllib.request.urlopen(url)\ncompressed_file = response.read()\n\n# Decompress and load into xarray using a temporary file\nwith tempfile.NamedTemporaryFile(suffix=\".grib2\") as f:\n    # Decompress the .gz content and write to temp file\n    f.write(gzip.decompress(compressed_file))\n\n    # Load GRIB2 data as an xarray DataArray\n    data_in = xr.load_dataarray(f.name, engine='cfgrib', decode_timedelta=True)\n\n\n\n","type":"content","url":"/notebooks/ch3-txfloods#access-and-load-mrms-data","position":15},{"hierarchy":{"lvl1":"Chapter 3: July 2025 Central TX Floods","lvl2":"Set Up Reflectivity Colormap and Extract Data"},"type":"lvl2","url":"/notebooks/ch3-txfloods#set-up-reflectivity-colormap-and-extract-data","position":16},{"hierarchy":{"lvl1":"Chapter 3: July 2025 Central TX Floods","lvl2":"Set Up Reflectivity Colormap and Extract Data"},"content":"This section gets the MRMS reflectivity data ready for plotting and builds a map to visualize it.\n\nColormap and Normalization:We use MetPy’s built-in NWSReflectivity colormap, which is designed for radar data in dBZ. The get_with_steps() function sets up color breaks every 5 dBZ — a common setup in operational radar displays.\n\nExtract Coordinates and Data:We pull out the longitude, latitude, and reflectivity values from the data array. If the coordinates are in 1D (which happens in some MRMS products), we convert them to 2D using np.meshgrid() so they work with the plotting function.\n\nMask Low Reflectivity Values:Reflectivity values below 5 dBZ are masked out with ma.masked_where() to remove light noise and clutter from the map.\n\nSet Up the Map:We create a static figure using matplotlib and Cartopy, with a PlateCarree projection centered over Texas. The domain is narrowed with set_extent() to focus on the region of interest.\n\nAdd Map Features:Coastlines, country borders, and U.S. state lines are added to give the plot geographic context.\n\nPlot the Reflectivity:The reflectivity field is plotted using pcolormesh() with our defined colormap and normalization. A horizontal colorbar is added to show the dBZ scale.\n\nFinal Touches:We include a plot title and display the final figure with \n\nplt.show().\n\nrefl_norm, refl_cmap = ctables.registry.get_with_steps('NWSReflectivity', 5, 5)\n\n# 2. Extract coords & data\nlons = data_in.longitude.values\nlats = data_in.latitude.values\nrefl = data_in.values\n\n# If coords are 1D, make them 2D\nif lons.ndim == 1 and lats.ndim == 1:\n    lons, lats = np.meshgrid(lons, lats)\n\n# 3. Plot\nfig = plt.figure(figsize=(10, 8))\nax = plt.axes(projection=ccrs.PlateCarree())\nax.set_extent([-106, -93, 25, 36], crs=ccrs.PlateCarree())\n\nax.add_feature(cfeature.COASTLINE, linewidth=1)\nax.add_feature(cfeature.BORDERS, linewidth=1)\nax.add_feature(cfeature.STATES, linewidth=0.5)\n\nmesh = ax.pcolormesh(\n    lons, lats, ma.masked_where(refl<5,refl),\n    cmap=refl_cmap,\n    norm=refl_norm,\n    transform=ccrs.PlateCarree()\n)\n\ncb = plt.colorbar(mesh, ax=ax, orientation='horizontal', pad=0.05, aspect=50)\ncb.set_label('Reflectivity (dBZ)')\n\nplt.title('MRMS Layer Composite Reflectivity – Texas', fontsize=14)\nplt.show()\n\n\n","type":"content","url":"/notebooks/ch3-txfloods#set-up-reflectivity-colormap-and-extract-data","position":17},{"hierarchy":{"lvl1":"Chapter 3: July 2025 Central TX Floods","lvl3":"Select Timestamps and Animate Reflectivity","lvl2":"Set Up Reflectivity Colormap and Extract Data"},"type":"lvl3","url":"/notebooks/ch3-txfloods#select-timestamps-and-animate-reflectivity","position":18},{"hierarchy":{"lvl1":"Chapter 3: July 2025 Central TX Floods","lvl3":"Select Timestamps and Animate Reflectivity","lvl2":"Set Up Reflectivity Colormap and Extract Data"},"content":"This part of the notebook automates the process of pulling in multiple MRMS reflectivity files and creating an animation to show how low-level reflectivity changed over time.\n\nCheck for Available Timestamps:We define a time range from July 4 to July 7, 2025, and loop through it in 30-minute steps. For each time, we generate a file path from the AWS-hosted MRMS archive and try downloading it. If the file exists, we save that timestamp. For this demo, we stop after grabbing six valid files.\n\nSet Up the Map and Colormap:After collecting the timestamps, we build a static map using Cartopy (Plate Carree projection), focused on Texas and surrounding areas. We also apply the MetPy NWSReflectivity colormap and mask out any reflectivity values below 5 dBZ to clean up the visualization.\n\nDownload and Plot Each Frame:For each timestamp:\n\nThe corresponding .grib2.gz file is downloaded and decompressed.\n\nWe extract the reflectivity data and coordinates using xarray.\n\nIf the coordinate arrays are 1D, we convert them to 2D for plotting.\n\nThe reflectivity data is plotted with pcolormesh(), and we add a dynamic title showing the UTC time.\n\nEach frame (plot + title) is saved for the animation.\n\nBuild the Animation:We use ArtistAnimation from Matplotlib to stitch the frames together into an animation. plt.close(fig) is used beforehand to prevent Jupyter from displaying a static image under the animation.\n\nExport as a GIF:The finished animation is saved as a .gif using Pillow so it can be easily shared or embedded in a presentation.\n\nThe result is a short radar loop showing how reflectivity evolved during the early hours of July 4, 2025, which is a period tied to widespread heavy rain and flash flooding across Central Texas.\n\nstart = datetime(2025, 7, 4, 0, 10, 40)\nend = datetime(2025, 7, 7, 0, 0, 0)\nstep = timedelta(minutes=30)\n\nvalid_timestamps = []\nt = start\n\nprint(\"Checking for available MRMS files...\\n\")\n\nwhile t <= end and len(valid_timestamps) < 6:\n    ts = t.strftime(\"%Y%m%d-%H%M%S\")\n    date_str = ts[:8]\n    url = (\n        f\"https://noaa-mrms-pds.s3.amazonaws.com/CONUS/LayerCompositeReflectivity_Low_00.50/\"\n        f\"{date_str}/MRMS_LayerCompositeReflectivity_Low_00.50_{ts}.grib2.gz\"\n    )\n    try:\n        resp = urllib.request.urlopen(url, timeout=5)\n        print(f\" Found: {ts}\")\n        valid_timestamps.append(ts)\n    except:\n        print(f\" Missing: {ts}\")\n    t += step\n\nprint(\"\\n Selected 6 timestamps:\")\nfor ts in valid_timestamps:\n    print(ts)\n\n\n# Define the 6 known working timestamps (one every hour)\ntimestamps = [\n    \"20250704-001040\",\n    \"20250704-011040\",\n    \"20250704-031040\",\n    \"20250704-054040\",\n    \"20250704-071040\",\n    \"20250704-091040\"\n]\n\n# Set up colormap and normalization for reflectivity\nrefl_norm, refl_cmap = ctables.registry.get_with_steps('NWSReflectivity', 5, 5)\n\n# Initialize animation container\nframes_six = []\n\n# Set up static map\nfig = plt.figure(figsize=(10, 8))\nax = plt.axes(projection=ccrs.PlateCarree())\nax.set_extent([-106, -93, 25, 36], crs=ccrs.PlateCarree())\nax.add_feature(cfeature.COASTLINE, linewidth=1)\nax.add_feature(cfeature.BORDERS, linewidth=1)\nax.add_feature(cfeature.STATES, linewidth=0.5)\n\n# Loop through timestamps and collect frames\nfor ts in timestamps:\n    print(f\"Loading {ts}...\")\n    try:\n        url = (\n            f\"https://noaa-mrms-pds.s3.amazonaws.com/CONUS/LayerCompositeReflectivity_Low_00.50/\"\n            f\"{ts[:8]}/MRMS_LayerCompositeReflectivity_Low_00.50_{ts}.grib2.gz\"\n        )\n        response = urllib.request.urlopen(url)\n        compressed_file = response.read()\n\n        with tempfile.NamedTemporaryFile(suffix=\".grib2\") as f:\n            f.write(gzip.decompress(compressed_file))\n            f.flush()\n            data_in = xr.load_dataarray(f.name, engine='cfgrib', decode_timedelta=True)\n\n        # Extract coordinates and reflectivity data\n        lons = data_in.longitude.values\n        lats = data_in.latitude.values\n        refl = data_in.values\n\n        if lons.ndim == 1 and lats.ndim == 1:\n            lons, lats = np.meshgrid(lons, lats)\n\n        # Plot single frame (no show)\n        mesh = ax.pcolormesh(\n            lons, lats, ma.masked_where(refl < 5, refl),\n            cmap=refl_cmap,\n            norm=refl_norm,\n            transform=ccrs.PlateCarree()\n        )\n\n        # Create a title text that updates with each frame\n        timestamp_label = f\"{ts[:4]}-{ts[4:6]}-{ts[6:8]} {ts[9:11]}:{ts[11:13]} UTC\"\n        title = ax.text(\n            0.5, 1.02,\n            f\"MRMS Low-Level Reflectivity (dBZ) – {timestamp_label}\",\n            transform=ax.transAxes,\n            ha=\"center\", va=\"bottom\", fontsize=14\n        )\n\n        # Save both mesh and title to animation frame\n        frames_six.append([mesh, title])\n\n    except Exception as e:\n        print(f\"Skipped {ts} → {e}\")\n        continue\n\n# Create and display an animation\nplt.close(fig)\nanim = ArtistAnimation(fig, frames_six, interval=500, blit=True)\nHTML(anim.to_jshtml())\n\n# Save animation as a .gif\nanim.save(\"mrms_reflectivity_animation.gif\", writer=PillowWriter(fps=2))\n\nprint(\"Animation saved as 'mrms_reflectivity_animation.gif'\")\n\n\n","type":"content","url":"/notebooks/ch3-txfloods#select-timestamps-and-animate-reflectivity","position":19},{"hierarchy":{"lvl1":"Chapter 3: July 2025 Central TX Floods","lvl2":"Reflectivity Animation: Summary"},"type":"lvl2","url":"/notebooks/ch3-txfloods#reflectivity-animation-summary","position":20},{"hierarchy":{"lvl1":"Chapter 3: July 2025 Central TX Floods","lvl2":"Reflectivity Animation: Summary"},"content":"We demonstrated how to access and animate low-level composite reflectivity data from the MRMS system using open-source Python tools. We focused on a short sequence from the July 4, 2025, Central Texas flood event to highlight how reflectivity features evolved.\n\nThis workflow is a flexible starting point for working with radar data, especially for case studies or quick visual diagnostics. The next section will continue building on this analysis with more approaches to explore the MRMS dataset!\n\n","type":"content","url":"/notebooks/ch3-txfloods#reflectivity-animation-summary","position":21},{"hierarchy":{"lvl1":"Chapter 3: July 2025 Central TX Floods","lvl2":"Comparison with ASOS Data"},"type":"lvl2","url":"/notebooks/ch3-txfloods#comparison-with-asos-data","position":22},{"hierarchy":{"lvl1":"Chapter 3: July 2025 Central TX Floods","lvl2":"Comparison with ASOS Data"},"content":"\n\n\naws = s3fs.S3FileSystem(anon=True)\npath = aws.ls(\"noaa-mrms-pds/CONUS/RadarOnly_QPE_24H_00.00/20250705/\")[0]\n\nresponse = urllib.request.urlopen(\"https://noaa-mrms-pds.s3.amazonaws.com/\" + path[14:])\ncompressed_file = response.read()\n\nwith tempfile.NamedTemporaryFile(suffix=\".grib2\") as f:\n            f.write(gzip.decompress(compressed_file))\n            f.flush()\n            data = xr.load_dataarray(f.name, engine='cfgrib', decode_timedelta=True)\n\n# Set lat and lon bounds\nlat_min, lat_max = 28, 33\nlon_min, lon_max = -102.5, -96.5\n\n# Subset data and delete original\nsubset = data.sel(\n    latitude=slice(lat_max, lat_min),\n    longitude=slice(360 - abs(lon_min), 360 - abs(lon_max)),\n).copy(deep=True)\n\n# Remove original data to free memory\ndel data\n\nurl = \"https://mesonet.agron.iastate.edu/cgi-bin/request/asos.py\"\n\nparams = {\n    \"network\": \"TX_ASOS\",  # Or just use \"ASOS\" for all U.S.\n    \"data\": \"p01i\",\n    \"year1\": \"2025\",\n    \"month1\": \"7\",\n    \"day1\": \"4\",\n    \"year2\": \"2025\",\n    \"month2\": \"7\",\n    \"day2\": \"4\",\n    \"format\": \"comma\",\n    \"latlon\": \"yes\",\n}\n\n# Make the request\nresponse = requests.get(url, params=params)\n\n# Parse CSV from response text\ndf = pd.read_csv(StringIO(response.text), skiprows=5)\n\n# Drop missing precip values\ndf = df[df[\"p01i\"] != \"M\"]\ndf[\"p01i\"] = df[\"p01i\"].astype(float)\n\n# Convert timestamp to datetime\ndf[\"valid\"] = pd.to_datetime(df[\"valid\"])\n\n# Group by station and sum hourly precip\ndaily_precip = (\n    df.groupby([\"station\", \"lon\", \"lat\"])[\"p01i\"]\n    .sum()\n    .reset_index()\n    .rename(columns={\"p01i\": \"precip_in\"})\n)\n\ndaily_precip\n\n# Set levels\nlevels = [\n    0,\n    0.01,\n    0.1,\n    0.25,\n    0.50,\n    1,\n    1.5,\n    2,\n    2.5,\n    3,\n    4,\n    5,\n    6,\n    7,\n    8,\n    9,\n    10,\n    12,\n    14,\n    16,\n    18,\n]\n\n# Create a normalization object\ncmap = plt.get_cmap(\"ChaseSpectral\")  # Use full-resolution colormap\nnorm = mcolors.BoundaryNorm(levels, ncolors=cmap.N, clip=False)\n\nfig = plt.figure(figsize=(10, 8))\nax = plt.axes(projection=ccrs.PlateCarree())\nax.set_extent([lon_min, lon_max, lat_min, lat_max], crs=ccrs.PlateCarree())\n\nax.add_feature(cfeature.COASTLINE, linewidth=1, edgecolor=\"white\")\nax.add_feature(cfeature.BORDERS, linewidth=1, edgecolor=\"white\")\nax.add_feature(cfeature.STATES, linewidth=0.5, edgecolor=\"white\")\n# Add counties\nax.add_feature(\n    cfeature.NaturalEarthFeature(\n        category=\"cultural\",\n        name=\"admin_2_counties\",\n        scale=\"10m\",\n        facecolor=\"none\",\n        edgecolor=\"white\",\n        linewidth=0.3,\n    )\n)\n\nmesh = ax.pcolormesh(\n    subset.longitude,\n    subset.latitude,\n    subset / 25.4,  # Convert mm to inches\n    norm=norm,\n    cmap=\"ChaseSpectral\",\n    transform=ccrs.PlateCarree(),\n)\n\n# Overlay ASOS bubble plot\nsc = ax.scatter(\n    daily_precip[\"lon\"],\n    daily_precip[\"lat\"],\n    s=daily_precip[\"precip_in\"] * 40,  # adjust bubble size scaling\n    c=daily_precip[\"precip_in\"],\n    cmap=cmap,\n    norm=norm,\n    alpha=0.9,\n    edgecolor=\"black\",\n    linewidth=0.4,\n    transform=ccrs.PlateCarree(),\n    zorder=10\n)\n\nfor size in [0.1, 0.5, 1.0, 2.0, 4.0]:\n    ax.scatter([], [], s=size * 40, c='gray', alpha=0.6, edgecolor='black', label=f\"{size:.1f}\\\"\")\n\nax.legend(scatterpoints=1, loc=\"lower right\", title=\"ASOS Daily Rain\", frameon=True)\n\n\ncb = plt.colorbar(\n    mesh, ax=ax, orientation=\"horizontal\", pad=0.05, aspect=50, shrink=0.8\n)\ncb.set_label(\"Rainfall (in)\")\n# Add tick labels to colorbar\ncb.set_ticks(levels)\ncb.set_ticklabels([f\"{level:.2f}\" for level in levels])\ncb.ax.tick_params(labelsize=10, rotation=45)\n\nplt.title(\"MRMS 24-Hour Radar Only QPE vs. ASOS Stations (July 4, 2025)\", fontsize=16)\nplt.tight_layout()\n\n# Convert lat/lon coordinates from MRMS subset\nlats = subset.latitude.values\nlons = subset.longitude.values\n\n# Ensure correct orientation (ascending order for interpolator)\nif lats[0] > lats[-1]:\n    lats = lats[::-1]\n    subset = subset[::-1, :]\n\n# Create interpolator (convert to inches)\ninterp_func = RegularGridInterpolator(\n    (lats, lons), (subset / 25.4).values, bounds_error=False, fill_value=np.nan\n)\n\n# Convert ASOS longitude from degrees west to degrees east (0–360)\ndaily_precip[\"lon_east\"] = daily_precip[\"lon\"].apply(lambda x: x if x >= 0 else 360 + x)\n\nstation_coords = list(zip(daily_precip[\"lat\"], daily_precip[\"lon_east\"]))\ndaily_precip[\"mrms_in\"] = interp_func(station_coords)\n\n\ndaily_precip[\"bias\"] = daily_precip[\"precip_in\"] - daily_precip[\"mrms_in\"]\n\n\n# Compute bias normalization\nvmax = np.nanmax(np.abs(daily_precip[\"bias\"]))\n\n# Define bias levels (nonlinear, symmetric)\nbias_levels = [-20, -10, -5, -2, -1, -0.5, -0.1, 0, 0.1, 0.5, 1, 2, 5, 10, 20]\n\n# Create BoundaryNorm\nnorm_bias = mcolors.BoundaryNorm(bias_levels, ncolors=plt.get_cmap(\"balance\").N, clip=True)\n\n\n# Compute scatter sizes based on bias magnitude (optional scaling factor)\nsizes = np.sqrt(np.abs(daily_precip[\"bias\"])) * 150  # tweak 100 as needed\n\n# Create figure and axis\nfig = plt.figure(figsize=(10, 8))\nax = plt.axes(projection=ccrs.PlateCarree())\nax.set_extent([lon_min, lon_max, lat_min, lat_max], crs=ccrs.PlateCarree())\n\n# Basemap features\nax.add_feature(cfeature.COASTLINE, linewidth=1, edgecolor=\"white\")\nax.add_feature(cfeature.BORDERS, linewidth=1, edgecolor=\"white\")\nax.add_feature(cfeature.STATES, linewidth=0.5, edgecolor=\"white\")\nax.add_feature(\n    cfeature.NaturalEarthFeature(\n        category=\"cultural\",\n        name=\"admin_2_counties\",\n        scale=\"10m\",\n        facecolor=\"none\",\n        edgecolor=\"white\",\n        linewidth=0.3,\n    )\n)\n\n# Pcolormesh for MRMS\nmesh = ax.pcolormesh(\n    subset.longitude,\n    subset.latitude,\n    subset / 25.4,  # Convert mm to inches\n    norm=norm,\n    cmap=\"ChaseSpectral\",\n    transform=ccrs.PlateCarree(),\n)\n\nsc = ax.scatter(\n    daily_precip[\"lon\"],\n    daily_precip[\"lat\"],\n    c=daily_precip[\"bias\"],\n    s=sizes,\n    cmap=\"balance\",  # cmocean or any diverging colormap\n    norm=norm_bias,\n    edgecolor=\"black\",\n    linewidth=0.4,\n    transform=ccrs.PlateCarree(),\n    zorder=10,\n)\n\n# Add text labels for each station's bias\nfor _, row in daily_precip.iterrows():\n    bias_val = row[\"bias\"]\n    if not np.isnan(bias_val):\n        ax.text(\n            row[\"lon\"], row[\"lat\"],\n            f\"{bias_val:.2f}\\\"\",\n            fontsize=6,\n            ha=\"center\", va=\"center\",\n            transform=ccrs.PlateCarree(),\n            zorder=11,\n            color=\"white\" if abs(bias_val) > 0.5 else \"black\",  # adjust for contrast\n        )\n\n\n\n# Bias colorbar (scatter)\ncb1 = plt.colorbar(sc, ax=ax, orientation=\"horizontal\", pad=0.05, shrink=0.8, aspect=50)\ncb1.set_label(\"ASOS - MRMS Bias (in)\")\ncb1.set_ticks(bias_levels)\ncb1.ax.tick_params(labelsize=10)\n\n\n\n# Add second colorbar (MRMS QPE from pcolormesh)\ncb2 = plt.colorbar(mesh, ax=ax, orientation=\"vertical\", pad=0.02, shrink=0.8)\ncb2.set_label(\"MRMS QPE (in)\")\ncb2.ax.tick_params(labelsize=10)\n\n# Title and layout\nax.set_title(\"ASOS vs. MRMS Radar-Only QPE Bias (July 4, 2025)\", fontsize=16)\nplt.tight_layout()\n\n\n","type":"content","url":"/notebooks/ch3-txfloods#comparison-with-asos-data","position":23},{"hierarchy":{"lvl1":"Chapter 3: July 2025 Central TX Floods","lvl2":"Compare MRMS Radar-Only to Pass 1 and Pass 2 QPE"},"type":"lvl2","url":"/notebooks/ch3-txfloods#compare-mrms-radar-only-to-pass-1-and-pass-2-qpe","position":24},{"hierarchy":{"lvl1":"Chapter 3: July 2025 Central TX Floods","lvl2":"Compare MRMS Radar-Only to Pass 1 and Pass 2 QPE"},"content":"\n\ndef load_mrms_qpe_24h(date_str, product=\"RadarOnly_QPE_24H_00.00\",\n                      lat_bounds=(28, 33), lon_bounds=(-102.5, -96.5)):\n    \"\"\"\n    Loads and subsets MRMS 24-hour radar-only QPE data from AWS.\n\n    Parameters:\n    ----------\n    date_str : str\n        Date in 'YYYYMMDD' format (e.g., '20250705')\n    product : str\n        MRMS product folder (default: 'RadarOnly_QPE_24H_00.00' for Pass1)\n    lat_bounds : tuple\n        Tuple of (lat_min, lat_max)\n    lon_bounds : tuple\n        Tuple of (lon_min, lon_max) in degrees west\n\n    Returns:\n    -------\n    subset : xarray.DataArray\n        Subset of MRMS QPE field for given domain and date\n    \"\"\"\n\n    # Access file listing on AWS\n    aws = s3fs.S3FileSystem(anon=True)\n    mrms_path = f\"noaa-mrms-pds/CONUS/{product}/{date_str}/\"\n    file_list = aws.ls(mrms_path)\n\n    # Only grab the first GRIB2 file for the day (should end in 0000.grib2.gz)\n    grib_path = next((f for f in file_list if f.endswith(\".grib2.gz\")), None)\n    if grib_path is None:\n        raise FileNotFoundError(f\"No GRIB2 file found for {date_str} in {product}\")\n\n    url = \"https://noaa-mrms-pds.s3.amazonaws.com/\" + grib_path[len(\"noaa-mrms-pds/\"):]\n    response = urllib.request.urlopen(url)\n    compressed_file = response.read()\n\n    with tempfile.NamedTemporaryFile(suffix=\".grib2\") as f:\n        f.write(gzip.decompress(compressed_file))\n        f.flush()\n        data = xr.load_dataarray(f.name, engine='cfgrib', decode_timedelta=True)\n\n    # Subset domain\n    lat_min, lat_max = lat_bounds\n    lon_min, lon_max = lon_bounds\n    subset = data.sel(\n        latitude=slice(lat_max, lat_min),\n        longitude=slice(360 - abs(lon_min), 360 - abs(lon_max)),\n    ).copy(deep=True)\n\n    # Clean up\n    del data\n\n    return subset\n\nsubset_pass1 = load_mrms_qpe_24h(\"20250705\", product=\"MultiSensor_QPE_24H_Pass1_00.00\")\nsubset_pass2 = load_mrms_qpe_24h(\"20250705\", product=\"MultiSensor_QPE_24H_Pass2_00.00\")\n\n# Define levels and normalization\nlevels = [\n    0, 0.01, 0.1, 0.25, 0.50, 1, 1.5, 2, 2.5,\n    3, 4, 5, 6, 7, 8, 9, 10, 12, 14, 16, 18\n]\ncmap = plt.get_cmap(\"ChaseSpectral\")\nnorm = mcolors.BoundaryNorm(levels, ncolors=cmap.N, clip=False)\n\n# Create figure and subplots\nfig, axes = plt.subplots(\n    1, 3, figsize=(15, 6),\n    subplot_kw={\"projection\": ccrs.PlateCarree()}\n)\n\n# Title mapping\ntitles = [\n    \"Radar-Only QPE\",\n    \"Gauge-Corrected QPE (Pass 1)\",\n    \"Gauge-Corrected QPE (Pass 2)\"\n]\n\n# Loop through datasets and plot\nfor ax, data, title in zip(\n    axes,\n    [subset, subset_pass1, subset_pass2],\n    titles\n):\n    ax.set_extent([lon_min, lon_max, lat_min, lat_max], crs=ccrs.PlateCarree())\n\n    # Basemap features\n    ax.add_feature(cfeature.COASTLINE, linewidth=1, edgecolor=\"white\")\n    ax.add_feature(cfeature.BORDERS, linewidth=1, edgecolor=\"white\")\n    ax.add_feature(cfeature.STATES, linewidth=0.5, edgecolor=\"white\")\n    ax.add_feature(\n        cfeature.NaturalEarthFeature(\n            category=\"cultural\",\n            name=\"admin_2_counties\",\n            scale=\"10m\",\n            facecolor=\"none\",\n            edgecolor=\"white\",\n            linewidth=0.3,\n        )\n    )\n\n    # Pcolormesh plot\n    mesh = ax.pcolormesh(\n        data.longitude,\n        data.latitude,\n        data / 25.4,  # mm to inches\n        norm=norm,\n        cmap=cmap,\n        transform=ccrs.PlateCarree(),\n    )\n\n    ax.set_title(title, fontsize=13)\n\n# Shared colorbar below all plots\ncb = fig.colorbar(\n    mesh, ax=axes, orientation=\"horizontal\", pad=0.08, aspect=50, shrink=0.8\n)\ncb.set_label(\"24-Hour Rainfall (in)\", fontsize=12)\ncb.set_ticks(levels)\ncb.set_ticklabels([f\"{level:.2f}\" for level in levels])\ncb.ax.tick_params(labelsize=10, rotation=45)\n\nplt.suptitle(\"MRMS 24-Hour QPE Products (July 4, 2025)\", fontsize=16)\nplt.tight_layout(rect=[0, 0.25, 1, 0.98])  # leave space for suptitle and colorbar\nplt.show()\n\n\n# Compute differences in inches\nbias_pass1 = (subset_pass1 - subset) / 25.4\nbias_pass2 = (subset_pass2 - subset) / 25.4\n\n# Define nonlinear boundaries for bias (symmetric)\nbias_levels = [-16, -10, -5, -2, -1, -0.5, -0.1, 0, 0.1, 0.5, 1, 2, 5, 10, 16]\nnorm_bias = mcolors.BoundaryNorm(bias_levels, ncolors=plt.get_cmap(\"balance\").N, clip=True)\n\n# Create figure and subplots\nfig, axes = plt.subplots(\n    1, 2, figsize=(12, 6), constrained_layout=True,\n    subplot_kw={\"projection\": ccrs.PlateCarree()}\n)\n\n# Titles\ntitles = [\n    \"Pass 1 – Radar-Only Bias (in)\",\n    \"Pass 2 – Radar-Only Bias (in)\"\n]\n\n# Loop through plots\nfor ax, bias_data, title in zip(\n    axes,\n    [bias_pass1, bias_pass2],\n    titles\n):\n    ax.set_extent([lon_min, lon_max, lat_min, lat_max], crs=ccrs.PlateCarree())\n\n    # Basemap features\n    ax.add_feature(cfeature.COASTLINE, linewidth=1, edgecolor=\"white\")\n    ax.add_feature(cfeature.BORDERS, linewidth=1, edgecolor=\"white\")\n    ax.add_feature(cfeature.STATES, linewidth=0.5, edgecolor=\"white\")\n    ax.add_feature(\n        cfeature.NaturalEarthFeature(\n            category=\"cultural\",\n            name=\"admin_2_counties\",\n            scale=\"10m\",\n            facecolor=\"none\",\n            edgecolor=\"white\",\n            linewidth=0.3,\n        )\n    )\n\n    # Pcolormesh\n    mesh = ax.pcolormesh(\n        bias_data.longitude,\n        bias_data.latitude,\n        bias_data,\n        cmap=\"balance\",  # diverging colormap\n        norm=norm_bias,\n        transform=ccrs.PlateCarree(),\n    )\n\n    ax.set_title(title, fontsize=13)\n\n# Shared colorbar\ncb = fig.colorbar(\n    mesh, ax=axes, orientation=\"horizontal\", pad=0.08, aspect=50, shrink=0.8\n)\ncb.set_label(\"Gauge-Corrected Bias from Radar-Only QPE (in)\", fontsize=12)\ncb.set_ticks(bias_levels)\ncb.ax.tick_params(labelsize=10, rotation=45)\n\n# Suptitle and layout\nplt.suptitle(\"MRMS 24-Hour Gauge Correction Bias (July 4, 2025)\", fontsize=16)\nplt.show()\n","type":"content","url":"/notebooks/ch3-txfloods#compare-mrms-radar-only-to-pass-1-and-pass-2-qpe","position":25},{"hierarchy":{"lvl1":"Chapter 5: Real-time MRMS Visualization"},"type":"lvl1","url":"/notebooks/ch4-realtimedata","position":0},{"hierarchy":{"lvl1":"Chapter 5: Real-time MRMS Visualization"},"content":"\n\nWelcome to the Real-time MRMS Visualization notebook! In this workflow, you will receive a quick briefing on the Multi-Radar/Multi-Sensor System (MRMS) content covered in \n\nChapter 1, learn about data access from Amazom Web Services (AWS), make a selection of MRMS data to request from AWS, and visualize the latest radar data in an interactive plot.\n\nIntent: This Project Pythia notebook allows a user to gain familiarity with the process of requesting real-time MRMS data from AWS S3 and provides the opportunity for further learning.Audience: Anyone with at least 5GB of memory on their computer or computing environment and a fundamental knowledge of MRMS.   No programming experience is required to go run this notebook, but it will help you understand where this data is coming from.Outcome: An interactive plot showing MRMS imagery from a selected region and radar product.Time to Learn: 15 minutes to run the notebook and read the documentation; 30 minutes to become familiar enough with the material to replicate these methods.\n\n","type":"content","url":"/notebooks/ch4-realtimedata","position":1},{"hierarchy":{"lvl1":"Chapter 5: Real-time MRMS Visualization","lvl2":"Overview"},"type":"lvl2","url":"/notebooks/ch4-realtimedata#overview","position":2},{"hierarchy":{"lvl1":"Chapter 5: Real-time MRMS Visualization","lvl2":"Overview"},"content":"Import required packages\n\nLearn about MRMS\n\nExplore near real-time MRMS data hosted on AWS\n\nSelect a region and product for viewing\n\nAccess selected MRMS data from AWS\n\nVisualize a selected variable using an interactive plot\n\n\n\n","type":"content","url":"/notebooks/ch4-realtimedata#overview","position":3},{"hierarchy":{"lvl1":"Chapter 5: Real-time MRMS Visualization","lvl2":"Imports"},"type":"lvl2","url":"/notebooks/ch4-realtimedata#imports","position":4},{"hierarchy":{"lvl1":"Chapter 5: Real-time MRMS Visualization","lvl2":"Imports"},"content":"\n\nHere are all required Python packages to run this code.\n\n# Packages required to request and open data from AWS S3\nimport s3fs\nimport urllib\nimport tempfile\nimport gzip\nimport xarray as xr\n\n# Packages required for data visualization\nimport datetime\nfrom datetime import timezone\nimport numpy.ma as ma\nfrom metpy.plots import ctables\nimport numpy as np\nimport holoviews as hv\nimport pandas as pd\nimport panel as pn\nimport hvplot.xarray \nimport matplotlib.colors as mcls\nfrom matplotlib.colors import Normalize\n#pn.extension(\"bokeh\")\nhv.extension('bokeh')\n\n\n\n","type":"content","url":"/notebooks/ch4-realtimedata#imports","position":5},{"hierarchy":{"lvl1":"Chapter 5: Real-time MRMS Visualization","lvl2":"About MRMS"},"type":"lvl2","url":"/notebooks/ch4-realtimedata#about-mrms","position":6},{"hierarchy":{"lvl1":"Chapter 5: Real-time MRMS Visualization","lvl2":"About MRMS"},"content":"\n\nimage\n\nThe Multi-Radar/Multi-Sensor System (MRMS) produces products for public infrastructure, weather forecasts and warnings, aviation, and numerical weather prediction. It provides high spatial (1-km) and temporal (2-min) resolution radar products at 31 vertical levels, and ingests data from numerous sources (including radar networks across the US and Canada, surface and upper air observations, lightning detection systems, satellite observations, and forecast models)\n\n1\n\nFor more information, please refer to Chapter 1 of this project: \n\nLearning about MRMS.\n\n\n\n","type":"content","url":"/notebooks/ch4-realtimedata#about-mrms","position":7},{"hierarchy":{"lvl1":"Chapter 5: Real-time MRMS Visualization","lvl2":"About AWS and NODD"},"type":"lvl2","url":"/notebooks/ch4-realtimedata#about-aws-and-nodd","position":8},{"hierarchy":{"lvl1":"Chapter 5: Real-time MRMS Visualization","lvl2":"About AWS and NODD"},"content":"\n\nlogo images\n\nThe Amazon Web Services Simple Storage Service (AWS S3) is cloud-based object storage service. Through a public-private partnership with the National Oceanic and Atmospheric Administration (NOAA)'s Open Data Dissemination Program (NODD), NOAA is able to store multiple petabytes of open-access earth science data on AWS S3, including the MRMS dataset. This allows users to quickly and freely access MRMS data in real-time (with an update frequency of two minutes) without having to download the data to their personal systems.\n\nBecause of this partnership, we can access the data as an anonymous client -- no login required!\n\n# Initialize the S3 filesystem as anonymous\naws = s3fs.S3FileSystem(anon=True)\n\nYou can explore the S3 bucket that holds MRMS data to assess data availability and structure -- just visit \n\nthis link, which takes you to the MRMS bucket.\n\n# Here's a hint -- you can run aws.ls to see the file structure in code. Try it yourself!\naws.ls(f'noaa-mrms-pds/CONUS/', refresh=True)[0:5]\n\n\n\n","type":"content","url":"/notebooks/ch4-realtimedata#about-aws-and-nodd","position":9},{"hierarchy":{"lvl1":"Chapter 5: Real-time MRMS Visualization","lvl2":"Data selection"},"type":"lvl2","url":"/notebooks/ch4-realtimedata#data-selection","position":10},{"hierarchy":{"lvl1":"Chapter 5: Real-time MRMS Visualization","lvl2":"Data selection"},"content":"For ease of use, I’ve integrated ipywidgets (drop-down menus!) that allow you to make selections from AWS, and refined a selection of data variables as a demonstration. You can choose between the QC’d Merged Reflectivity Composite (the maximum reflectivity in a column, as a composite), a 12-hour multisensor QPE from Pass 1 (12h rainfall accumulation estimate, using data from multiple sensors), and the Probability of Severe Hail (probability of 0.75-inch diameter hail).\n\nNow, you have the option to select a region and a radar product to visualize in near real-time. Go ahead and use the drop-down menus to select a region, a radar product, then run the next cell. If you run the drop-down cell again, it will reset your values.\n\n# Define dropdown options\nregion_options = [\"CONUS\", \"ALASKA\", \"CARIB\", \"GUAM\", \"HAWAII\"]\nproduct_options = [\n    \"MergedReflectivityQCComposite_00.50\",\n    \"MultiSensor_QPE_12H_Pass1_00.00\",\n    \"POSH_00.50\"\n]\n\n# Create the dropdowns with similar layout/formatting\nregion_choice = pn.widgets.Select(name='Region', options=region_options, width=325)\nproduct_choice = pn.widgets.Select(name='MRMS product', options=product_options, width=325)\n\n# Display the widgets together in a vertical layout (Column)\npn.Column(region_choice, product_choice)\n\nCongratulations, you’ve made your data selection!\n\nIf you choose to adapt this notebook to your own workflow, this section can easily be adjusted to your own use case. Simply delete the cell above, then update the cell below to reflect the region and data variable you wish to use. If you decide to use a product that is not covered in this notebook, you can search through \n\nall available data products on AWS and paste it in verbatim. It may be helpful to cross-reference these variables against the \n\nNSSL variable table and\n\n\nChapter 1.\n\n# Retrieve the user selection from 'region' \nregion = region_choice.value\n\n# Retrieve the user selection from 'MRMS product'\nproduct = product_choice.value\n\nprint(region, product)\n\n\n\n","type":"content","url":"/notebooks/ch4-realtimedata#data-selection","position":11},{"hierarchy":{"lvl1":"Chapter 5: Real-time MRMS Visualization","lvl2":"Data request"},"type":"lvl2","url":"/notebooks/ch4-realtimedata#data-request","position":12},{"hierarchy":{"lvl1":"Chapter 5: Real-time MRMS Visualization","lvl2":"Data request"},"content":"Now that you’ve made your variable selection, it’s time to read in the data from AWS. First, we retrieve the current UTC datetime so that we can request files from today’s S3 bucket.\n\n# Retrieve the current datetime in UTC to know which bucket to query\nnow = datetime.datetime.now(datetime.UTC)\ndatestring = now.strftime('%Y%m%d')\n\nNext, we query the S3 bucket to make sure the data is available on AWS. If this section errors, reference \n\nthe S3 bucket to confirm that your requested region, date, and product exists and is entered correctly.\n\n# Query the S3 bucket for the available files that meet the criteria\ntry:\n    data_files = aws.ls(f'noaa-mrms-pds/{region}/{product}/{datestring}/', refresh=True)  \nexcept Exception as e:\n    print(f\"Error accessing S3 bucket: {e}\")\n    data_files = []\n\nFinally, we make the data request and read it in using xarray. This block of code finds the most recent file that fits your criteria, ensures that the file was created recently (within two hours), then makes the data request. Due to way the data was uploaded to S3, the file arrives as a compressed grib2 file. This code decompresses the file and reads it in using xarray, making the format more easily incorporated into our workflow.\n\nif data_files:\n    # Choose the last file from S3 for the most recent data\n    most_recent_file = data_files[-1]\n\n    # Check that the most recent file is within 2 hours of current time\n    timestamp_str = most_recent_file.split('_')[-1].replace('.grib2.gz', '')\n    dt = datetime.datetime.strptime(timestamp_str, \"%Y%m%d-%H%M%S\").replace(tzinfo=timezone.utc)\n    if abs((now - dt).total_seconds()) <= 120 * 60:\n        # Download file to memory, decompress from .gz, and read into xarray\n        try:\n            response = urllib.request.urlopen(f\"https://noaa-mrms-pds.s3.amazonaws.com/{most_recent_file[14:]}\")\n            compressed_file = response.read()\n\n            with tempfile.NamedTemporaryFile(suffix=\".grib2\") as f:\n                f.write(gzip.decompress(compressed_file))\n                f.flush()\n                data = xr.load_dataarray(f.name, engine=\"cfgrib\", decode_timedelta=True)\n        except Exception as e:\n            print(f\"Failed to process {product}: {e}\")\n\n\n\n","type":"content","url":"/notebooks/ch4-realtimedata#data-request","position":13},{"hierarchy":{"lvl1":"Chapter 5: Real-time MRMS Visualization","lvl2":"Visualization"},"type":"lvl2","url":"/notebooks/ch4-realtimedata#visualization","position":14},{"hierarchy":{"lvl1":"Chapter 5: Real-time MRMS Visualization","lvl2":"Visualization"},"content":"Now that we have the data read into memory using xarray, it is quite simple to plot. Here, we use hvplot to make an interactive visualization that allows the user to zoom in to a region of interest and mouse over values to better understand the product’s functionality over a specific region.\n\n# Mask data for neater visualization\ndata = data.where(data > 0, np.nan)\n\n# Get the NWS Reflectivity colormap and normalize range\nref_norm, ref_cmap = ctables.registry.get_with_steps('NWSReflectivity', 5, 5)\n\n# Convert to hex colors for Bokeh\nnorm = Normalize(vmin=ref_norm.vmin, vmax=ref_norm.vmax)\nhex_cmap = [ref_cmap(norm(val)) for val in range(ref_norm.vmin, ref_norm.vmax + 5, 5)]\nhex_cmap = [mcls.to_hex(c) for c in hex_cmap]\n\n# Plot using hvplot\nreflectivity_plot = data.hvplot.image(\n    x=\"longitude\", y=\"latitude\",\n    cmap=hex_cmap,\n    colorbar=True,\n    geo=True, \n    tiles=True, \n    alpha=0.7,\n    clim=(ref_norm.vmin, ref_norm.vmax),\n    title=f\"{product} - {pd.to_datetime(data.time.values).strftime('%b %d, %Y at %H:%M:%S')} UTC\",\n    frame_width=700,\n    frame_height=500,\n    xlabel='Longitude',\n    ylabel='Latitude',\n    tools=['hover']\n)\n\nreflectivity_plot\n\nAbove is your visualization! You can use the menu bar at the upper right side of the plot to pan around the plot, zoom in to a region of interest, and reset your selections to the default map. If you mouse over the values on the screen, you will see the latitude, longitude, and value associated with the selected product.\n\n","type":"content","url":"/notebooks/ch4-realtimedata#visualization","position":15},{"hierarchy":{"lvl1":"Chapter 5: Real-time MRMS Visualization","lvl2":"Parting thoughts"},"type":"lvl2","url":"/notebooks/ch4-realtimedata#parting-thoughts","position":16},{"hierarchy":{"lvl1":"Chapter 5: Real-time MRMS Visualization","lvl2":"Parting thoughts"},"content":"Congratulations on the completion of this notebook! You have successfully selected a region and product, queried the AWS S3 bucket, and visualized MRMS data in near real-time.\n\nIf you’d like to continue this analysis, here are a couple of bonus challenges:\n\n","type":"content","url":"/notebooks/ch4-realtimedata#parting-thoughts","position":17},{"hierarchy":{"lvl1":"Chapter 5: Real-time MRMS Visualization","lvl3":"Challenge (easy): Use the drop-down widgets in this notebook to plot a different project and region from your initial run!","lvl2":"Parting thoughts"},"type":"lvl3","url":"/notebooks/ch4-realtimedata#challenge-easy-use-the-drop-down-widgets-in-this-notebook-to-plot-a-different-project-and-region-from-your-initial-run","position":18},{"hierarchy":{"lvl1":"Chapter 5: Real-time MRMS Visualization","lvl3":"Challenge (easy): Use the drop-down widgets in this notebook to plot a different project and region from your initial run!","lvl2":"Parting thoughts"},"content":"\n\n","type":"content","url":"/notebooks/ch4-realtimedata#challenge-easy-use-the-drop-down-widgets-in-this-notebook-to-plot-a-different-project-and-region-from-your-initial-run","position":19},{"hierarchy":{"lvl1":"Chapter 5: Real-time MRMS Visualization","lvl3":"Challenge (medium): Delete the widget cell and use populate the notebook with a hard-coded “region” and “product” variable. Find a variable that was not covered in this notebook using the AWS S3 bucket.","lvl2":"Parting thoughts"},"type":"lvl3","url":"/notebooks/ch4-realtimedata#challenge-medium-delete-the-widget-cell-and-use-populate-the-notebook-with-a-hard-coded-region-and-product-variable-find-a-variable-that-was-not-covered-in-this-notebook-using-the-aws-s3-bucket","position":20},{"hierarchy":{"lvl1":"Chapter 5: Real-time MRMS Visualization","lvl3":"Challenge (medium): Delete the widget cell and use populate the notebook with a hard-coded “region” and “product” variable. Find a variable that was not covered in this notebook using the AWS S3 bucket.","lvl2":"Parting thoughts"},"content":"Hint: Make sure to copy the variable names from the AWS Explorer exactly as you see them on screen, or your bucket access step will error.\nHint 2: The visualization step has the correct framework for a new product, but has been customized for the three examples in this notebook. Make sure to find a good color bar and reformat the name of your product to make a more beautiful plot.\n\n","type":"content","url":"/notebooks/ch4-realtimedata#challenge-medium-delete-the-widget-cell-and-use-populate-the-notebook-with-a-hard-coded-region-and-product-variable-find-a-variable-that-was-not-covered-in-this-notebook-using-the-aws-s3-bucket","position":21},{"hierarchy":{"lvl1":"Chapter 5: Real-time MRMS Visualization","lvl3":"Challenge (difficult): Turn this notebook into a Python script, then use cron to create an updated plot from MRMS data every hour. Incorporate this plot into a web page, send it to your friend, or try it just for fun!","lvl2":"Parting thoughts"},"type":"lvl3","url":"/notebooks/ch4-realtimedata#challenge-difficult-turn-this-notebook-into-a-python-script-then-use-cron-to-create-an-updated-plot-from-mrms-data-every-hour-incorporate-this-plot-into-a-web-page-send-it-to-your-friend-or-try-it-just-for-fun","position":22},{"hierarchy":{"lvl1":"Chapter 5: Real-time MRMS Visualization","lvl3":"Challenge (difficult): Turn this notebook into a Python script, then use cron to create an updated plot from MRMS data every hour. Incorporate this plot into a web page, send it to your friend, or try it just for fun!","lvl2":"Parting thoughts"},"content":"Hint: See the appendix for static plotting code to get you started.\n\n\n\n","type":"content","url":"/notebooks/ch4-realtimedata#challenge-difficult-turn-this-notebook-into-a-python-script-then-use-cron-to-create-an-updated-plot-from-mrms-data-every-hour-incorporate-this-plot-into-a-web-page-send-it-to-your-friend-or-try-it-just-for-fun","position":23},{"hierarchy":{"lvl1":"Chapter 5: Real-time MRMS Visualization","lvl2":"Resources and references"},"type":"lvl2","url":"/notebooks/ch4-realtimedata#resources-and-references","position":24},{"hierarchy":{"lvl1":"Chapter 5: Real-time MRMS Visualization","lvl2":"Resources and references"},"content":"\n\nThings\n\nSecond things\n\n","type":"content","url":"/notebooks/ch4-realtimedata#resources-and-references","position":25},{"hierarchy":{"lvl1":"Chapter 5: Real-time MRMS Visualization","lvl2":"Appendix"},"type":"lvl2","url":"/notebooks/ch4-realtimedata#appendix","position":26},{"hierarchy":{"lvl1":"Chapter 5: Real-time MRMS Visualization","lvl2":"Appendix"},"content":"If you’d prefer to plot these data as a static plot, below is some sample code to kickstart your plotting journey.\n\n\"\"\"\nimport matplotlib.pyplot as plt\nimport cartopy.crs as ccrs\nimport cartopy.feature as cfeature\n    \nlons = data.longitude\nlats = data.latitude\nvalues = data.values\ndate = data.time.values\n\nminLon = lons.min() \nmaxLon = lons.max()\nminLat = lats.min()\nmaxLat = lats.max()\n\nfig = plt.figure(figsize=(12,6), facecolor='w', edgecolor='k')\nax = fig.add_axes([0, 0, 1, 1], projection=ccrs.Mercator())\nax.set_extent([minLon, maxLon, minLat, maxLat], crs=ccrs.Geodetic())\n\n# Set colors\nref_norm, ref_cmap = ctables.registry.get_with_steps('NWSReflectivity', 5, 5)\nunits = \"Reflectivity (dBZ)\"\ntitle = \"MRMS Merged Reflectivity\"\n\n# Add Boundaries\nax.add_feature(cfeature.STATES, linewidth=0.25)\n\n# Plot Data\nradarplot = ax.pcolormesh(lons, lats, values, transform=ccrs.PlateCarree(), cmap=ref_cmap, norm=ref_norm)\ncbar = plt.colorbar(radarplot)\ncbar.set_label(units)\n\nplt.title(f\"{title}\", loc='left', fontweight='bold')\n#plt.title('{}'.format(pd.to_datetime(date).strftime('%d %B %Y at %H:%M UTC')), loc='right')\n\nplt.show()\n\n\"\"\"","type":"content","url":"/notebooks/ch4-realtimedata#appendix","position":27}]}