{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MRMS Visualization](images/realtime_header.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5: Real-time MRMS Visualization\n",
    "\n",
    "This chapter walks you through the process of accessing and visualizing near real-time **Multi-Radar/Multi-Sensor System (MRMS)** data from **Amazon Web Services (AWS)**. You will select a region and radar product from a list of pre-set options, retrieve the latest data corresponding to your selections, and display it in an interactive plot.\n",
    "\n",
    "---\n",
    "\n",
    "### Purpose\n",
    "To provide hands-on experience in requesting and working with near real-time MRMS data from AWS S3.\n",
    "\n",
    "### Audience\n",
    "Users with at least **5 GB of memory** in their computing environment and a **basic familiarity with MRMS** concepts.        \n",
    "No programming experience is necessary to run the notebook, but a **basic knowledge of Python** (especially xarray) will help you apply these skills!\n",
    "\n",
    "### Expected Outcome\n",
    "By the end of this chapter, you will produce an **interactive visualization** of MRMS imagery for your chosen region and product. If you wish to continue working with near real-time MRMS data beyond this notebook, there are three bonus challenges at the end of the notebook that encourage the user to further apply their skills.    \n",
    "\n",
    "### Estimated Time\n",
    "- **15 minutes** ‚Äî Run the notebook and review the code.  \n",
    "- **30 minutes** ‚Äî Build enough familiarity to reproduce the workflow independently, and begin to tackle the bonus challenges.\n",
    "- **2 hours** - Complete all bonus steps and begin to integrate these concepts into your own workflow. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages required to request and open data from AWS S3\n",
    "import s3fs\n",
    "import urllib\n",
    "import tempfile\n",
    "import gzip\n",
    "import xarray as xr\n",
    "\n",
    "# Packages required for data visualization\n",
    "import datetime\n",
    "from datetime import timezone\n",
    "import numpy.ma as ma\n",
    "from metpy.plots import ctables\n",
    "import numpy as np\n",
    "import holoviews as hv\n",
    "import pandas as pd\n",
    "import panel as pn\n",
    "import hvplot.xarray \n",
    "import matplotlib.colors as mcls\n",
    "from matplotlib.colors import Normalize\n",
    "#pn.extension('bokeh')\n",
    "hv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üåßÔ∏è About MRMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Multi-Radar/Multi-Sensor System (MRMS) produces products for public infrastructure, weather forecasts and warnings, aviation, and numerical weather prediction. It provides high spatial (1-km) and temporal (2-min) resolution radar products at 31 vertical levels, and ingests data from numerous sources (including radar networks across the US and Canada, surface and upper air observations, lightning detection systems, satellite observations, and forecast models)[<sup>1</sup>](https://www.nssl.noaa.gov/projects/mrms/).\n",
    "\n",
    "\n",
    "For more information, please refer to Chapter 1 of this project: [Learning about MRMS](ch1_Introduction.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚òÅÔ∏è About AWS and NOAA's Open Data Dissemination Program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Amazon Web Services Simple Storage Service ([AWS S3](https://aws.amazon.com/s3/)) is cloud-based object storage service. Through a public-private partnership with the National Oceanic and Atmospheric Administration (NOAA)'s Open Data Dissemination Program ([NODD](https://www.noaa.gov/information-technology/open-data-dissemination)), NOAA is able to store multiple petabytes of open-access earth science data on AWS S3, including the MRMS dataset. This allows users to quickly and freely access MRMS data in real-time (with an update frequency of two minutes) without having to download the data to their personal systems. \n",
    "\n",
    "Because of this partnership, we can access the data as an anonymous client -- no login required!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the S3 filesystem as anonymous\n",
    "aws = s3fs.S3FileSystem(anon=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can explore the S3 bucket that holds MRMS data to assess data availability and structure -- just visit [this link](https://noaa-mrms-pds.s3.amazonaws.com/index.html), which takes you to the MRMS bucket."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{hint}\n",
    "You can run `aws.ls` to see the file structure in code. Try it yourself!\n",
    "\n",
    "```python\n",
    "# Example code to execute: first five items in the 'CONUS' directory of the MRMS bucket on S3\n",
    "print(aws.ls(f'noaa-mrms-pds/CONUS/')[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Data selection\n",
    "\n",
    "For ease of use, I've integrated widgets (drop-down menus!) that allow you to make selections from AWS, and refined a selection of data variables as a demonstration. You can choose between the QC'd Merged Reflectivity Composite[^MRQC], a 12-hour multisensor QPE from Pass 2[^MSQPE], and the Probability of Severe Hail[^POSH]. \n",
    "\n",
    "Now, you have the option to select a region and a radar product to visualize in near real-time. Go ahead and run the cell below, then use the created drop-down menus to select a region, a radar product. \n",
    "\n",
    "[^MRQC]: **Merged Reflectivity Composite**          \n",
    "    ![MRMS Visualization](images/QCReflectivity.png)        \n",
    "    **Description:** The maximum reflectivity in a vertical column, from the merged product.       \n",
    "    **Spatial Resolution:** 0.01¬∫ Latitude (~1.11 km) x 0.01¬∫ Longitude (~1.01 km at 25¬∫N and 0.73 km at 49¬∫N)      \n",
    "    **Temporal Resolution:** 2 minutes       \n",
    "    **AWS Variable:** \"MergedReflectivityQCComposite_00.50\"         \n",
    "\n",
    "[^MSQPE]: **12-hour Multisensor Quantitative Precipitation Estimate (Pass 2)**\n",
    "     ![MRMS Visualization](images/QPE.png)        \n",
    "    **Description:** 12h rainfall accumulation estimate, using data from rain gauges and NWP QPF (HRRR/RAP blend for CONUS). This is the Pass 2 dataset, which has a higher latency but includes more rain gauge data than Pass 1 (Pass 1 has 20-minute latency and includes 10% of gauges, while Pass 2 has 60-minute latency and includes 60% of gauges).   \n",
    "    **Spatial Resolution:** 1km x 1km        \n",
    "    **Temporal Resolution:** 60 minutes      \n",
    "    **AWS Variable:** \"MultiSensor_QPE_12H_Pass2_00.00\"  \n",
    "\n",
    "[^POSH]: **Probability of Severe Hail**\n",
    "     ![MRMS Visualization](images/POSH.png)        \n",
    "    **Description:** The probability of 0.75-inch diameter hail.    \n",
    "    **Spatial Resolution:** 0.01¬∫ Latitude (~1.11 km) x 0.01¬∫ Longitude (~1.01 km at 25¬∫N and 0.73 km at 49¬∫N)      \n",
    "    **Temporal Resolution:** 2 minutes             \n",
    "    **AWS Variable:** \"POSH_00.50\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dropdown options -- region and product from the AWS structure\n",
    "region_options = [\n",
    "    \"CONUS\",\n",
    "    \"ALASKA\",\n",
    "    \"CARIB\",\n",
    "    \"GUAM\",\n",
    "    \"HAWAII\"\n",
    "]\n",
    "\n",
    "product_options = [\n",
    "    \"MergedReflectivityQCComposite_00.50\",\n",
    "    \"MultiSensor_QPE_12H_Pass2_00.00\",\n",
    "    \"POSH_00.50\"\n",
    "]\n",
    "\n",
    "# Create dropdown widgets for user selection\n",
    "region_choice = pn.widgets.Select(name='Region', options=region_options, width=325)\n",
    "product_choice = pn.widgets.Select(name='MRMS product', options=product_options, width=325)\n",
    "\n",
    "pn.Column(region_choice, product_choice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéâ Congratulations, you've made your data selection!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} Caution\n",
    ":class: warning\n",
    "\n",
    "If you re-run the cell that generated your drop-down menus (above), it will reset your selection. Click into the next cell (below) and continue running the notebook from there!\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the user selection from 'Region' \n",
    "region = region_choice.value\n",
    "\n",
    "# Retrieve the user selection from 'MRMS product'\n",
    "product = product_choice.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì° Data request\n",
    "Now that you've made your variable selection, it's time to read in the data from AWS. First, we retrieve the current UTC datetime so that we can request files from today's S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the current datetime in UTC to know which bucket to query\n",
    "now = datetime.datetime.now(datetime.UTC)\n",
    "datestring = now.strftime('%Y%m%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we query the S3 bucket to make sure the data is available on AWS. If the following cell errors, reference [the S3](https://noaa-mrms-pds.s3.amazonaws.com/index.html#CONUS/) bucket to confirm that your requested region, date, and product exists and is entered correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the S3 bucket for the available files that meet the criteria\n",
    "try:\n",
    "    data_files = aws.ls(f'noaa-mrms-pds/{region}/{product}/{datestring}/', refresh=True)  \n",
    "except Exception as e:\n",
    "    print(f\"Error accessing S3 bucket: {e}\")\n",
    "    data_files = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we make the data request and read it in using xarray. The following block of code finds the most recent file that fits your criteria, ensures that the file was created recently (within the past two hours), then makes the data request. The MRMS data was uploaded to S3 as a compressed grib2 file, so that's what our program receives. This code decompresses the grib2 file and reads it in using xarray, making the format more easily incorporated into our workflow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_files:\n",
    "    # Choose the last file from S3 for the most recent data\n",
    "    most_recent_file = data_files[-1]\n",
    "\n",
    "    # Check that the most recent file is within 2 hours of current time\n",
    "    timestamp_str = most_recent_file.split('_')[-1].replace('.grib2.gz', '')\n",
    "    dt = datetime.datetime.strptime(timestamp_str, \"%Y%m%d-%H%M%S\").replace(tzinfo=timezone.utc)\n",
    "    if abs((now - dt).total_seconds()) <= 120 * 60:\n",
    "        # Download file to memory, decompress from .gz, and read into xarray\n",
    "        try:\n",
    "            response = urllib.request.urlopen(f\"https://noaa-mrms-pds.s3.amazonaws.com/{most_recent_file[14:]}\")\n",
    "            compressed_file = response.read()\n",
    "\n",
    "            with tempfile.NamedTemporaryFile(suffix=\".grib2\") as f:\n",
    "                f.write(gzip.decompress(compressed_file))\n",
    "                f.flush()\n",
    "                data = xr.load_dataarray(f.name, engine=\"cfgrib\", decode_timedelta=True)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process {product}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data is now contained as an xarray data array in the **data** variable!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üó∫Ô∏è Visualization\n",
    "Now that we have the data read into memory using xarray, it is quite simple to plot. Here, we use hvplot to make an interactive visualization that allows the user to zoom in to a region of interest and mouse over values to better understand the product's functionality over a specific region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask data for neater visualization\n",
    "data = data.where(data > 0, np.nan)\n",
    "\n",
    "# Get the NWS Reflectivity colormap and normalize range\n",
    "ref_norm, ref_cmap = ctables.registry.get_with_steps('NWSReflectivity', 5, 5)\n",
    "\n",
    "# Convert to hex colors for Bokeh\n",
    "norm = Normalize(vmin=ref_norm.vmin, vmax=ref_norm.vmax)\n",
    "hex_cmap = [ref_cmap(norm(val)) for val in range(ref_norm.vmin, ref_norm.vmax + 5, 5)]\n",
    "hex_cmap = [mcls.to_hex(c) for c in hex_cmap]\n",
    "\n",
    "# Plot using hvplot\n",
    "reflectivity_plot = data.hvplot.image(\n",
    "    x=\"longitude\", y=\"latitude\",\n",
    "    cmap=hex_cmap,\n",
    "    colorbar=True,\n",
    "    geo=True, \n",
    "    tiles=True, \n",
    "    alpha=0.7,\n",
    "    clim=(ref_norm.vmin, ref_norm.vmax),\n",
    "    title=f\"{product} - {pd.to_datetime(data.time.values).strftime('%b %d, %Y at %H:%M:%S')} UTC\",\n",
    "    frame_width=700,\n",
    "    frame_height=500,\n",
    "    xlabel='Longitude',\n",
    "    ylabel='Latitude',\n",
    "    tools=['hover']\n",
    ")\n",
    "\n",
    "reflectivity_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is your visualization! You can use the menu bar at the upper right side of the plot to pan around the plot, zoom in to a region of interest, and reset your selections to the default map. If you mouse over the values on the screen, you will see the latitude, longitude, and value associated with the selected product. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèÜ Bonus Challenges\n",
    "Congratulations on the completion of this notebook! You have successfully selected a region and product, queried the AWS S3 bucket, and visualized MRMS data in near real-time.\n",
    "\n",
    "If you'd like to continue this analysis, I've provided a couple of bonus challenges. Click on the drop-down menu to view the bonus challenge according to your desired level of difficulty. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{dropdown} üü¢ Challenge (easy) -- make a new data selection\n",
    ":class: tip\n",
    "\n",
    "Use the drop-down widgets in this notebook to plot a different product and region from your initial run!\n",
    "\n",
    "```{dropdown} üí° Hint\n",
    "- Scroll up to the drop-down menus, make new region/product selections, and run all cells *below* the drop-down menus to see your new visualization!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{dropdown} üü° Challenge (medium) -- plot a new variable from AWS\n",
    ":class: warning\n",
    "\n",
    "Browse the [AWS S3 bucket](https://noaa-mrms-pds.s3.amazonaws.com/index.html) and the [NSSL Variable Table](https://www.nssl.noaa.gov/projects/mrms/operational/tables.php) and find an MRMS product that was not covered in this notebook. Alter the provided code to read in and plot your new variable!\n",
    "\n",
    "```{dropdown} üí° Hints\n",
    "**Step-by-step:**\n",
    "1. Delete the widget-generating cell in the \"Data selection\" section.\n",
    "2. Hard-code the \"region\" and \"product\" variables with the *exact* strings that correspond to your data product on AWS. For example: \n",
    "    ```python\n",
    "    region = \"CONUS\" \n",
    "    product = \"MergedReflectivityQCComposite_00.50\"\n",
    "3. Run the rest of the notebook cells to produce your plot.\n",
    "\n",
    "**Troubleshooting:**       \n",
    "- If your data request step returns an error, go to the [AWS S3 bucket](https://noaa-mrms-pds.s3.amazonaws.com/index.html) and manually click through your selection. Is the data there? Did you copy the product and region variable names *exactly* as they are in S3?   \n",
    "- Some datasets have different values to indicate that the data is missing, range folded, or not covered. You can find this information in the [NSSL talbe](https://www.nssl.noaa.gov/projects/mrms/operational/tables.php). If your data has unique values, you may need to mask it in the plotting step to make sure the colorbar works for your dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{dropdown} üî¥ Challenge (difficult) -- create a cron job to update your MRMS plot hourly\n",
    ":class: danger\n",
    "\n",
    "Turn this notebook into a Python script, then use cron to create an updated plot from MRMS data every hour. Incorporate this plot into a web page, send it to your friend, or try it just for fun!      \n",
    "\n",
    "```{dropdown} üí° Hints\n",
    "**Step-by-step:**\n",
    "1. Delete the widget-generating cell in the \"Data selection\" section.\n",
    "2. Hard-code the \"region\" and \"product\" variables with the *exact* strings that correspond to your data product on AWS. For example: \n",
    "    ```python\n",
    "    region = \"CONUS\" \n",
    "    product = \"MergedReflectivityQCComposite_00.50\"\n",
    "3. Delete the hvplot-generating cell in the \"Visualization\" section.\n",
    "4. Use the static plotting code located in the appendix for your visualization, or write your own static plotting code. Change the filepath in plt.savefig() to an absolute path to ensure that your plot will be saved in a known, designated location.\n",
    "5. (optional) Delete all markdown cells in the notebook to make your code sections more clearly delineated. \n",
    "6. Organize the import statements, removing any unnecessary imports (such as those associated with widgets and the hvplot) and duplicates. \n",
    "7. Restart the notebook, clear all outputs, and run the cells again to confirm that the output is a single, static plot with the most recent time stamp. If everything executed as expected, you may continue. If you ran into any errors, now is the time to troubleshoot!\n",
    "8. Create a .py file, and copy your Jupyter Notebook cells chronologically into this file. \n",
    "\n",
    "Now, the exact way you go about creating a cron-ready file is up to you. You can apply your current cron workflow (if one exists), paste your current .py script into ChatGPT or another GenAI programming tool for help, or find online resources that list cron best practices. \n",
    "\n",
    "Here is what I did:\n",
    "1. Organized my Python code into two functions: retrieve_data() and plot_data(). I execute these functions under the block: <<__name__ == \"__main__\">>:, using input from retrieve_data() as an argument to plot_data(). \n",
    "2. Added try except and exit in case of failure\n",
    "3. Added logging if AWS logging isn't buggy.\n",
    "4. Ran this line to run every hour: \n",
    "5. Maybe my code will just be in an example folder somewhere. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Resources and references"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AWS Data Access:**\n",
    "- [AWS S3 bucket for MRMS data](https://aws.amazon.com/marketplace/pp/prodview-6odvdc4md2jjc)\n",
    "\n",
    "**MRMS Information:**\n",
    "\n",
    "**Coding References and Examples:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Appendix\n",
    "If you'd prefer to plot these data as a static plot, below is some sample code to kickstart your plotting journey. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import pandas as pd\n",
    "from metpy.plots import ctables\n",
    "\n",
    "# Mask data for neater visualization\n",
    "data = data.where(data > 0, np.nan)\n",
    "\n",
    "# Extract data\n",
    "lons = data.longitude\n",
    "lats = data.latitude\n",
    "values = data.values\n",
    "date = pd.to_datetime(data.time.values)\n",
    "\n",
    "# Domain bounds\n",
    "minLon, maxLon = lons.min(), lons.max()\n",
    "minLat, maxLat = lats.min(), lats.max()\n",
    "\n",
    "# Setup figure and axis\n",
    "fig, ax = plt.subplots(figsize=(12, 6),\n",
    "                       subplot_kw={\"projection\": ccrs.Mercator()})\n",
    "\n",
    "ax.set_extent([minLon, maxLon, minLat, maxLat], crs=ccrs.PlateCarree())\n",
    "\n",
    "# Set colors\n",
    "ref_norm, ref_cmap = ctables.registry.get_with_steps(\"NWSReflectivity\", 5, 5)\n",
    "units = \"Reflectivity (dBZ)\"\n",
    "title = \"MRMS Merged Reflectivity\"\n",
    "\n",
    "# Add features\n",
    "ax.add_feature(cfeature.STATES, linewidth=0.5)\n",
    "ax.add_feature(cfeature.BORDERS, linewidth=0.7)\n",
    "\n",
    "# Plot data\n",
    "radarplot = ax.pcolormesh(\n",
    "    lons, lats, values,\n",
    "    transform=ccrs.PlateCarree(),\n",
    "    cmap=ref_cmap, norm=ref_norm,\n",
    "    shading=\"auto\"\n",
    ")\n",
    "\n",
    "# Colorbar\n",
    "cbar = fig.colorbar(radarplot, ax=ax, orientation=\"vertical\", pad=0.02)\n",
    "cbar.set_label(units)\n",
    "\n",
    "# Titles\n",
    "ax.set_title(title, loc=\"left\", fontweight=\"bold\")\n",
    "ax.set_title(date.strftime(\"%d %B %Y at %H:%M UTC\"), loc=\"right\")\n",
    "\n",
    "png_name = f\"mrms_{region}_{product}_{date.strftime('%Y%m%d_%H%M%S')}.png\"\n",
    "plt.savefig(png_name, dpi=150, bbox_inches=\"tight\")\n",
    "plt.close(fig)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "nbdime-conflicts": {
   "local_diff": [
    {
     "diff": [
      {
       "diff": [
        {
         "key": 0,
         "op": "addrange",
         "valuelist": [
          "Python 3"
         ]
        },
        {
         "key": 0,
         "length": 1,
         "op": "removerange"
        }
       ],
       "key": "display_name",
       "op": "patch"
      }
     ],
     "key": "kernelspec",
     "op": "patch"
    }
   ],
   "remote_diff": [
    {
     "diff": [
      {
       "diff": [
        {
         "key": 0,
         "op": "addrange",
         "valuelist": [
          "Python3"
         ]
        },
        {
         "key": 0,
         "length": 1,
         "op": "removerange"
        }
       ],
       "key": "display_name",
       "op": "patch"
      }
     ],
     "key": "kernelspec",
     "op": "patch"
    }
   ]
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
